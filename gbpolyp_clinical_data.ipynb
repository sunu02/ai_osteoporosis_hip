{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total images = 163\n",
      "total images = 27\n",
      "total images = 3\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "import keras\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Dropout\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "share_dir = '/home/ubuntu/workspace/share/ai_osteoporosis_hip'\n",
    "crop_dir = os.path.join(share_dir, 'crop')\n",
    "xls_dir = os.path.join(share_dir, 'excel_files')\n",
    "#data_dir = '/home/ubuntu/workspace/share/gbpolyp/final_data'\n",
    "work_dir = '/home/ubuntu/workspace/ai_osteoporosis_hip'\n",
    "xls_file = os.path.join(xls_dir, 'final.xlsx')\n",
    "\n",
    "def generate_df(xls_file):\n",
    "    df = pd.read_excel(xls_file, dtype={'patient_id':str})\n",
    "\n",
    "    d1 = df[df['split']==1]\n",
    "\n",
    "    columns_list = ['age', 'height', 'weight', 'bmi']\n",
    "    \n",
    "    for column_name in columns_list:\n",
    "        mean = d1[column_name].mean()\n",
    "        std = d1[column_name].std()\n",
    "        df[column_name] = df[column_name].apply(lambda x: (x - mean) / std)\n",
    "        \n",
    "    sex_to_code = {'M': 1, 'F':0}\n",
    "    df['sex_code'] = df['sex'].apply(lambda x: sex_to_code[x])    \n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def get_data(df, set_name):\n",
    "    count = 0\n",
    "\n",
    "    set_dict = {'train':1, 'validation':2, 'test':3}\n",
    "    set_code = set_dict[set_name]\n",
    "    data = df[df['split']==set_code]\n",
    "    count = len(data)\n",
    "    print('total images = %d' % count)\n",
    "\n",
    "    clinical_data = np.ndarray((count, 3), dtype=np.float32)\n",
    "    y_data = np.ndarray((count, ), dtype=np.int8)\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        age = data.iloc[i]['age']\n",
    "        sex = data.iloc[i]['sex_code']\n",
    "        bmi = data.iloc[i]['bmi']\n",
    "        class2_1 = data.iloc[i]['class2_1']\n",
    "\n",
    "        clinical_data[i] = (age, sex, bmi)\n",
    "        y_data[i] = class2_1\n",
    "        i += 1\n",
    "\n",
    "    return clinical_data, y_data\n",
    "\n",
    "def resample(df):\n",
    "    resampled_list = []\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        age = df.iloc[i]['age']\n",
    "        sex = df.iloc[i]['sex_code']\n",
    "        bmi = df.iloc[i]['bmi']\n",
    "        class2_1 = df.iloc[i]['class2_1']\n",
    "        split = df.iloc[i]['split']\n",
    "        if class2_1 == 0:\n",
    "            resampled_list.append((age, sex, bmi, class2_1, split))\n",
    "        else:\n",
    "            resampled_list.append((age, sex, bmi, class2_1, split))\n",
    "            resampled_list.append((age, sex, bmi, class2_1, split))\n",
    "            resampled_list.append((age, sex, bmi, class2_1, split))\n",
    "    \n",
    "    random.shuffle(resampled_list)\n",
    "    df2 = pd.DataFrame(resampled_list[0:200], columns=['age', 'sex_code', 'bmi', 'class2_1', 'split'])\n",
    "                     \n",
    "    return df2\n",
    "\n",
    "df1 = generate_df(xls_file)\n",
    "df = resample(df1)\n",
    "\n",
    "clinical_train, y_train = get_data(df, 'train')\n",
    "clinical_validation, y_validation = get_data(df, 'validation')\n",
    "clinical_test, y_test = get_data(df, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "\n",
    "def get_model(hidden_layer):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(hidden_layer, kernel_regularizer=l2(0.001), activation='relu', input_dim=3))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(hidden_layer, kernel_regularizer=l2(0.001), activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(hidden_layer, kernel_regularizer=l2(0.001), activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=RMSprop(lr=0.0001), loss='binary_crossentropy', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 163 samples, validate on 27 samples\n",
      "Epoch 1/3000\n",
      "163/163 [==============================] - 1s 5ms/step - loss: 0.6945 - acc: 0.5706 - val_loss: 0.6953 - val_acc: 0.4074\n",
      "Epoch 2/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.6917 - acc: 0.6380 - val_loss: 0.6954 - val_acc: 0.4444\n",
      "Epoch 3/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.6891 - acc: 0.6626 - val_loss: 0.6938 - val_acc: 0.5185\n",
      "Epoch 4/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.6853 - acc: 0.7055 - val_loss: 0.6920 - val_acc: 0.5556\n",
      "Epoch 5/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.6817 - acc: 0.7117 - val_loss: 0.6900 - val_acc: 0.6296\n",
      "Epoch 6/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.6784 - acc: 0.7117 - val_loss: 0.6887 - val_acc: 0.5926\n",
      "Epoch 7/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.6755 - acc: 0.7178 - val_loss: 0.6867 - val_acc: 0.6296\n",
      "Epoch 8/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.6728 - acc: 0.7362 - val_loss: 0.6857 - val_acc: 0.5926\n",
      "Epoch 9/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.6704 - acc: 0.7423 - val_loss: 0.6842 - val_acc: 0.6296\n",
      "Epoch 10/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.6680 - acc: 0.7301 - val_loss: 0.6833 - val_acc: 0.5926\n",
      "Epoch 11/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.6656 - acc: 0.7239 - val_loss: 0.6821 - val_acc: 0.6296\n",
      "Epoch 12/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.6634 - acc: 0.7301 - val_loss: 0.6805 - val_acc: 0.6296\n",
      "Epoch 13/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.6611 - acc: 0.7301 - val_loss: 0.6793 - val_acc: 0.6296\n",
      "Epoch 14/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.6588 - acc: 0.7239 - val_loss: 0.6777 - val_acc: 0.6296\n",
      "Epoch 15/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.6564 - acc: 0.7301 - val_loss: 0.6765 - val_acc: 0.6296\n",
      "Epoch 16/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.6542 - acc: 0.7362 - val_loss: 0.6749 - val_acc: 0.6296\n",
      "Epoch 17/3000\n",
      "163/163 [==============================] - 0s 56us/step - loss: 0.6519 - acc: 0.7301 - val_loss: 0.6746 - val_acc: 0.6296\n",
      "Epoch 18/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.6496 - acc: 0.7239 - val_loss: 0.6728 - val_acc: 0.6296\n",
      "Epoch 19/3000\n",
      "163/163 [==============================] - 0s 53us/step - loss: 0.6473 - acc: 0.7301 - val_loss: 0.6720 - val_acc: 0.6296\n",
      "Epoch 20/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.6450 - acc: 0.7239 - val_loss: 0.6708 - val_acc: 0.6296\n",
      "Epoch 21/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.6426 - acc: 0.7301 - val_loss: 0.6699 - val_acc: 0.6296\n",
      "Epoch 22/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.6402 - acc: 0.7301 - val_loss: 0.6683 - val_acc: 0.6296\n",
      "Epoch 23/3000\n",
      "163/163 [==============================] - 0s 53us/step - loss: 0.6379 - acc: 0.7362 - val_loss: 0.6680 - val_acc: 0.6296\n",
      "Epoch 24/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.6355 - acc: 0.7301 - val_loss: 0.6661 - val_acc: 0.6296\n",
      "Epoch 25/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.6331 - acc: 0.7362 - val_loss: 0.6661 - val_acc: 0.6296\n",
      "Epoch 26/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.6307 - acc: 0.7239 - val_loss: 0.6647 - val_acc: 0.6296\n",
      "Epoch 27/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.6284 - acc: 0.7239 - val_loss: 0.6650 - val_acc: 0.5556\n",
      "Epoch 28/3000\n",
      "163/163 [==============================] - 0s 57us/step - loss: 0.6261 - acc: 0.7301 - val_loss: 0.6637 - val_acc: 0.6296\n",
      "Epoch 29/3000\n",
      "163/163 [==============================] - 0s 53us/step - loss: 0.6237 - acc: 0.7362 - val_loss: 0.6643 - val_acc: 0.5556\n",
      "Epoch 30/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.6214 - acc: 0.7362 - val_loss: 0.6628 - val_acc: 0.5556\n",
      "Epoch 31/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.6191 - acc: 0.7362 - val_loss: 0.6633 - val_acc: 0.5556\n",
      "Epoch 32/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.6168 - acc: 0.7423 - val_loss: 0.6622 - val_acc: 0.5556\n",
      "Epoch 33/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.6143 - acc: 0.7423 - val_loss: 0.6624 - val_acc: 0.5556\n",
      "Epoch 34/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.6119 - acc: 0.7485 - val_loss: 0.6614 - val_acc: 0.5556\n",
      "Epoch 35/3000\n",
      "163/163 [==============================] - 0s 57us/step - loss: 0.6095 - acc: 0.7485 - val_loss: 0.6614 - val_acc: 0.5556\n",
      "Epoch 36/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.6071 - acc: 0.7423 - val_loss: 0.6605 - val_acc: 0.5556\n",
      "Epoch 37/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.6048 - acc: 0.7485 - val_loss: 0.6614 - val_acc: 0.5556\n",
      "Epoch 38/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.6025 - acc: 0.7423 - val_loss: 0.6599 - val_acc: 0.5556\n",
      "Epoch 39/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.6001 - acc: 0.7423 - val_loss: 0.6605 - val_acc: 0.5556\n",
      "Epoch 40/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.5978 - acc: 0.7423 - val_loss: 0.6594 - val_acc: 0.5556\n",
      "Epoch 41/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.5955 - acc: 0.7485 - val_loss: 0.6599 - val_acc: 0.5556\n",
      "Epoch 42/3000\n",
      "163/163 [==============================] - 0s 56us/step - loss: 0.5932 - acc: 0.7485 - val_loss: 0.6583 - val_acc: 0.5556\n",
      "Epoch 43/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.5909 - acc: 0.7485 - val_loss: 0.6585 - val_acc: 0.5556\n",
      "Epoch 44/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.5885 - acc: 0.7485 - val_loss: 0.6579 - val_acc: 0.5556\n",
      "Epoch 45/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.5861 - acc: 0.7669 - val_loss: 0.6580 - val_acc: 0.5185\n",
      "Epoch 46/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.5838 - acc: 0.7607 - val_loss: 0.6575 - val_acc: 0.5185\n",
      "Epoch 47/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.5815 - acc: 0.7607 - val_loss: 0.6570 - val_acc: 0.5185\n",
      "Epoch 48/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.5791 - acc: 0.7546 - val_loss: 0.6564 - val_acc: 0.5185\n",
      "Epoch 49/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.5768 - acc: 0.7485 - val_loss: 0.6566 - val_acc: 0.5185\n",
      "Epoch 50/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.5745 - acc: 0.7485 - val_loss: 0.6558 - val_acc: 0.5185\n",
      "Epoch 51/3000\n",
      "163/163 [==============================] - 0s 58us/step - loss: 0.5723 - acc: 0.7423 - val_loss: 0.6570 - val_acc: 0.5185\n",
      "Epoch 52/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.5701 - acc: 0.7485 - val_loss: 0.6548 - val_acc: 0.5556\n",
      "Epoch 53/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.5679 - acc: 0.7423 - val_loss: 0.6565 - val_acc: 0.5185\n",
      "Epoch 54/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.5656 - acc: 0.7485 - val_loss: 0.6548 - val_acc: 0.5556\n",
      "Epoch 55/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.5634 - acc: 0.7485 - val_loss: 0.6564 - val_acc: 0.5556\n",
      "Epoch 56/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.5613 - acc: 0.7485 - val_loss: 0.6548 - val_acc: 0.5556\n",
      "Epoch 57/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.5592 - acc: 0.7485 - val_loss: 0.6568 - val_acc: 0.5185\n",
      "Epoch 58/3000\n",
      "163/163 [==============================] - 0s 54us/step - loss: 0.5571 - acc: 0.7485 - val_loss: 0.6552 - val_acc: 0.5556\n",
      "Epoch 59/3000\n",
      "163/163 [==============================] - 0s 55us/step - loss: 0.5549 - acc: 0.7423 - val_loss: 0.6573 - val_acc: 0.5556\n",
      "Epoch 60/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.5528 - acc: 0.7362 - val_loss: 0.6560 - val_acc: 0.5556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.5506 - acc: 0.7362 - val_loss: 0.6556 - val_acc: 0.5556\n",
      "Epoch 62/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.5485 - acc: 0.7423 - val_loss: 0.6572 - val_acc: 0.5556\n",
      "Epoch 63/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.5464 - acc: 0.7362 - val_loss: 0.6562 - val_acc: 0.5556\n",
      "Epoch 64/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.5443 - acc: 0.7362 - val_loss: 0.6578 - val_acc: 0.5556\n",
      "Epoch 65/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.5423 - acc: 0.7362 - val_loss: 0.6570 - val_acc: 0.5556\n",
      "Epoch 66/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.5404 - acc: 0.7423 - val_loss: 0.6582 - val_acc: 0.5556\n",
      "Epoch 67/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.5385 - acc: 0.7423 - val_loss: 0.6577 - val_acc: 0.5556\n",
      "Epoch 68/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.5366 - acc: 0.7423 - val_loss: 0.6592 - val_acc: 0.5556\n",
      "Epoch 69/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.5348 - acc: 0.7423 - val_loss: 0.6580 - val_acc: 0.5556\n",
      "Epoch 70/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.5331 - acc: 0.7423 - val_loss: 0.6613 - val_acc: 0.5556\n",
      "Epoch 71/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.5314 - acc: 0.7423 - val_loss: 0.6584 - val_acc: 0.5556\n",
      "Epoch 72/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.5298 - acc: 0.7423 - val_loss: 0.6623 - val_acc: 0.5556\n",
      "Epoch 73/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.5281 - acc: 0.7423 - val_loss: 0.6588 - val_acc: 0.5556\n",
      "Epoch 74/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.5265 - acc: 0.7423 - val_loss: 0.6630 - val_acc: 0.5556\n",
      "Epoch 75/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.5250 - acc: 0.7423 - val_loss: 0.6609 - val_acc: 0.5556\n",
      "Epoch 76/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.5234 - acc: 0.7423 - val_loss: 0.6632 - val_acc: 0.5556\n",
      "Epoch 77/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.5219 - acc: 0.7423 - val_loss: 0.6631 - val_acc: 0.5556\n",
      "Epoch 78/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.5205 - acc: 0.7423 - val_loss: 0.6644 - val_acc: 0.5556\n",
      "Epoch 79/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.5191 - acc: 0.7423 - val_loss: 0.6640 - val_acc: 0.5556\n",
      "Epoch 80/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.5177 - acc: 0.7362 - val_loss: 0.6651 - val_acc: 0.5556\n",
      "Epoch 81/3000\n",
      "163/163 [==============================] - 0s 54us/step - loss: 0.5164 - acc: 0.7423 - val_loss: 0.6635 - val_acc: 0.5556\n",
      "Epoch 82/3000\n",
      "163/163 [==============================] - 0s 54us/step - loss: 0.5151 - acc: 0.7362 - val_loss: 0.6664 - val_acc: 0.5556\n",
      "Epoch 83/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.5138 - acc: 0.7423 - val_loss: 0.6639 - val_acc: 0.5556\n",
      "Epoch 84/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.5126 - acc: 0.7362 - val_loss: 0.6673 - val_acc: 0.5556\n",
      "Epoch 85/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.5114 - acc: 0.7423 - val_loss: 0.6644 - val_acc: 0.5556\n",
      "Epoch 86/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.5101 - acc: 0.7362 - val_loss: 0.6674 - val_acc: 0.5556\n",
      "Epoch 87/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.5090 - acc: 0.7423 - val_loss: 0.6650 - val_acc: 0.5556\n",
      "Epoch 88/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.5079 - acc: 0.7423 - val_loss: 0.6695 - val_acc: 0.5556\n",
      "Epoch 89/3000\n",
      "163/163 [==============================] - 0s 53us/step - loss: 0.5068 - acc: 0.7423 - val_loss: 0.6658 - val_acc: 0.5556\n",
      "Epoch 90/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.5059 - acc: 0.7423 - val_loss: 0.6703 - val_acc: 0.5556\n",
      "Epoch 91/3000\n",
      "163/163 [==============================] - 0s 56us/step - loss: 0.5049 - acc: 0.7423 - val_loss: 0.6667 - val_acc: 0.5556\n",
      "Epoch 92/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.5040 - acc: 0.7423 - val_loss: 0.6720 - val_acc: 0.5556\n",
      "Epoch 93/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.5030 - acc: 0.7423 - val_loss: 0.6671 - val_acc: 0.5926\n",
      "Epoch 94/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.5020 - acc: 0.7423 - val_loss: 0.6732 - val_acc: 0.5556\n",
      "Epoch 95/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.5011 - acc: 0.7423 - val_loss: 0.6703 - val_acc: 0.5556\n",
      "Epoch 96/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.5002 - acc: 0.7423 - val_loss: 0.6737 - val_acc: 0.5556\n",
      "Epoch 97/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.4994 - acc: 0.7423 - val_loss: 0.6715 - val_acc: 0.5556\n",
      "Epoch 98/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.4987 - acc: 0.7423 - val_loss: 0.6757 - val_acc: 0.5556\n",
      "Epoch 99/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.4979 - acc: 0.7423 - val_loss: 0.6731 - val_acc: 0.5556\n",
      "Epoch 100/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.4971 - acc: 0.7362 - val_loss: 0.6750 - val_acc: 0.5556\n",
      "Epoch 101/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.4963 - acc: 0.7362 - val_loss: 0.6745 - val_acc: 0.5556\n",
      "Epoch 102/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.4955 - acc: 0.7362 - val_loss: 0.6765 - val_acc: 0.5556\n",
      "Epoch 103/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.4947 - acc: 0.7362 - val_loss: 0.6727 - val_acc: 0.5926\n",
      "Epoch 104/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.4939 - acc: 0.7362 - val_loss: 0.6770 - val_acc: 0.5556\n",
      "Epoch 105/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.4932 - acc: 0.7362 - val_loss: 0.6733 - val_acc: 0.6296\n",
      "Epoch 106/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.4925 - acc: 0.7362 - val_loss: 0.6792 - val_acc: 0.5556\n",
      "Epoch 107/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.4918 - acc: 0.7362 - val_loss: 0.6745 - val_acc: 0.6296\n",
      "Epoch 108/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.4911 - acc: 0.7362 - val_loss: 0.6787 - val_acc: 0.5556\n",
      "Epoch 109/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.4904 - acc: 0.7423 - val_loss: 0.6757 - val_acc: 0.6296\n",
      "Epoch 110/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.4898 - acc: 0.7485 - val_loss: 0.6805 - val_acc: 0.5556\n",
      "Epoch 111/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.4892 - acc: 0.7485 - val_loss: 0.6765 - val_acc: 0.6296\n",
      "Epoch 112/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.4886 - acc: 0.7485 - val_loss: 0.6824 - val_acc: 0.5556\n",
      "Epoch 113/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.4881 - acc: 0.7485 - val_loss: 0.6777 - val_acc: 0.6296\n",
      "Epoch 114/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.4875 - acc: 0.7485 - val_loss: 0.6844 - val_acc: 0.5556\n",
      "Epoch 115/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.4869 - acc: 0.7485 - val_loss: 0.6781 - val_acc: 0.6296\n",
      "Epoch 116/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.4863 - acc: 0.7485 - val_loss: 0.6870 - val_acc: 0.5556\n",
      "Epoch 117/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.4859 - acc: 0.7485 - val_loss: 0.6781 - val_acc: 0.6296\n",
      "Epoch 118/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.4853 - acc: 0.7485 - val_loss: 0.6868 - val_acc: 0.5556\n",
      "Epoch 119/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.4848 - acc: 0.7485 - val_loss: 0.6755 - val_acc: 0.6296\n",
      "Epoch 120/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.4844 - acc: 0.7485 - val_loss: 0.6890 - val_acc: 0.5556\n",
      "Epoch 121/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 0s 34us/step - loss: 0.4839 - acc: 0.7485 - val_loss: 0.6753 - val_acc: 0.6296\n",
      "Epoch 122/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.4834 - acc: 0.7485 - val_loss: 0.6862 - val_acc: 0.5926\n",
      "Epoch 123/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.4828 - acc: 0.7485 - val_loss: 0.6779 - val_acc: 0.6296\n",
      "Epoch 124/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.4824 - acc: 0.7485 - val_loss: 0.6857 - val_acc: 0.5926\n",
      "Epoch 125/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.4819 - acc: 0.7485 - val_loss: 0.6781 - val_acc: 0.6296\n",
      "Epoch 126/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.4814 - acc: 0.7485 - val_loss: 0.6866 - val_acc: 0.6296\n",
      "Epoch 127/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.4810 - acc: 0.7485 - val_loss: 0.6781 - val_acc: 0.6296\n",
      "Epoch 128/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.4805 - acc: 0.7485 - val_loss: 0.6860 - val_acc: 0.6296\n",
      "Epoch 129/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.4800 - acc: 0.7485 - val_loss: 0.6771 - val_acc: 0.7037\n",
      "Epoch 130/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.4795 - acc: 0.7485 - val_loss: 0.6850 - val_acc: 0.6296\n",
      "Epoch 131/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.4790 - acc: 0.7485 - val_loss: 0.6766 - val_acc: 0.7037\n",
      "Epoch 132/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.4785 - acc: 0.7485 - val_loss: 0.6850 - val_acc: 0.6296\n",
      "Epoch 133/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.4780 - acc: 0.7485 - val_loss: 0.6761 - val_acc: 0.7037\n",
      "Epoch 134/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.4776 - acc: 0.7485 - val_loss: 0.6871 - val_acc: 0.6296\n",
      "Epoch 135/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.4771 - acc: 0.7485 - val_loss: 0.6737 - val_acc: 0.7037\n",
      "Epoch 136/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.4766 - acc: 0.7485 - val_loss: 0.6874 - val_acc: 0.6296\n",
      "Epoch 137/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.4762 - acc: 0.7485 - val_loss: 0.6732 - val_acc: 0.7037\n",
      "Epoch 138/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.4756 - acc: 0.7485 - val_loss: 0.6877 - val_acc: 0.6296\n",
      "Epoch 139/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.4751 - acc: 0.7546 - val_loss: 0.6731 - val_acc: 0.7037\n",
      "Epoch 140/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.4747 - acc: 0.7485 - val_loss: 0.6849 - val_acc: 0.6296\n",
      "Epoch 141/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.4741 - acc: 0.7546 - val_loss: 0.6733 - val_acc: 0.7037\n",
      "Epoch 142/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.4737 - acc: 0.7485 - val_loss: 0.6854 - val_acc: 0.6296\n",
      "Epoch 143/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.4732 - acc: 0.7546 - val_loss: 0.6734 - val_acc: 0.7037\n",
      "Epoch 144/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.4727 - acc: 0.7485 - val_loss: 0.6858 - val_acc: 0.6296\n",
      "Epoch 145/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.4723 - acc: 0.7546 - val_loss: 0.6739 - val_acc: 0.7037\n",
      "Epoch 146/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.4717 - acc: 0.7485 - val_loss: 0.6856 - val_acc: 0.6296\n",
      "Epoch 147/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.4713 - acc: 0.7546 - val_loss: 0.6726 - val_acc: 0.7407\n",
      "Epoch 148/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.4708 - acc: 0.7546 - val_loss: 0.6829 - val_acc: 0.6667\n",
      "Epoch 149/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.4703 - acc: 0.7546 - val_loss: 0.6744 - val_acc: 0.7407\n",
      "Epoch 150/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.4700 - acc: 0.7546 - val_loss: 0.6797 - val_acc: 0.7407\n",
      "Epoch 151/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.4695 - acc: 0.7546 - val_loss: 0.6769 - val_acc: 0.7407\n",
      "Epoch 152/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.4691 - acc: 0.7546 - val_loss: 0.6797 - val_acc: 0.7407\n",
      "Epoch 153/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.4686 - acc: 0.7546 - val_loss: 0.6723 - val_acc: 0.7407\n",
      "Epoch 154/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.4682 - acc: 0.7546 - val_loss: 0.6840 - val_acc: 0.6667\n",
      "Epoch 155/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.4678 - acc: 0.7607 - val_loss: 0.6673 - val_acc: 0.7407\n",
      "Epoch 156/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.4676 - acc: 0.7546 - val_loss: 0.6877 - val_acc: 0.6667\n",
      "Epoch 157/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.4672 - acc: 0.7607 - val_loss: 0.6671 - val_acc: 0.7407\n",
      "Epoch 158/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.4668 - acc: 0.7546 - val_loss: 0.6843 - val_acc: 0.7037\n",
      "Epoch 159/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.4663 - acc: 0.7607 - val_loss: 0.6685 - val_acc: 0.7407\n",
      "Epoch 160/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.4659 - acc: 0.7546 - val_loss: 0.6825 - val_acc: 0.7037\n",
      "Epoch 161/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.4655 - acc: 0.7607 - val_loss: 0.6698 - val_acc: 0.7407\n",
      "Epoch 162/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.4651 - acc: 0.7546 - val_loss: 0.6805 - val_acc: 0.7407\n",
      "Epoch 163/3000\n",
      "163/163 [==============================] - 0s 27us/step - loss: 0.4647 - acc: 0.7607 - val_loss: 0.6693 - val_acc: 0.7407\n",
      "Epoch 164/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.4643 - acc: 0.7546 - val_loss: 0.6809 - val_acc: 0.7407\n",
      "Epoch 165/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.4639 - acc: 0.7607 - val_loss: 0.6696 - val_acc: 0.7407\n",
      "Epoch 166/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.4635 - acc: 0.7546 - val_loss: 0.6801 - val_acc: 0.7407\n",
      "Epoch 167/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.4631 - acc: 0.7607 - val_loss: 0.6675 - val_acc: 0.7407\n",
      "Epoch 168/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.4628 - acc: 0.7546 - val_loss: 0.6802 - val_acc: 0.7037\n",
      "Epoch 169/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.4624 - acc: 0.7607 - val_loss: 0.6666 - val_acc: 0.7407\n",
      "Epoch 170/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.4621 - acc: 0.7607 - val_loss: 0.6787 - val_acc: 0.7037\n",
      "Epoch 171/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.4616 - acc: 0.7607 - val_loss: 0.6684 - val_acc: 0.7407\n",
      "Epoch 172/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.4614 - acc: 0.7607 - val_loss: 0.6779 - val_acc: 0.7407\n",
      "Epoch 173/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.4609 - acc: 0.7607 - val_loss: 0.6686 - val_acc: 0.7407\n",
      "Epoch 174/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.4605 - acc: 0.7607 - val_loss: 0.6770 - val_acc: 0.7407\n",
      "Epoch 175/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.4601 - acc: 0.7607 - val_loss: 0.6690 - val_acc: 0.7407\n",
      "Epoch 176/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.4598 - acc: 0.7607 - val_loss: 0.6771 - val_acc: 0.7407\n",
      "Epoch 177/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.4594 - acc: 0.7669 - val_loss: 0.6671 - val_acc: 0.7407\n",
      "Epoch 178/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.4590 - acc: 0.7607 - val_loss: 0.6763 - val_acc: 0.7407\n",
      "Epoch 179/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.4586 - acc: 0.7669 - val_loss: 0.6672 - val_acc: 0.7407\n",
      "Epoch 180/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.4583 - acc: 0.7607 - val_loss: 0.6758 - val_acc: 0.7407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.4578 - acc: 0.7669 - val_loss: 0.6671 - val_acc: 0.7407\n",
      "Epoch 182/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.4575 - acc: 0.7607 - val_loss: 0.6754 - val_acc: 0.7407\n",
      "Epoch 183/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.4572 - acc: 0.7669 - val_loss: 0.6646 - val_acc: 0.7407\n",
      "Epoch 184/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.4569 - acc: 0.7607 - val_loss: 0.6797 - val_acc: 0.7037\n",
      "Epoch 185/3000\n",
      "163/163 [==============================] - 0s 26us/step - loss: 0.4565 - acc: 0.7669 - val_loss: 0.6576 - val_acc: 0.7407\n",
      "Epoch 186/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.4564 - acc: 0.7607 - val_loss: 0.6793 - val_acc: 0.7037\n",
      "Epoch 187/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.4558 - acc: 0.7607 - val_loss: 0.6637 - val_acc: 0.7407\n",
      "Epoch 188/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.4555 - acc: 0.7607 - val_loss: 0.6741 - val_acc: 0.7407\n",
      "Epoch 189/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.4549 - acc: 0.7669 - val_loss: 0.6641 - val_acc: 0.7407\n",
      "Epoch 190/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.4546 - acc: 0.7607 - val_loss: 0.6746 - val_acc: 0.7407\n",
      "Epoch 191/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.4542 - acc: 0.7669 - val_loss: 0.6628 - val_acc: 0.7407\n",
      "Epoch 192/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.4538 - acc: 0.7669 - val_loss: 0.6736 - val_acc: 0.7407\n",
      "Epoch 193/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.4535 - acc: 0.7607 - val_loss: 0.6626 - val_acc: 0.7407\n",
      "Epoch 194/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.4530 - acc: 0.7669 - val_loss: 0.6742 - val_acc: 0.7407\n",
      "Epoch 195/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.4527 - acc: 0.7607 - val_loss: 0.6612 - val_acc: 0.7407\n",
      "Epoch 196/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.4523 - acc: 0.7669 - val_loss: 0.6744 - val_acc: 0.7407\n",
      "Epoch 197/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.4521 - acc: 0.7669 - val_loss: 0.6601 - val_acc: 0.7407\n",
      "Epoch 198/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.4517 - acc: 0.7669 - val_loss: 0.6754 - val_acc: 0.7407\n",
      "Epoch 199/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.4513 - acc: 0.7669 - val_loss: 0.6598 - val_acc: 0.7407\n",
      "Epoch 200/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.4510 - acc: 0.7730 - val_loss: 0.6770 - val_acc: 0.7407\n",
      "Epoch 201/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.4507 - acc: 0.7669 - val_loss: 0.6593 - val_acc: 0.7407\n",
      "Epoch 202/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.4503 - acc: 0.7730 - val_loss: 0.6754 - val_acc: 0.7407\n",
      "Epoch 203/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.4499 - acc: 0.7669 - val_loss: 0.6603 - val_acc: 0.7407\n",
      "Epoch 204/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.4495 - acc: 0.7669 - val_loss: 0.6738 - val_acc: 0.7407\n",
      "Epoch 205/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.4492 - acc: 0.7669 - val_loss: 0.6626 - val_acc: 0.7407\n",
      "Epoch 206/3000\n",
      "163/163 [==============================] - 0s 27us/step - loss: 0.4487 - acc: 0.7730 - val_loss: 0.6705 - val_acc: 0.7407\n",
      "Epoch 207/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.4484 - acc: 0.7669 - val_loss: 0.6615 - val_acc: 0.7407\n",
      "Epoch 208/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.4481 - acc: 0.7791 - val_loss: 0.6744 - val_acc: 0.7407\n",
      "Epoch 209/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.4478 - acc: 0.7669 - val_loss: 0.6582 - val_acc: 0.7407\n",
      "Epoch 210/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.4475 - acc: 0.7791 - val_loss: 0.6758 - val_acc: 0.7407\n",
      "Epoch 211/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.4472 - acc: 0.7607 - val_loss: 0.6552 - val_acc: 0.7407\n",
      "Epoch 212/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.4470 - acc: 0.7853 - val_loss: 0.6788 - val_acc: 0.7037\n",
      "Epoch 213/3000\n",
      "163/163 [==============================] - 0s 27us/step - loss: 0.4467 - acc: 0.7607 - val_loss: 0.6583 - val_acc: 0.7407\n",
      "Epoch 214/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.4462 - acc: 0.7853 - val_loss: 0.6787 - val_acc: 0.7037\n",
      "Epoch 215/3000\n",
      "163/163 [==============================] - 0s 25us/step - loss: 0.4460 - acc: 0.7607 - val_loss: 0.6574 - val_acc: 0.7407\n",
      "Epoch 216/3000\n",
      "163/163 [==============================] - 0s 27us/step - loss: 0.4456 - acc: 0.7853 - val_loss: 0.6774 - val_acc: 0.7037\n",
      "Epoch 217/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.4452 - acc: 0.7607 - val_loss: 0.6588 - val_acc: 0.7407\n",
      "Epoch 218/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.4448 - acc: 0.7730 - val_loss: 0.6764 - val_acc: 0.7037\n",
      "Epoch 219/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.4445 - acc: 0.7607 - val_loss: 0.6583 - val_acc: 0.7407\n",
      "Epoch 220/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.4443 - acc: 0.7730 - val_loss: 0.6774 - val_acc: 0.7037\n",
      "Epoch 221/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.4439 - acc: 0.7607 - val_loss: 0.6591 - val_acc: 0.7407\n",
      "Epoch 222/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.4436 - acc: 0.7730 - val_loss: 0.6744 - val_acc: 0.7037\n",
      "Epoch 223/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.4432 - acc: 0.7607 - val_loss: 0.6618 - val_acc: 0.7407\n",
      "Epoch 224/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.4428 - acc: 0.7730 - val_loss: 0.6748 - val_acc: 0.7037\n",
      "Epoch 225/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.4425 - acc: 0.7607 - val_loss: 0.6612 - val_acc: 0.7407\n",
      "Epoch 226/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.4421 - acc: 0.7730 - val_loss: 0.6763 - val_acc: 0.6667\n",
      "Epoch 227/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.4418 - acc: 0.7607 - val_loss: 0.6617 - val_acc: 0.7407\n",
      "Epoch 228/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.4414 - acc: 0.7730 - val_loss: 0.6753 - val_acc: 0.6667\n",
      "Epoch 229/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.4411 - acc: 0.7607 - val_loss: 0.6604 - val_acc: 0.7407\n",
      "Epoch 230/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.4407 - acc: 0.7730 - val_loss: 0.6785 - val_acc: 0.6667\n",
      "Epoch 231/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.4406 - acc: 0.7607 - val_loss: 0.6549 - val_acc: 0.7407\n",
      "Epoch 232/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.4403 - acc: 0.7791 - val_loss: 0.6794 - val_acc: 0.6667\n",
      "Epoch 233/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.4399 - acc: 0.7669 - val_loss: 0.6556 - val_acc: 0.7407\n",
      "Epoch 234/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.4396 - acc: 0.7791 - val_loss: 0.6760 - val_acc: 0.7037\n",
      "Epoch 235/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.4391 - acc: 0.7730 - val_loss: 0.6634 - val_acc: 0.7407\n",
      "Epoch 236/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.4387 - acc: 0.7730 - val_loss: 0.6732 - val_acc: 0.7037\n",
      "Epoch 237/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.4383 - acc: 0.7730 - val_loss: 0.6619 - val_acc: 0.7407\n",
      "Epoch 238/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.4380 - acc: 0.7730 - val_loss: 0.6770 - val_acc: 0.7037\n",
      "Epoch 239/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.4377 - acc: 0.7730 - val_loss: 0.6604 - val_acc: 0.7407\n",
      "Epoch 240/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.4376 - acc: 0.7791 - val_loss: 0.6791 - val_acc: 0.7037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.4372 - acc: 0.7730 - val_loss: 0.6571 - val_acc: 0.7407\n",
      "Epoch 242/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.4370 - acc: 0.7791 - val_loss: 0.6794 - val_acc: 0.7037\n",
      "Epoch 243/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.4366 - acc: 0.7730 - val_loss: 0.6604 - val_acc: 0.7407\n",
      "Epoch 244/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.4363 - acc: 0.7791 - val_loss: 0.6772 - val_acc: 0.7037\n",
      "Epoch 245/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.4359 - acc: 0.7730 - val_loss: 0.6640 - val_acc: 0.7407\n",
      "Epoch 246/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.4356 - acc: 0.7730 - val_loss: 0.6755 - val_acc: 0.7037\n",
      "Epoch 247/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.4352 - acc: 0.7730 - val_loss: 0.6654 - val_acc: 0.7407\n",
      "Epoch 248/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.4348 - acc: 0.7730 - val_loss: 0.6741 - val_acc: 0.7037\n",
      "Epoch 249/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.4345 - acc: 0.7669 - val_loss: 0.6659 - val_acc: 0.7407\n",
      "Epoch 250/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.4341 - acc: 0.7730 - val_loss: 0.6782 - val_acc: 0.7037\n",
      "Epoch 251/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.4340 - acc: 0.7730 - val_loss: 0.6582 - val_acc: 0.7407\n",
      "Epoch 252/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.4338 - acc: 0.7791 - val_loss: 0.6836 - val_acc: 0.7037\n",
      "Epoch 253/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.4335 - acc: 0.7791 - val_loss: 0.6561 - val_acc: 0.7407\n",
      "Epoch 254/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.4334 - acc: 0.7791 - val_loss: 0.6830 - val_acc: 0.7037\n",
      "Epoch 255/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.4328 - acc: 0.7791 - val_loss: 0.6620 - val_acc: 0.7407\n",
      "Epoch 256/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.4324 - acc: 0.7730 - val_loss: 0.6798 - val_acc: 0.7037\n",
      "Epoch 257/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.4321 - acc: 0.7730 - val_loss: 0.6645 - val_acc: 0.7407\n",
      "Epoch 258/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.4316 - acc: 0.7730 - val_loss: 0.6788 - val_acc: 0.7037\n",
      "Epoch 259/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.4313 - acc: 0.7669 - val_loss: 0.6665 - val_acc: 0.7407\n",
      "Epoch 260/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.4310 - acc: 0.7730 - val_loss: 0.6787 - val_acc: 0.7037\n",
      "Epoch 261/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.4307 - acc: 0.7669 - val_loss: 0.6653 - val_acc: 0.7407\n",
      "Epoch 262/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.4303 - acc: 0.7730 - val_loss: 0.6816 - val_acc: 0.7037\n",
      "Epoch 263/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.4300 - acc: 0.7669 - val_loss: 0.6620 - val_acc: 0.7407\n",
      "Epoch 264/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.4298 - acc: 0.7669 - val_loss: 0.6849 - val_acc: 0.7037\n",
      "Epoch 265/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.4296 - acc: 0.7730 - val_loss: 0.6593 - val_acc: 0.7407\n",
      "Epoch 266/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.4294 - acc: 0.7730 - val_loss: 0.6851 - val_acc: 0.7037\n",
      "Epoch 267/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.4288 - acc: 0.7730 - val_loss: 0.6649 - val_acc: 0.7407\n",
      "Epoch 268/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.4284 - acc: 0.7730 - val_loss: 0.6828 - val_acc: 0.7037\n",
      "Epoch 269/3000\n",
      "163/163 [==============================] - 0s 26us/step - loss: 0.4279 - acc: 0.7730 - val_loss: 0.6688 - val_acc: 0.7407\n",
      "Epoch 270/3000\n",
      "163/163 [==============================] - 0s 25us/step - loss: 0.4275 - acc: 0.7669 - val_loss: 0.6805 - val_acc: 0.7037\n",
      "Epoch 271/3000\n",
      "163/163 [==============================] - 0s 25us/step - loss: 0.4271 - acc: 0.7669 - val_loss: 0.6707 - val_acc: 0.7407\n",
      "Epoch 272/3000\n",
      "163/163 [==============================] - 0s 26us/step - loss: 0.4268 - acc: 0.7730 - val_loss: 0.6841 - val_acc: 0.7037\n",
      "Epoch 273/3000\n",
      "163/163 [==============================] - 0s 25us/step - loss: 0.4264 - acc: 0.7669 - val_loss: 0.6644 - val_acc: 0.7407\n",
      "Epoch 274/3000\n",
      "163/163 [==============================] - 0s 25us/step - loss: 0.4262 - acc: 0.7730 - val_loss: 0.6879 - val_acc: 0.7037\n",
      "Epoch 275/3000\n",
      "163/163 [==============================] - 0s 26us/step - loss: 0.4258 - acc: 0.7730 - val_loss: 0.6632 - val_acc: 0.7407\n",
      "Epoch 276/3000\n",
      "163/163 [==============================] - 0s 26us/step - loss: 0.4256 - acc: 0.7730 - val_loss: 0.6891 - val_acc: 0.7037\n",
      "Epoch 277/3000\n",
      "163/163 [==============================] - 0s 25us/step - loss: 0.4251 - acc: 0.7730 - val_loss: 0.6635 - val_acc: 0.7407\n",
      "Epoch 278/3000\n",
      "163/163 [==============================] - 0s 25us/step - loss: 0.4250 - acc: 0.7669 - val_loss: 0.6899 - val_acc: 0.7037\n",
      "Epoch 279/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.4244 - acc: 0.7730 - val_loss: 0.6663 - val_acc: 0.7407\n",
      "Epoch 280/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.4240 - acc: 0.7730 - val_loss: 0.6866 - val_acc: 0.7037\n",
      "Epoch 281/3000\n",
      "163/163 [==============================] - 0s 27us/step - loss: 0.4236 - acc: 0.7730 - val_loss: 0.6711 - val_acc: 0.7037\n",
      "Epoch 282/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.4232 - acc: 0.7730 - val_loss: 0.6850 - val_acc: 0.7037\n",
      "Epoch 283/3000\n",
      "163/163 [==============================] - 0s 27us/step - loss: 0.4228 - acc: 0.7730 - val_loss: 0.6697 - val_acc: 0.7407\n",
      "Epoch 284/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.4224 - acc: 0.7730 - val_loss: 0.6877 - val_acc: 0.7037\n",
      "Epoch 285/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.4220 - acc: 0.7730 - val_loss: 0.6698 - val_acc: 0.7407\n",
      "Epoch 286/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.4217 - acc: 0.7730 - val_loss: 0.6888 - val_acc: 0.7037\n",
      "Epoch 287/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.4214 - acc: 0.7730 - val_loss: 0.6679 - val_acc: 0.7407\n",
      "Epoch 288/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.4209 - acc: 0.7669 - val_loss: 0.6915 - val_acc: 0.7037\n",
      "Epoch 289/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.4207 - acc: 0.7791 - val_loss: 0.6628 - val_acc: 0.7407\n",
      "Epoch 290/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.4205 - acc: 0.7730 - val_loss: 0.6946 - val_acc: 0.7037\n",
      "Epoch 291/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.4200 - acc: 0.7791 - val_loss: 0.6658 - val_acc: 0.7407\n",
      "Epoch 292/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.4198 - acc: 0.7730 - val_loss: 0.6932 - val_acc: 0.7037\n",
      "Epoch 293/3000\n",
      "163/163 [==============================] - 0s 25us/step - loss: 0.4192 - acc: 0.7791 - val_loss: 0.6693 - val_acc: 0.7407\n",
      "Epoch 294/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.4187 - acc: 0.7730 - val_loss: 0.6895 - val_acc: 0.7037\n",
      "Epoch 295/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.4182 - acc: 0.7791 - val_loss: 0.6726 - val_acc: 0.7037\n",
      "Epoch 296/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.4177 - acc: 0.7730 - val_loss: 0.6841 - val_acc: 0.7037\n",
      "Epoch 297/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.4173 - acc: 0.7791 - val_loss: 0.6721 - val_acc: 0.7037\n",
      "Epoch 298/3000\n",
      "163/163 [==============================] - 0s 27us/step - loss: 0.4168 - acc: 0.7730 - val_loss: 0.6871 - val_acc: 0.7037\n",
      "Epoch 299/3000\n",
      "163/163 [==============================] - 0s 26us/step - loss: 0.4164 - acc: 0.7853 - val_loss: 0.6675 - val_acc: 0.7037\n",
      "Epoch 300/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.4163 - acc: 0.7791 - val_loss: 0.6934 - val_acc: 0.7037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.4158 - acc: 0.7791 - val_loss: 0.6665 - val_acc: 0.7407\n",
      "Epoch 302/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.4155 - acc: 0.7791 - val_loss: 0.6926 - val_acc: 0.7037\n",
      "Epoch 303/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.4150 - acc: 0.7791 - val_loss: 0.6693 - val_acc: 0.7037\n",
      "Epoch 304/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.4147 - acc: 0.7853 - val_loss: 0.6928 - val_acc: 0.7037\n",
      "Epoch 305/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.4141 - acc: 0.7791 - val_loss: 0.6724 - val_acc: 0.7037\n",
      "Epoch 306/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.4137 - acc: 0.7791 - val_loss: 0.6905 - val_acc: 0.7037\n",
      "Epoch 307/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.4132 - acc: 0.7791 - val_loss: 0.6739 - val_acc: 0.7037\n",
      "Epoch 308/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.4129 - acc: 0.7853 - val_loss: 0.6930 - val_acc: 0.7037\n",
      "Epoch 309/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.4126 - acc: 0.7853 - val_loss: 0.6685 - val_acc: 0.7407\n",
      "Epoch 310/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.4123 - acc: 0.7853 - val_loss: 0.6965 - val_acc: 0.7037\n",
      "Epoch 311/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.4119 - acc: 0.7791 - val_loss: 0.6663 - val_acc: 0.7407\n",
      "Epoch 312/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.4114 - acc: 0.7853 - val_loss: 0.6957 - val_acc: 0.7037\n",
      "Epoch 313/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.4110 - acc: 0.7791 - val_loss: 0.6692 - val_acc: 0.7407\n",
      "Epoch 314/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.4106 - acc: 0.7853 - val_loss: 0.6954 - val_acc: 0.7037\n",
      "Epoch 315/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.4101 - acc: 0.7853 - val_loss: 0.6725 - val_acc: 0.7407\n",
      "Epoch 316/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.4095 - acc: 0.7975 - val_loss: 0.6910 - val_acc: 0.7037\n",
      "Epoch 317/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.4093 - acc: 0.7914 - val_loss: 0.6731 - val_acc: 0.7407\n",
      "Epoch 318/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.4087 - acc: 0.7914 - val_loss: 0.6895 - val_acc: 0.7037\n",
      "Epoch 319/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.4082 - acc: 0.7914 - val_loss: 0.6771 - val_acc: 0.7407\n",
      "Epoch 320/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.4077 - acc: 0.7914 - val_loss: 0.6892 - val_acc: 0.7037\n",
      "Epoch 321/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.4074 - acc: 0.7975 - val_loss: 0.6737 - val_acc: 0.7037\n",
      "Epoch 322/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.4071 - acc: 0.7914 - val_loss: 0.6937 - val_acc: 0.7037\n",
      "Epoch 323/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.4065 - acc: 0.7975 - val_loss: 0.6746 - val_acc: 0.7037\n",
      "Epoch 324/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.4062 - acc: 0.7914 - val_loss: 0.6955 - val_acc: 0.7037\n",
      "Epoch 325/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.4057 - acc: 0.7975 - val_loss: 0.6707 - val_acc: 0.7037\n",
      "Epoch 326/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.4053 - acc: 0.7914 - val_loss: 0.6990 - val_acc: 0.7037\n",
      "Epoch 327/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.4049 - acc: 0.7975 - val_loss: 0.6700 - val_acc: 0.7037\n",
      "Epoch 328/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.4045 - acc: 0.7975 - val_loss: 0.6943 - val_acc: 0.7037\n",
      "Epoch 329/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.4039 - acc: 0.7975 - val_loss: 0.6742 - val_acc: 0.7037\n",
      "Epoch 330/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.4034 - acc: 0.7914 - val_loss: 0.6939 - val_acc: 0.7037\n",
      "Epoch 331/3000\n",
      "163/163 [==============================] - 0s 27us/step - loss: 0.4029 - acc: 0.7975 - val_loss: 0.6728 - val_acc: 0.7037\n",
      "Epoch 332/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.4026 - acc: 0.7914 - val_loss: 0.6948 - val_acc: 0.7037\n",
      "Epoch 333/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.4019 - acc: 0.7975 - val_loss: 0.6724 - val_acc: 0.7037\n",
      "Epoch 334/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.4014 - acc: 0.7914 - val_loss: 0.6960 - val_acc: 0.7037\n",
      "Epoch 335/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.4011 - acc: 0.7975 - val_loss: 0.6714 - val_acc: 0.7037\n",
      "Epoch 336/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.4007 - acc: 0.7975 - val_loss: 0.7015 - val_acc: 0.7037\n",
      "Epoch 337/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.4003 - acc: 0.7975 - val_loss: 0.6695 - val_acc: 0.7037\n",
      "Epoch 338/3000\n",
      "163/163 [==============================] - 0s 26us/step - loss: 0.3998 - acc: 0.7975 - val_loss: 0.7031 - val_acc: 0.7037\n",
      "Epoch 339/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.3996 - acc: 0.8037 - val_loss: 0.6688 - val_acc: 0.7037\n",
      "Epoch 340/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.3992 - acc: 0.7975 - val_loss: 0.7020 - val_acc: 0.7037\n",
      "Epoch 341/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.3985 - acc: 0.8037 - val_loss: 0.6721 - val_acc: 0.7037\n",
      "Epoch 342/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.3980 - acc: 0.8037 - val_loss: 0.6957 - val_acc: 0.7037\n",
      "Epoch 343/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.3973 - acc: 0.7975 - val_loss: 0.6761 - val_acc: 0.7037\n",
      "Epoch 344/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.3969 - acc: 0.8037 - val_loss: 0.6991 - val_acc: 0.6667\n",
      "Epoch 345/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.3965 - acc: 0.7975 - val_loss: 0.6759 - val_acc: 0.7037\n",
      "Epoch 346/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.3959 - acc: 0.8098 - val_loss: 0.6978 - val_acc: 0.7037\n",
      "Epoch 347/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.3955 - acc: 0.8037 - val_loss: 0.6773 - val_acc: 0.7037\n",
      "Epoch 348/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.3950 - acc: 0.8098 - val_loss: 0.7004 - val_acc: 0.6667\n",
      "Epoch 349/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.3947 - acc: 0.8098 - val_loss: 0.6762 - val_acc: 0.7037\n",
      "Epoch 350/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.3941 - acc: 0.8098 - val_loss: 0.6998 - val_acc: 0.6667\n",
      "Epoch 351/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.3936 - acc: 0.8098 - val_loss: 0.6789 - val_acc: 0.7037\n",
      "Epoch 352/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.3931 - acc: 0.8098 - val_loss: 0.6978 - val_acc: 0.7037\n",
      "Epoch 353/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.3924 - acc: 0.8037 - val_loss: 0.6791 - val_acc: 0.7037\n",
      "Epoch 354/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.3920 - acc: 0.8098 - val_loss: 0.7036 - val_acc: 0.6667\n",
      "Epoch 355/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.3917 - acc: 0.8037 - val_loss: 0.6715 - val_acc: 0.7037\n",
      "Epoch 356/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.3913 - acc: 0.8037 - val_loss: 0.7127 - val_acc: 0.6296\n",
      "Epoch 357/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.3912 - acc: 0.8098 - val_loss: 0.6703 - val_acc: 0.7037\n",
      "Epoch 358/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.3907 - acc: 0.8098 - val_loss: 0.7117 - val_acc: 0.6667\n",
      "Epoch 359/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.3901 - acc: 0.8098 - val_loss: 0.6766 - val_acc: 0.7037\n",
      "Epoch 360/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.3891 - acc: 0.8160 - val_loss: 0.7000 - val_acc: 0.7037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.3884 - acc: 0.8037 - val_loss: 0.6845 - val_acc: 0.7037\n",
      "Epoch 362/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.3879 - acc: 0.8160 - val_loss: 0.7002 - val_acc: 0.7037\n",
      "Epoch 363/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.3876 - acc: 0.8098 - val_loss: 0.6832 - val_acc: 0.7037\n",
      "Epoch 364/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.3869 - acc: 0.8160 - val_loss: 0.6980 - val_acc: 0.7037\n",
      "Epoch 365/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.3864 - acc: 0.8098 - val_loss: 0.6836 - val_acc: 0.7037\n",
      "Epoch 366/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.3860 - acc: 0.8160 - val_loss: 0.7019 - val_acc: 0.7037\n",
      "Epoch 367/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.3856 - acc: 0.8037 - val_loss: 0.6735 - val_acc: 0.7037\n",
      "Epoch 368/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.3851 - acc: 0.8160 - val_loss: 0.7077 - val_acc: 0.6296\n",
      "Epoch 369/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.3849 - acc: 0.8098 - val_loss: 0.6682 - val_acc: 0.7037\n",
      "Epoch 370/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.3846 - acc: 0.8098 - val_loss: 0.7104 - val_acc: 0.6296\n",
      "Epoch 371/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.3842 - acc: 0.8160 - val_loss: 0.6686 - val_acc: 0.7037\n",
      "Epoch 372/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.3836 - acc: 0.8098 - val_loss: 0.7050 - val_acc: 0.6667\n",
      "Epoch 373/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.3830 - acc: 0.8098 - val_loss: 0.6715 - val_acc: 0.7037\n",
      "Epoch 374/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.3825 - acc: 0.8098 - val_loss: 0.7020 - val_acc: 0.6667\n",
      "Epoch 375/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.3819 - acc: 0.8098 - val_loss: 0.6713 - val_acc: 0.7037\n",
      "Epoch 376/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.3814 - acc: 0.8098 - val_loss: 0.6987 - val_acc: 0.6667\n",
      "Epoch 377/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.3807 - acc: 0.8098 - val_loss: 0.6760 - val_acc: 0.7037\n",
      "Epoch 378/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.3802 - acc: 0.8160 - val_loss: 0.6986 - val_acc: 0.6667\n",
      "Epoch 379/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.3797 - acc: 0.8160 - val_loss: 0.6715 - val_acc: 0.7037\n",
      "Epoch 380/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.3795 - acc: 0.8098 - val_loss: 0.7035 - val_acc: 0.6667\n",
      "Epoch 381/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.3790 - acc: 0.8160 - val_loss: 0.6674 - val_acc: 0.7037\n",
      "Epoch 382/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.3789 - acc: 0.8160 - val_loss: 0.7080 - val_acc: 0.6296\n",
      "Epoch 383/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.3783 - acc: 0.8160 - val_loss: 0.6660 - val_acc: 0.7037\n",
      "Epoch 384/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.3778 - acc: 0.8098 - val_loss: 0.7057 - val_acc: 0.6667\n",
      "Epoch 385/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.3775 - acc: 0.8160 - val_loss: 0.6689 - val_acc: 0.7037\n",
      "Epoch 386/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.3768 - acc: 0.8160 - val_loss: 0.7026 - val_acc: 0.6667\n",
      "Epoch 387/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.3763 - acc: 0.8160 - val_loss: 0.6731 - val_acc: 0.7037\n",
      "Epoch 388/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.3756 - acc: 0.8098 - val_loss: 0.6962 - val_acc: 0.6667\n",
      "Epoch 389/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.3750 - acc: 0.8221 - val_loss: 0.6772 - val_acc: 0.7037\n",
      "Epoch 390/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.3744 - acc: 0.8160 - val_loss: 0.6963 - val_acc: 0.6667\n",
      "Epoch 391/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.3741 - acc: 0.8221 - val_loss: 0.6741 - val_acc: 0.7037\n",
      "Epoch 392/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.3736 - acc: 0.8160 - val_loss: 0.7021 - val_acc: 0.6667\n",
      "Epoch 393/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.3732 - acc: 0.8221 - val_loss: 0.6686 - val_acc: 0.7037\n",
      "Epoch 394/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.3730 - acc: 0.8282 - val_loss: 0.7113 - val_acc: 0.6296\n",
      "Epoch 395/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.3729 - acc: 0.8282 - val_loss: 0.6631 - val_acc: 0.7037\n",
      "Epoch 396/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.3727 - acc: 0.8405 - val_loss: 0.7139 - val_acc: 0.6296\n",
      "Epoch 397/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.3719 - acc: 0.8282 - val_loss: 0.6703 - val_acc: 0.7037\n",
      "Epoch 398/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.3712 - acc: 0.8344 - val_loss: 0.7047 - val_acc: 0.6296\n",
      "Epoch 399/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.3704 - acc: 0.8344 - val_loss: 0.6815 - val_acc: 0.7037\n",
      "Epoch 400/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.3697 - acc: 0.8160 - val_loss: 0.7018 - val_acc: 0.6296\n",
      "Epoch 401/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.3692 - acc: 0.8282 - val_loss: 0.6801 - val_acc: 0.7037\n",
      "Epoch 402/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.3687 - acc: 0.8282 - val_loss: 0.7062 - val_acc: 0.6296\n",
      "Epoch 403/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.3682 - acc: 0.8282 - val_loss: 0.6747 - val_acc: 0.7037\n",
      "Epoch 404/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.3682 - acc: 0.8344 - val_loss: 0.7119 - val_acc: 0.6296\n",
      "Epoch 405/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.3676 - acc: 0.8344 - val_loss: 0.6700 - val_acc: 0.7037\n",
      "Epoch 406/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.3673 - acc: 0.8405 - val_loss: 0.7181 - val_acc: 0.6296\n",
      "Epoch 407/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.3669 - acc: 0.8282 - val_loss: 0.6717 - val_acc: 0.7037\n",
      "Epoch 408/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.3665 - acc: 0.8405 - val_loss: 0.7148 - val_acc: 0.6296\n",
      "Epoch 409/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.3657 - acc: 0.8344 - val_loss: 0.6771 - val_acc: 0.7037\n",
      "Epoch 410/3000\n",
      "163/163 [==============================] - 0s 26us/step - loss: 0.3653 - acc: 0.8405 - val_loss: 0.7140 - val_acc: 0.6296\n",
      "Epoch 411/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.3648 - acc: 0.8405 - val_loss: 0.6782 - val_acc: 0.7037\n",
      "Epoch 412/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.3642 - acc: 0.8405 - val_loss: 0.7129 - val_acc: 0.6296\n",
      "Epoch 413/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.3636 - acc: 0.8405 - val_loss: 0.6785 - val_acc: 0.7037\n",
      "Epoch 414/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.3635 - acc: 0.8528 - val_loss: 0.7183 - val_acc: 0.6296\n",
      "Epoch 415/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.3631 - acc: 0.8405 - val_loss: 0.6760 - val_acc: 0.7037\n",
      "Epoch 416/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.3631 - acc: 0.8466 - val_loss: 0.7186 - val_acc: 0.6296\n",
      "Epoch 417/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.3625 - acc: 0.8405 - val_loss: 0.6786 - val_acc: 0.7037\n",
      "Epoch 418/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.3619 - acc: 0.8528 - val_loss: 0.7176 - val_acc: 0.6296\n",
      "Epoch 419/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.3613 - acc: 0.8466 - val_loss: 0.6793 - val_acc: 0.7037\n",
      "Epoch 420/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.3608 - acc: 0.8466 - val_loss: 0.7163 - val_acc: 0.6296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.3606 - acc: 0.8466 - val_loss: 0.6784 - val_acc: 0.7407\n",
      "Epoch 422/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.3602 - acc: 0.8466 - val_loss: 0.7173 - val_acc: 0.6296\n",
      "Epoch 423/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.3596 - acc: 0.8466 - val_loss: 0.6826 - val_acc: 0.7037\n",
      "Epoch 424/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.3590 - acc: 0.8528 - val_loss: 0.7176 - val_acc: 0.6296\n",
      "Epoch 425/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.3587 - acc: 0.8466 - val_loss: 0.6780 - val_acc: 0.7407\n",
      "Epoch 426/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.3586 - acc: 0.8528 - val_loss: 0.7208 - val_acc: 0.6296\n",
      "Epoch 427/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.3579 - acc: 0.8466 - val_loss: 0.6783 - val_acc: 0.7407\n",
      "Epoch 428/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.3576 - acc: 0.8528 - val_loss: 0.7194 - val_acc: 0.6296\n",
      "Epoch 429/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.3572 - acc: 0.8466 - val_loss: 0.6780 - val_acc: 0.7407\n",
      "Epoch 430/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.3568 - acc: 0.8528 - val_loss: 0.7199 - val_acc: 0.6296\n",
      "Epoch 431/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.3563 - acc: 0.8466 - val_loss: 0.6770 - val_acc: 0.7407\n",
      "Epoch 432/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.3564 - acc: 0.8528 - val_loss: 0.7244 - val_acc: 0.6296\n",
      "Epoch 433/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.3558 - acc: 0.8466 - val_loss: 0.6811 - val_acc: 0.7407\n",
      "Epoch 434/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.3549 - acc: 0.8528 - val_loss: 0.7145 - val_acc: 0.6667\n",
      "Epoch 435/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.3542 - acc: 0.8466 - val_loss: 0.6856 - val_acc: 0.7407\n",
      "Epoch 436/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.3537 - acc: 0.8466 - val_loss: 0.7153 - val_acc: 0.7037\n",
      "Epoch 437/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.3533 - acc: 0.8528 - val_loss: 0.6842 - val_acc: 0.7407\n",
      "Epoch 438/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.3528 - acc: 0.8528 - val_loss: 0.7205 - val_acc: 0.6296\n",
      "Epoch 439/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.3529 - acc: 0.8466 - val_loss: 0.6769 - val_acc: 0.7407\n",
      "Epoch 440/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.3525 - acc: 0.8528 - val_loss: 0.7256 - val_acc: 0.6296\n",
      "Epoch 441/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.3521 - acc: 0.8466 - val_loss: 0.6746 - val_acc: 0.7407\n",
      "Epoch 442/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.3520 - acc: 0.8528 - val_loss: 0.7273 - val_acc: 0.6296\n",
      "Epoch 443/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.3515 - acc: 0.8466 - val_loss: 0.6749 - val_acc: 0.7407\n",
      "Epoch 444/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.3509 - acc: 0.8466 - val_loss: 0.7226 - val_acc: 0.6667\n",
      "Epoch 445/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.3499 - acc: 0.8466 - val_loss: 0.6823 - val_acc: 0.7407\n",
      "Epoch 446/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.3494 - acc: 0.8528 - val_loss: 0.7155 - val_acc: 0.6667\n",
      "Epoch 447/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.3487 - acc: 0.8589 - val_loss: 0.6850 - val_acc: 0.7407\n",
      "Epoch 448/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.3481 - acc: 0.8589 - val_loss: 0.7121 - val_acc: 0.7407\n",
      "Epoch 449/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.3476 - acc: 0.8589 - val_loss: 0.6905 - val_acc: 0.7407\n",
      "Epoch 450/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.3471 - acc: 0.8589 - val_loss: 0.7127 - val_acc: 0.7407\n",
      "Epoch 451/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.3468 - acc: 0.8589 - val_loss: 0.6853 - val_acc: 0.7407\n",
      "Epoch 452/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.3464 - acc: 0.8650 - val_loss: 0.7193 - val_acc: 0.7037\n",
      "Epoch 453/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.3464 - acc: 0.8589 - val_loss: 0.6749 - val_acc: 0.7407\n",
      "Epoch 454/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.3460 - acc: 0.8589 - val_loss: 0.7341 - val_acc: 0.6667\n",
      "Epoch 455/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.3462 - acc: 0.8528 - val_loss: 0.6663 - val_acc: 0.7407\n",
      "Epoch 456/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.3460 - acc: 0.8528 - val_loss: 0.7364 - val_acc: 0.6667\n",
      "Epoch 457/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.3456 - acc: 0.8405 - val_loss: 0.6721 - val_acc: 0.7407\n",
      "Epoch 458/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.3443 - acc: 0.8528 - val_loss: 0.7252 - val_acc: 0.7037\n",
      "Epoch 459/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.3435 - acc: 0.8589 - val_loss: 0.6786 - val_acc: 0.7407\n",
      "Epoch 460/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.3430 - acc: 0.8589 - val_loss: 0.7214 - val_acc: 0.7037\n",
      "Epoch 461/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.3424 - acc: 0.8528 - val_loss: 0.6809 - val_acc: 0.7407\n",
      "Epoch 462/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.3416 - acc: 0.8589 - val_loss: 0.7207 - val_acc: 0.7037\n",
      "Epoch 463/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.3412 - acc: 0.8528 - val_loss: 0.6811 - val_acc: 0.7407\n",
      "Epoch 464/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.3408 - acc: 0.8589 - val_loss: 0.7233 - val_acc: 0.7037\n",
      "Epoch 465/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.3404 - acc: 0.8528 - val_loss: 0.6802 - val_acc: 0.7407\n",
      "Epoch 466/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.3400 - acc: 0.8589 - val_loss: 0.7285 - val_acc: 0.7037\n",
      "Epoch 467/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.3397 - acc: 0.8528 - val_loss: 0.6757 - val_acc: 0.7407\n",
      "Epoch 468/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.3393 - acc: 0.8589 - val_loss: 0.7315 - val_acc: 0.6667\n",
      "Epoch 469/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.3391 - acc: 0.8589 - val_loss: 0.6765 - val_acc: 0.7407\n",
      "Epoch 470/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.3387 - acc: 0.8589 - val_loss: 0.7321 - val_acc: 0.7037\n",
      "Epoch 471/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.3381 - acc: 0.8589 - val_loss: 0.6797 - val_acc: 0.7407\n",
      "Epoch 472/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.3376 - acc: 0.8650 - val_loss: 0.7289 - val_acc: 0.7037\n",
      "Epoch 473/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.3370 - acc: 0.8589 - val_loss: 0.6814 - val_acc: 0.7407\n",
      "Epoch 474/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.3366 - acc: 0.8650 - val_loss: 0.7307 - val_acc: 0.7037\n",
      "Epoch 475/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.3363 - acc: 0.8650 - val_loss: 0.6822 - val_acc: 0.7407\n",
      "Epoch 476/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.3356 - acc: 0.8650 - val_loss: 0.7305 - val_acc: 0.7037\n",
      "Epoch 477/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.3352 - acc: 0.8650 - val_loss: 0.6825 - val_acc: 0.7407\n",
      "Epoch 478/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.3348 - acc: 0.8650 - val_loss: 0.7319 - val_acc: 0.6667\n",
      "Epoch 479/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.3344 - acc: 0.8589 - val_loss: 0.6839 - val_acc: 0.7407\n",
      "Epoch 480/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.3344 - acc: 0.8650 - val_loss: 0.7353 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.3340 - acc: 0.8650 - val_loss: 0.6836 - val_acc: 0.7407\n",
      "Epoch 482/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.3332 - acc: 0.8650 - val_loss: 0.7347 - val_acc: 0.6667\n",
      "Epoch 483/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.3330 - acc: 0.8650 - val_loss: 0.6865 - val_acc: 0.7407\n",
      "Epoch 484/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.3326 - acc: 0.8650 - val_loss: 0.7317 - val_acc: 0.6667\n",
      "Epoch 485/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.3320 - acc: 0.8650 - val_loss: 0.6854 - val_acc: 0.7407\n",
      "Epoch 486/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.3316 - acc: 0.8650 - val_loss: 0.7365 - val_acc: 0.6667\n",
      "Epoch 487/3000\n",
      "163/163 [==============================] - 0s 55us/step - loss: 0.3313 - acc: 0.8650 - val_loss: 0.6844 - val_acc: 0.7407\n",
      "Epoch 488/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.3309 - acc: 0.8650 - val_loss: 0.7394 - val_acc: 0.6667\n",
      "Epoch 489/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.3305 - acc: 0.8650 - val_loss: 0.6866 - val_acc: 0.7407\n",
      "Epoch 490/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.3299 - acc: 0.8773 - val_loss: 0.7383 - val_acc: 0.6296\n",
      "Epoch 491/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.3294 - acc: 0.8650 - val_loss: 0.6866 - val_acc: 0.7407\n",
      "Epoch 492/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.3296 - acc: 0.8712 - val_loss: 0.7425 - val_acc: 0.6667\n",
      "Epoch 493/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.3289 - acc: 0.8650 - val_loss: 0.6905 - val_acc: 0.7407\n",
      "Epoch 494/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.3284 - acc: 0.8773 - val_loss: 0.7392 - val_acc: 0.6296\n",
      "Epoch 495/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.3281 - acc: 0.8650 - val_loss: 0.6881 - val_acc: 0.7407\n",
      "Epoch 496/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.3278 - acc: 0.8712 - val_loss: 0.7448 - val_acc: 0.6296\n",
      "Epoch 497/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.3275 - acc: 0.8650 - val_loss: 0.6874 - val_acc: 0.7407\n",
      "Epoch 498/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.3269 - acc: 0.8712 - val_loss: 0.7421 - val_acc: 0.6296\n",
      "Epoch 499/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.3262 - acc: 0.8650 - val_loss: 0.6881 - val_acc: 0.7407\n",
      "Epoch 500/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.3261 - acc: 0.8773 - val_loss: 0.7443 - val_acc: 0.6296\n",
      "Epoch 501/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.3257 - acc: 0.8650 - val_loss: 0.6880 - val_acc: 0.7407\n",
      "Epoch 502/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.3252 - acc: 0.8712 - val_loss: 0.7436 - val_acc: 0.6296\n",
      "Epoch 503/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.3249 - acc: 0.8650 - val_loss: 0.6881 - val_acc: 0.7407\n",
      "Epoch 504/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.3244 - acc: 0.8712 - val_loss: 0.7432 - val_acc: 0.6296\n",
      "Epoch 505/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.3241 - acc: 0.8650 - val_loss: 0.6929 - val_acc: 0.7407\n",
      "Epoch 506/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.3236 - acc: 0.8773 - val_loss: 0.7430 - val_acc: 0.6667\n",
      "Epoch 507/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.3232 - acc: 0.8650 - val_loss: 0.6925 - val_acc: 0.7407\n",
      "Epoch 508/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.3229 - acc: 0.8712 - val_loss: 0.7454 - val_acc: 0.6667\n",
      "Epoch 509/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.3226 - acc: 0.8650 - val_loss: 0.6897 - val_acc: 0.7407\n",
      "Epoch 510/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.3223 - acc: 0.8712 - val_loss: 0.7465 - val_acc: 0.6667\n",
      "Epoch 511/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.3218 - acc: 0.8650 - val_loss: 0.6928 - val_acc: 0.7407\n",
      "Epoch 512/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.3213 - acc: 0.8712 - val_loss: 0.7477 - val_acc: 0.6667\n",
      "Epoch 513/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.3208 - acc: 0.8650 - val_loss: 0.6926 - val_acc: 0.7407\n",
      "Epoch 514/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.3207 - acc: 0.8712 - val_loss: 0.7483 - val_acc: 0.6667\n",
      "Epoch 515/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.3202 - acc: 0.8650 - val_loss: 0.6912 - val_acc: 0.7407\n",
      "Epoch 516/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.3199 - acc: 0.8712 - val_loss: 0.7515 - val_acc: 0.6667\n",
      "Epoch 517/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.3195 - acc: 0.8650 - val_loss: 0.6918 - val_acc: 0.7407\n",
      "Epoch 518/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.3192 - acc: 0.8834 - val_loss: 0.7503 - val_acc: 0.6667\n",
      "Epoch 519/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.3186 - acc: 0.8650 - val_loss: 0.6937 - val_acc: 0.7407\n",
      "Epoch 520/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.3181 - acc: 0.8834 - val_loss: 0.7500 - val_acc: 0.6667\n",
      "Epoch 521/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.3175 - acc: 0.8650 - val_loss: 0.6956 - val_acc: 0.7407\n",
      "Epoch 522/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.3172 - acc: 0.8834 - val_loss: 0.7493 - val_acc: 0.6667\n",
      "Epoch 523/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.3169 - acc: 0.8650 - val_loss: 0.6962 - val_acc: 0.7407\n",
      "Epoch 524/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.3165 - acc: 0.8834 - val_loss: 0.7512 - val_acc: 0.6667\n",
      "Epoch 525/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.3165 - acc: 0.8650 - val_loss: 0.6942 - val_acc: 0.7407\n",
      "Epoch 526/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.3161 - acc: 0.8834 - val_loss: 0.7546 - val_acc: 0.6296\n",
      "Epoch 527/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.3154 - acc: 0.8650 - val_loss: 0.6973 - val_acc: 0.7407\n",
      "Epoch 528/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.3152 - acc: 0.8834 - val_loss: 0.7547 - val_acc: 0.6296\n",
      "Epoch 529/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.3146 - acc: 0.8650 - val_loss: 0.6955 - val_acc: 0.7407\n",
      "Epoch 530/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.3140 - acc: 0.8834 - val_loss: 0.7547 - val_acc: 0.6296\n",
      "Epoch 531/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.3138 - acc: 0.8650 - val_loss: 0.6971 - val_acc: 0.7407\n",
      "Epoch 532/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.3131 - acc: 0.8834 - val_loss: 0.7541 - val_acc: 0.6296\n",
      "Epoch 533/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.3129 - acc: 0.8712 - val_loss: 0.6976 - val_acc: 0.7037\n",
      "Epoch 534/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.3126 - acc: 0.8896 - val_loss: 0.7560 - val_acc: 0.6296\n",
      "Epoch 535/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.3125 - acc: 0.8712 - val_loss: 0.6966 - val_acc: 0.7037\n",
      "Epoch 536/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.3121 - acc: 0.8896 - val_loss: 0.7577 - val_acc: 0.6296\n",
      "Epoch 537/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.3115 - acc: 0.8712 - val_loss: 0.6976 - val_acc: 0.7037\n",
      "Epoch 538/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.3113 - acc: 0.8834 - val_loss: 0.7557 - val_acc: 0.6296\n",
      "Epoch 539/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.3107 - acc: 0.8650 - val_loss: 0.6949 - val_acc: 0.7407\n",
      "Epoch 540/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.3104 - acc: 0.8896 - val_loss: 0.7566 - val_acc: 0.6296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 541/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.3102 - acc: 0.8773 - val_loss: 0.6977 - val_acc: 0.7037\n",
      "Epoch 542/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.3097 - acc: 0.8896 - val_loss: 0.7557 - val_acc: 0.6296\n",
      "Epoch 543/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.3090 - acc: 0.8773 - val_loss: 0.6986 - val_acc: 0.7037\n",
      "Epoch 544/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.3091 - acc: 0.8896 - val_loss: 0.7569 - val_acc: 0.6296\n",
      "Epoch 545/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.3084 - acc: 0.8773 - val_loss: 0.7028 - val_acc: 0.7037\n",
      "Epoch 546/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.3079 - acc: 0.8896 - val_loss: 0.7583 - val_acc: 0.6296\n",
      "Epoch 547/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.3074 - acc: 0.8773 - val_loss: 0.7014 - val_acc: 0.7037\n",
      "Epoch 548/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.3071 - acc: 0.8896 - val_loss: 0.7593 - val_acc: 0.6667\n",
      "Epoch 549/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.3066 - acc: 0.8650 - val_loss: 0.6982 - val_acc: 0.7037\n",
      "Epoch 550/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.3066 - acc: 0.8896 - val_loss: 0.7624 - val_acc: 0.6296\n",
      "Epoch 551/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.3066 - acc: 0.8773 - val_loss: 0.6978 - val_acc: 0.7037\n",
      "Epoch 552/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.3064 - acc: 0.8896 - val_loss: 0.7615 - val_acc: 0.6296\n",
      "Epoch 553/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.3054 - acc: 0.8773 - val_loss: 0.6981 - val_acc: 0.7037\n",
      "Epoch 554/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.3052 - acc: 0.8896 - val_loss: 0.7641 - val_acc: 0.6296\n",
      "Epoch 555/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.3049 - acc: 0.8589 - val_loss: 0.6969 - val_acc: 0.7037\n",
      "Epoch 556/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.3044 - acc: 0.8896 - val_loss: 0.7608 - val_acc: 0.6667\n",
      "Epoch 557/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.3036 - acc: 0.8773 - val_loss: 0.7038 - val_acc: 0.7037\n",
      "Epoch 558/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.3033 - acc: 0.8896 - val_loss: 0.7558 - val_acc: 0.6667\n",
      "Epoch 559/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.3026 - acc: 0.8773 - val_loss: 0.7106 - val_acc: 0.7037\n",
      "Epoch 560/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.3022 - acc: 0.8896 - val_loss: 0.7589 - val_acc: 0.6667\n",
      "Epoch 561/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.3017 - acc: 0.8773 - val_loss: 0.7065 - val_acc: 0.7037\n",
      "Epoch 562/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.3016 - acc: 0.8896 - val_loss: 0.7624 - val_acc: 0.6667\n",
      "Epoch 563/3000\n",
      "163/163 [==============================] - 0s 53us/step - loss: 0.3012 - acc: 0.8712 - val_loss: 0.7001 - val_acc: 0.7037\n",
      "Epoch 564/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.3013 - acc: 0.8896 - val_loss: 0.7687 - val_acc: 0.6296\n",
      "Epoch 565/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.3014 - acc: 0.8712 - val_loss: 0.6992 - val_acc: 0.7037\n",
      "Epoch 566/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.3008 - acc: 0.8896 - val_loss: 0.7686 - val_acc: 0.6296\n",
      "Epoch 567/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.3000 - acc: 0.8712 - val_loss: 0.7018 - val_acc: 0.7037\n",
      "Epoch 568/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.2999 - acc: 0.8896 - val_loss: 0.7671 - val_acc: 0.6667\n",
      "Epoch 569/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.2996 - acc: 0.8712 - val_loss: 0.7103 - val_acc: 0.7037\n",
      "Epoch 570/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.2984 - acc: 0.8896 - val_loss: 0.7611 - val_acc: 0.6667\n",
      "Epoch 571/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.2979 - acc: 0.8773 - val_loss: 0.7100 - val_acc: 0.7037\n",
      "Epoch 572/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.2974 - acc: 0.8896 - val_loss: 0.7614 - val_acc: 0.6667\n",
      "Epoch 573/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.2972 - acc: 0.8773 - val_loss: 0.7081 - val_acc: 0.7037\n",
      "Epoch 574/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.2970 - acc: 0.8896 - val_loss: 0.7636 - val_acc: 0.6296\n",
      "Epoch 575/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.2967 - acc: 0.8773 - val_loss: 0.7043 - val_acc: 0.7037\n",
      "Epoch 576/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.2965 - acc: 0.8896 - val_loss: 0.7728 - val_acc: 0.6667\n",
      "Epoch 577/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.2968 - acc: 0.8650 - val_loss: 0.6985 - val_acc: 0.7037\n",
      "Epoch 578/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.2966 - acc: 0.8896 - val_loss: 0.7728 - val_acc: 0.6296\n",
      "Epoch 579/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.2959 - acc: 0.8712 - val_loss: 0.7037 - val_acc: 0.7037\n",
      "Epoch 580/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.2954 - acc: 0.8896 - val_loss: 0.7678 - val_acc: 0.6667\n",
      "Epoch 581/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.2947 - acc: 0.8712 - val_loss: 0.7153 - val_acc: 0.7037\n",
      "Epoch 582/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.2943 - acc: 0.8896 - val_loss: 0.7631 - val_acc: 0.6667\n",
      "Epoch 583/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.2933 - acc: 0.8834 - val_loss: 0.7172 - val_acc: 0.6667\n",
      "Epoch 584/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.2929 - acc: 0.8896 - val_loss: 0.7629 - val_acc: 0.6667\n",
      "Epoch 585/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.2923 - acc: 0.8773 - val_loss: 0.7117 - val_acc: 0.7037\n",
      "Epoch 586/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.2927 - acc: 0.8896 - val_loss: 0.7731 - val_acc: 0.6296\n",
      "Epoch 587/3000\n",
      "163/163 [==============================] - 0s 56us/step - loss: 0.2929 - acc: 0.8712 - val_loss: 0.7009 - val_acc: 0.7037\n",
      "Epoch 588/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.2931 - acc: 0.8896 - val_loss: 0.7827 - val_acc: 0.6667\n",
      "Epoch 589/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.2935 - acc: 0.8712 - val_loss: 0.7075 - val_acc: 0.7037\n",
      "Epoch 590/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.2923 - acc: 0.8896 - val_loss: 0.7764 - val_acc: 0.6667\n",
      "Epoch 591/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.2919 - acc: 0.8712 - val_loss: 0.7161 - val_acc: 0.7037\n",
      "Epoch 592/3000\n",
      "163/163 [==============================] - 0s 58us/step - loss: 0.2907 - acc: 0.8896 - val_loss: 0.7706 - val_acc: 0.6667\n",
      "Epoch 593/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.2901 - acc: 0.8773 - val_loss: 0.7173 - val_acc: 0.6667\n",
      "Epoch 594/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.2894 - acc: 0.8896 - val_loss: 0.7701 - val_acc: 0.6667\n",
      "Epoch 595/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.2893 - acc: 0.8712 - val_loss: 0.7108 - val_acc: 0.6667\n",
      "Epoch 596/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.2894 - acc: 0.8896 - val_loss: 0.7781 - val_acc: 0.6667\n",
      "Epoch 597/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.2896 - acc: 0.8712 - val_loss: 0.7086 - val_acc: 0.7037\n",
      "Epoch 598/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.2893 - acc: 0.8896 - val_loss: 0.7813 - val_acc: 0.6667\n",
      "Epoch 599/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.2897 - acc: 0.8712 - val_loss: 0.7122 - val_acc: 0.6667\n",
      "Epoch 600/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.2883 - acc: 0.8896 - val_loss: 0.7758 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 601/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2880 - acc: 0.8773 - val_loss: 0.7182 - val_acc: 0.7037\n",
      "Epoch 602/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.2872 - acc: 0.8896 - val_loss: 0.7754 - val_acc: 0.6667\n",
      "Epoch 603/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.2871 - acc: 0.8712 - val_loss: 0.7128 - val_acc: 0.6667\n",
      "Epoch 604/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.2869 - acc: 0.8896 - val_loss: 0.7792 - val_acc: 0.6667\n",
      "Epoch 605/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.2864 - acc: 0.8712 - val_loss: 0.7124 - val_acc: 0.6667\n",
      "Epoch 606/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.2863 - acc: 0.8896 - val_loss: 0.7818 - val_acc: 0.6667\n",
      "Epoch 607/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.2866 - acc: 0.8650 - val_loss: 0.7102 - val_acc: 0.6667\n",
      "Epoch 608/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.2861 - acc: 0.8896 - val_loss: 0.7826 - val_acc: 0.6667\n",
      "Epoch 609/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2861 - acc: 0.8773 - val_loss: 0.7182 - val_acc: 0.6667\n",
      "Epoch 610/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.2850 - acc: 0.8896 - val_loss: 0.7789 - val_acc: 0.6667\n",
      "Epoch 611/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.2845 - acc: 0.8712 - val_loss: 0.7210 - val_acc: 0.6667\n",
      "Epoch 612/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.2841 - acc: 0.8896 - val_loss: 0.7813 - val_acc: 0.6667\n",
      "Epoch 613/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.2840 - acc: 0.8712 - val_loss: 0.7206 - val_acc: 0.6667\n",
      "Epoch 614/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.2837 - acc: 0.8896 - val_loss: 0.7845 - val_acc: 0.6667\n",
      "Epoch 615/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2836 - acc: 0.8650 - val_loss: 0.7142 - val_acc: 0.6667\n",
      "Epoch 616/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.2831 - acc: 0.8896 - val_loss: 0.7847 - val_acc: 0.6667\n",
      "Epoch 617/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.2828 - acc: 0.8712 - val_loss: 0.7165 - val_acc: 0.6667\n",
      "Epoch 618/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.2831 - acc: 0.8896 - val_loss: 0.7905 - val_acc: 0.6667\n",
      "Epoch 619/3000\n",
      "163/163 [==============================] - 0s 54us/step - loss: 0.2833 - acc: 0.8650 - val_loss: 0.7195 - val_acc: 0.6667\n",
      "Epoch 620/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2818 - acc: 0.8896 - val_loss: 0.7842 - val_acc: 0.6667\n",
      "Epoch 621/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.2816 - acc: 0.8712 - val_loss: 0.7289 - val_acc: 0.6667\n",
      "Epoch 622/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.2808 - acc: 0.8896 - val_loss: 0.7811 - val_acc: 0.6667\n",
      "Epoch 623/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.2806 - acc: 0.8712 - val_loss: 0.7207 - val_acc: 0.6667\n",
      "Epoch 624/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.2808 - acc: 0.8896 - val_loss: 0.7895 - val_acc: 0.6667\n",
      "Epoch 625/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.2811 - acc: 0.8650 - val_loss: 0.7184 - val_acc: 0.6667\n",
      "Epoch 626/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.2807 - acc: 0.8896 - val_loss: 0.7904 - val_acc: 0.6667\n",
      "Epoch 627/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.2801 - acc: 0.8650 - val_loss: 0.7248 - val_acc: 0.6667\n",
      "Epoch 628/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.2794 - acc: 0.8896 - val_loss: 0.7901 - val_acc: 0.6667\n",
      "Epoch 629/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.2792 - acc: 0.8650 - val_loss: 0.7204 - val_acc: 0.6667\n",
      "Epoch 630/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.2788 - acc: 0.8896 - val_loss: 0.7919 - val_acc: 0.6667\n",
      "Epoch 631/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.2787 - acc: 0.8650 - val_loss: 0.7249 - val_acc: 0.6667\n",
      "Epoch 632/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.2785 - acc: 0.8896 - val_loss: 0.7897 - val_acc: 0.6667\n",
      "Epoch 633/3000\n",
      "163/163 [==============================] - 0s 74us/step - loss: 0.2791 - acc: 0.8650 - val_loss: 0.7306 - val_acc: 0.6667\n",
      "Epoch 634/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.2774 - acc: 0.8896 - val_loss: 0.7938 - val_acc: 0.6667\n",
      "Epoch 635/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.2776 - acc: 0.8650 - val_loss: 0.7229 - val_acc: 0.6667\n",
      "Epoch 636/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.2772 - acc: 0.8896 - val_loss: 0.7990 - val_acc: 0.6667\n",
      "Epoch 637/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.2777 - acc: 0.8650 - val_loss: 0.7208 - val_acc: 0.6667\n",
      "Epoch 638/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2772 - acc: 0.8957 - val_loss: 0.7967 - val_acc: 0.6667\n",
      "Epoch 639/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.2771 - acc: 0.8650 - val_loss: 0.7241 - val_acc: 0.6667\n",
      "Epoch 640/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.2759 - acc: 0.8896 - val_loss: 0.7919 - val_acc: 0.6667\n",
      "Epoch 641/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.2755 - acc: 0.8650 - val_loss: 0.7273 - val_acc: 0.6667\n",
      "Epoch 642/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.2755 - acc: 0.8896 - val_loss: 0.7962 - val_acc: 0.6667\n",
      "Epoch 643/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.2762 - acc: 0.8650 - val_loss: 0.7303 - val_acc: 0.6667\n",
      "Epoch 644/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.2747 - acc: 0.8896 - val_loss: 0.7950 - val_acc: 0.6667\n",
      "Epoch 645/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.2746 - acc: 0.8650 - val_loss: 0.7273 - val_acc: 0.6667\n",
      "Epoch 646/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.2748 - acc: 0.8896 - val_loss: 0.7968 - val_acc: 0.6667\n",
      "Epoch 647/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2745 - acc: 0.8650 - val_loss: 0.7301 - val_acc: 0.6667\n",
      "Epoch 648/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.2734 - acc: 0.8896 - val_loss: 0.7938 - val_acc: 0.6667\n",
      "Epoch 649/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.2734 - acc: 0.8650 - val_loss: 0.7287 - val_acc: 0.6667\n",
      "Epoch 650/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.2732 - acc: 0.8896 - val_loss: 0.8021 - val_acc: 0.6667\n",
      "Epoch 651/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.2742 - acc: 0.8650 - val_loss: 0.7291 - val_acc: 0.6667\n",
      "Epoch 652/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.2732 - acc: 0.8896 - val_loss: 0.8024 - val_acc: 0.6667\n",
      "Epoch 653/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.2732 - acc: 0.8650 - val_loss: 0.7319 - val_acc: 0.6667\n",
      "Epoch 654/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.2722 - acc: 0.8896 - val_loss: 0.7987 - val_acc: 0.6667\n",
      "Epoch 655/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.2718 - acc: 0.8650 - val_loss: 0.7296 - val_acc: 0.6667\n",
      "Epoch 656/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.2716 - acc: 0.8896 - val_loss: 0.8025 - val_acc: 0.6667\n",
      "Epoch 657/3000\n",
      "163/163 [==============================] - 0s 54us/step - loss: 0.2721 - acc: 0.8650 - val_loss: 0.7280 - val_acc: 0.6667\n",
      "Epoch 658/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.2720 - acc: 0.8957 - val_loss: 0.8061 - val_acc: 0.6667\n",
      "Epoch 659/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.2722 - acc: 0.8650 - val_loss: 0.7359 - val_acc: 0.6667\n",
      "Epoch 660/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.2705 - acc: 0.8896 - val_loss: 0.7944 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 661/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.2698 - acc: 0.8650 - val_loss: 0.7429 - val_acc: 0.6667\n",
      "Epoch 662/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.2696 - acc: 0.8896 - val_loss: 0.8010 - val_acc: 0.6667\n",
      "Epoch 663/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.2700 - acc: 0.8712 - val_loss: 0.7311 - val_acc: 0.6667\n",
      "Epoch 664/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.2698 - acc: 0.8957 - val_loss: 0.8066 - val_acc: 0.6667\n",
      "Epoch 665/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2701 - acc: 0.8650 - val_loss: 0.7302 - val_acc: 0.6667\n",
      "Epoch 666/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2696 - acc: 0.8896 - val_loss: 0.8137 - val_acc: 0.6667\n",
      "Epoch 667/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2702 - acc: 0.8650 - val_loss: 0.7345 - val_acc: 0.6667\n",
      "Epoch 668/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.2692 - acc: 0.8957 - val_loss: 0.8108 - val_acc: 0.6667\n",
      "Epoch 669/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.2695 - acc: 0.8650 - val_loss: 0.7373 - val_acc: 0.6667\n",
      "Epoch 670/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.2681 - acc: 0.8957 - val_loss: 0.8105 - val_acc: 0.6667\n",
      "Epoch 671/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.2685 - acc: 0.8650 - val_loss: 0.7379 - val_acc: 0.6667\n",
      "Epoch 672/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.2674 - acc: 0.8896 - val_loss: 0.8075 - val_acc: 0.6667\n",
      "Epoch 673/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.2680 - acc: 0.8650 - val_loss: 0.7372 - val_acc: 0.6667\n",
      "Epoch 674/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.2671 - acc: 0.8896 - val_loss: 0.8083 - val_acc: 0.6667\n",
      "Epoch 675/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.2673 - acc: 0.8650 - val_loss: 0.7364 - val_acc: 0.6667\n",
      "Epoch 676/3000\n",
      "163/163 [==============================] - 0s 56us/step - loss: 0.2665 - acc: 0.8957 - val_loss: 0.8146 - val_acc: 0.6667\n",
      "Epoch 677/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.2670 - acc: 0.8650 - val_loss: 0.7423 - val_acc: 0.6667\n",
      "Epoch 678/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2662 - acc: 0.8834 - val_loss: 0.8097 - val_acc: 0.6667\n",
      "Epoch 679/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.2663 - acc: 0.8650 - val_loss: 0.7434 - val_acc: 0.6667\n",
      "Epoch 680/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.2655 - acc: 0.8896 - val_loss: 0.8130 - val_acc: 0.6667\n",
      "Epoch 681/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.2658 - acc: 0.8650 - val_loss: 0.7384 - val_acc: 0.6667\n",
      "Epoch 682/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.2653 - acc: 0.8896 - val_loss: 0.8175 - val_acc: 0.6296\n",
      "Epoch 683/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.2663 - acc: 0.8650 - val_loss: 0.7378 - val_acc: 0.6667\n",
      "Epoch 684/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2652 - acc: 0.8957 - val_loss: 0.8225 - val_acc: 0.6667\n",
      "Epoch 685/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.2664 - acc: 0.8650 - val_loss: 0.7437 - val_acc: 0.6667\n",
      "Epoch 686/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.2644 - acc: 0.8896 - val_loss: 0.8151 - val_acc: 0.6667\n",
      "Epoch 687/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.2641 - acc: 0.8650 - val_loss: 0.7520 - val_acc: 0.6667\n",
      "Epoch 688/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.2634 - acc: 0.8834 - val_loss: 0.8125 - val_acc: 0.6667\n",
      "Epoch 689/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.2636 - acc: 0.8650 - val_loss: 0.7467 - val_acc: 0.6667\n",
      "Epoch 690/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2630 - acc: 0.8834 - val_loss: 0.8147 - val_acc: 0.6296\n",
      "Epoch 691/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.2631 - acc: 0.8712 - val_loss: 0.7406 - val_acc: 0.6667\n",
      "Epoch 692/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2631 - acc: 0.8896 - val_loss: 0.8197 - val_acc: 0.6296\n",
      "Epoch 693/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.2635 - acc: 0.8650 - val_loss: 0.7446 - val_acc: 0.6667\n",
      "Epoch 694/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.2630 - acc: 0.8957 - val_loss: 0.8231 - val_acc: 0.6667\n",
      "Epoch 695/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2632 - acc: 0.8650 - val_loss: 0.7565 - val_acc: 0.6667\n",
      "Epoch 696/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.2621 - acc: 0.9018 - val_loss: 0.8161 - val_acc: 0.6667\n",
      "Epoch 697/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.2614 - acc: 0.8773 - val_loss: 0.7515 - val_acc: 0.6667\n",
      "Epoch 698/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.2606 - acc: 0.8896 - val_loss: 0.8087 - val_acc: 0.6296\n",
      "Epoch 699/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2608 - acc: 0.8712 - val_loss: 0.7555 - val_acc: 0.6667\n",
      "Epoch 700/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.2605 - acc: 0.8896 - val_loss: 0.8232 - val_acc: 0.6296\n",
      "Epoch 701/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.2610 - acc: 0.8650 - val_loss: 0.7454 - val_acc: 0.6667\n",
      "Epoch 702/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.2610 - acc: 0.8957 - val_loss: 0.8406 - val_acc: 0.6296\n",
      "Epoch 703/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.2628 - acc: 0.8650 - val_loss: 0.7502 - val_acc: 0.6667\n",
      "Epoch 704/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.2609 - acc: 0.8957 - val_loss: 0.8276 - val_acc: 0.6296\n",
      "Epoch 705/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.2607 - acc: 0.8650 - val_loss: 0.7562 - val_acc: 0.6667\n",
      "Epoch 706/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.2592 - acc: 0.8896 - val_loss: 0.8145 - val_acc: 0.6296\n",
      "Epoch 707/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2589 - acc: 0.8712 - val_loss: 0.7595 - val_acc: 0.6667\n",
      "Epoch 708/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.2582 - acc: 0.8896 - val_loss: 0.8210 - val_acc: 0.6296\n",
      "Epoch 709/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.2586 - acc: 0.8712 - val_loss: 0.7556 - val_acc: 0.6667\n",
      "Epoch 710/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2585 - acc: 0.8896 - val_loss: 0.8351 - val_acc: 0.6296\n",
      "Epoch 711/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.2597 - acc: 0.8650 - val_loss: 0.7455 - val_acc: 0.6667\n",
      "Epoch 712/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.2590 - acc: 0.8957 - val_loss: 0.8334 - val_acc: 0.6296\n",
      "Epoch 713/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.2594 - acc: 0.8650 - val_loss: 0.7546 - val_acc: 0.6667\n",
      "Epoch 714/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2581 - acc: 0.8957 - val_loss: 0.8369 - val_acc: 0.6296\n",
      "Epoch 715/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.2588 - acc: 0.8650 - val_loss: 0.7641 - val_acc: 0.6667\n",
      "Epoch 716/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.2569 - acc: 0.8896 - val_loss: 0.8270 - val_acc: 0.6296\n",
      "Epoch 717/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.2574 - acc: 0.8712 - val_loss: 0.7649 - val_acc: 0.6667\n",
      "Epoch 718/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.2561 - acc: 0.8957 - val_loss: 0.8234 - val_acc: 0.6296\n",
      "Epoch 719/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.2562 - acc: 0.8712 - val_loss: 0.7646 - val_acc: 0.6667\n",
      "Epoch 720/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.2557 - acc: 0.8957 - val_loss: 0.8299 - val_acc: 0.6296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 721/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.2559 - acc: 0.8712 - val_loss: 0.7574 - val_acc: 0.6667\n",
      "Epoch 722/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.2563 - acc: 0.8957 - val_loss: 0.8412 - val_acc: 0.6296\n",
      "Epoch 723/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.2570 - acc: 0.8650 - val_loss: 0.7578 - val_acc: 0.6667\n",
      "Epoch 724/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.2559 - acc: 0.8957 - val_loss: 0.8447 - val_acc: 0.6296\n",
      "Epoch 725/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.2566 - acc: 0.8650 - val_loss: 0.7603 - val_acc: 0.6667\n",
      "Epoch 726/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2553 - acc: 0.8957 - val_loss: 0.8463 - val_acc: 0.6296\n",
      "Epoch 727/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.2556 - acc: 0.8650 - val_loss: 0.7678 - val_acc: 0.6667\n",
      "Epoch 728/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2540 - acc: 0.8896 - val_loss: 0.8363 - val_acc: 0.6296\n",
      "Epoch 729/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.2543 - acc: 0.8712 - val_loss: 0.7731 - val_acc: 0.6667\n",
      "Epoch 730/3000\n",
      "163/163 [==============================] - 0s 55us/step - loss: 0.2540 - acc: 0.8957 - val_loss: 0.8321 - val_acc: 0.6296\n",
      "Epoch 731/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.2546 - acc: 0.8712 - val_loss: 0.7700 - val_acc: 0.6667\n",
      "Epoch 732/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.2536 - acc: 0.8957 - val_loss: 0.8461 - val_acc: 0.6296\n",
      "Epoch 733/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.2534 - acc: 0.8712 - val_loss: 0.7641 - val_acc: 0.6667\n",
      "Epoch 734/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.2538 - acc: 0.8957 - val_loss: 0.8456 - val_acc: 0.6296\n",
      "Epoch 735/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.2544 - acc: 0.8650 - val_loss: 0.7677 - val_acc: 0.6667\n",
      "Epoch 736/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.2533 - acc: 0.8957 - val_loss: 0.8554 - val_acc: 0.6296\n",
      "Epoch 737/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.2535 - acc: 0.8650 - val_loss: 0.7655 - val_acc: 0.6667\n",
      "Epoch 738/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.2532 - acc: 0.8957 - val_loss: 0.8465 - val_acc: 0.6296\n",
      "Epoch 739/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.2533 - acc: 0.8650 - val_loss: 0.7729 - val_acc: 0.6667\n",
      "Epoch 740/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.2515 - acc: 0.8957 - val_loss: 0.8452 - val_acc: 0.6296\n",
      "Epoch 741/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.2519 - acc: 0.8712 - val_loss: 0.7732 - val_acc: 0.6667\n",
      "Epoch 742/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.2513 - acc: 0.8896 - val_loss: 0.8444 - val_acc: 0.6296\n",
      "Epoch 743/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.2515 - acc: 0.8712 - val_loss: 0.7796 - val_acc: 0.6667\n",
      "Epoch 744/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.2509 - acc: 0.8896 - val_loss: 0.8561 - val_acc: 0.6296\n",
      "Epoch 745/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.2509 - acc: 0.8712 - val_loss: 0.7738 - val_acc: 0.6667\n",
      "Epoch 746/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.2511 - acc: 0.8957 - val_loss: 0.8546 - val_acc: 0.6296\n",
      "Epoch 747/3000\n",
      "163/163 [==============================] - 0s 27us/step - loss: 0.2519 - acc: 0.8650 - val_loss: 0.7755 - val_acc: 0.6667\n",
      "Epoch 748/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.2512 - acc: 0.8957 - val_loss: 0.8619 - val_acc: 0.6296\n",
      "Epoch 749/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.2509 - acc: 0.8712 - val_loss: 0.7812 - val_acc: 0.6667\n",
      "Epoch 750/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.2500 - acc: 0.8957 - val_loss: 0.8664 - val_acc: 0.6296\n",
      "Epoch 751/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.2506 - acc: 0.8650 - val_loss: 0.7811 - val_acc: 0.6667\n",
      "Epoch 752/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.2499 - acc: 0.8957 - val_loss: 0.8618 - val_acc: 0.6296\n",
      "Epoch 753/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.2499 - acc: 0.8650 - val_loss: 0.7807 - val_acc: 0.6296\n",
      "Epoch 754/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.2492 - acc: 0.8957 - val_loss: 0.8574 - val_acc: 0.6296\n",
      "Epoch 755/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.2492 - acc: 0.8650 - val_loss: 0.7855 - val_acc: 0.6296\n",
      "Epoch 756/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.2481 - acc: 0.8957 - val_loss: 0.8578 - val_acc: 0.6296\n",
      "Epoch 757/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.2483 - acc: 0.8650 - val_loss: 0.7853 - val_acc: 0.6296\n",
      "Epoch 758/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.2478 - acc: 0.8957 - val_loss: 0.8566 - val_acc: 0.6296\n",
      "Epoch 759/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.2480 - acc: 0.8650 - val_loss: 0.7876 - val_acc: 0.6296\n",
      "Epoch 760/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.2473 - acc: 0.8957 - val_loss: 0.8595 - val_acc: 0.6296\n",
      "Epoch 761/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.2477 - acc: 0.8773 - val_loss: 0.7828 - val_acc: 0.6296\n",
      "Epoch 762/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.2482 - acc: 0.8957 - val_loss: 0.8703 - val_acc: 0.6296\n",
      "Epoch 763/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.2484 - acc: 0.8650 - val_loss: 0.7881 - val_acc: 0.6296\n",
      "Epoch 764/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.2481 - acc: 0.8957 - val_loss: 0.8765 - val_acc: 0.6296\n",
      "Epoch 765/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.2478 - acc: 0.8650 - val_loss: 0.7919 - val_acc: 0.6296\n",
      "Epoch 766/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.2469 - acc: 0.8957 - val_loss: 0.8792 - val_acc: 0.6296\n",
      "Epoch 767/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.2474 - acc: 0.8650 - val_loss: 0.7947 - val_acc: 0.6296\n",
      "Epoch 768/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.2460 - acc: 0.8957 - val_loss: 0.8694 - val_acc: 0.6296\n",
      "Epoch 769/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.2459 - acc: 0.8650 - val_loss: 0.7903 - val_acc: 0.6296\n",
      "Epoch 770/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.2456 - acc: 0.8957 - val_loss: 0.8683 - val_acc: 0.6667\n",
      "Epoch 771/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.2467 - acc: 0.8650 - val_loss: 0.7958 - val_acc: 0.6296\n",
      "Epoch 772/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.2456 - acc: 0.8957 - val_loss: 0.8691 - val_acc: 0.6296\n",
      "Epoch 773/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2455 - acc: 0.8712 - val_loss: 0.7874 - val_acc: 0.6296\n",
      "Epoch 774/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.2461 - acc: 0.8957 - val_loss: 0.8831 - val_acc: 0.6667\n",
      "Epoch 775/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2461 - acc: 0.8650 - val_loss: 0.7933 - val_acc: 0.6296\n",
      "Epoch 776/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.2452 - acc: 0.8957 - val_loss: 0.8850 - val_acc: 0.6296\n",
      "Epoch 777/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.2454 - acc: 0.8650 - val_loss: 0.7964 - val_acc: 0.6296\n",
      "Epoch 778/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.2446 - acc: 0.8957 - val_loss: 0.8645 - val_acc: 0.6296\n",
      "Epoch 779/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2440 - acc: 0.8773 - val_loss: 0.8059 - val_acc: 0.6296\n",
      "Epoch 780/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.2440 - acc: 0.8957 - val_loss: 0.8772 - val_acc: 0.6296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 781/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.2435 - acc: 0.8773 - val_loss: 0.8030 - val_acc: 0.6296\n",
      "Epoch 782/3000\n",
      "163/163 [==============================] - 0s 57us/step - loss: 0.2431 - acc: 0.8957 - val_loss: 0.8716 - val_acc: 0.6296\n",
      "Epoch 783/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.2429 - acc: 0.8712 - val_loss: 0.8015 - val_acc: 0.6296\n",
      "Epoch 784/3000\n",
      "163/163 [==============================] - 0s 53us/step - loss: 0.2433 - acc: 0.8957 - val_loss: 0.8929 - val_acc: 0.6667\n",
      "Epoch 785/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2445 - acc: 0.8712 - val_loss: 0.7897 - val_acc: 0.6296\n",
      "Epoch 786/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.2443 - acc: 0.8957 - val_loss: 0.8896 - val_acc: 0.6667\n",
      "Epoch 787/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.2440 - acc: 0.8712 - val_loss: 0.8030 - val_acc: 0.6296\n",
      "Epoch 788/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.2423 - acc: 0.8957 - val_loss: 0.8896 - val_acc: 0.6667\n",
      "Epoch 789/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.2425 - acc: 0.8712 - val_loss: 0.8094 - val_acc: 0.6296\n",
      "Epoch 790/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.2414 - acc: 0.9018 - val_loss: 0.8750 - val_acc: 0.6667\n",
      "Epoch 791/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.2413 - acc: 0.8834 - val_loss: 0.8131 - val_acc: 0.6296\n",
      "Epoch 792/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.2404 - acc: 0.9018 - val_loss: 0.8695 - val_acc: 0.6296\n",
      "Epoch 793/3000\n",
      "163/163 [==============================] - 0s 59us/step - loss: 0.2398 - acc: 0.8834 - val_loss: 0.8203 - val_acc: 0.6296\n",
      "Epoch 794/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.2402 - acc: 0.8957 - val_loss: 0.8898 - val_acc: 0.6667\n",
      "Epoch 795/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.2410 - acc: 0.8773 - val_loss: 0.7956 - val_acc: 0.6296\n",
      "Epoch 796/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.2425 - acc: 0.8957 - val_loss: 0.9120 - val_acc: 0.6667\n",
      "Epoch 797/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2441 - acc: 0.8650 - val_loss: 0.8003 - val_acc: 0.6296\n",
      "Epoch 798/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2434 - acc: 0.8957 - val_loss: 0.9100 - val_acc: 0.6667\n",
      "Epoch 799/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.2427 - acc: 0.8650 - val_loss: 0.8006 - val_acc: 0.6296\n",
      "Epoch 800/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.2408 - acc: 0.8957 - val_loss: 0.8903 - val_acc: 0.6667\n",
      "Epoch 801/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2401 - acc: 0.8712 - val_loss: 0.8165 - val_acc: 0.6296\n",
      "Epoch 802/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.2385 - acc: 0.9018 - val_loss: 0.8791 - val_acc: 0.6296\n",
      "Epoch 803/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.2385 - acc: 0.8834 - val_loss: 0.8276 - val_acc: 0.6296\n",
      "Epoch 804/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.2386 - acc: 0.8957 - val_loss: 0.8934 - val_acc: 0.6296\n",
      "Epoch 805/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.2386 - acc: 0.8834 - val_loss: 0.8156 - val_acc: 0.6296\n",
      "Epoch 806/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.2391 - acc: 0.8957 - val_loss: 0.9069 - val_acc: 0.6667\n",
      "Epoch 807/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.2402 - acc: 0.8712 - val_loss: 0.8073 - val_acc: 0.6296\n",
      "Epoch 808/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.2404 - acc: 0.8957 - val_loss: 0.9133 - val_acc: 0.6667\n",
      "Epoch 809/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2402 - acc: 0.8773 - val_loss: 0.8115 - val_acc: 0.6296\n",
      "Epoch 810/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.2386 - acc: 0.8957 - val_loss: 0.9104 - val_acc: 0.6667\n",
      "Epoch 811/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.2396 - acc: 0.8773 - val_loss: 0.8152 - val_acc: 0.6296\n",
      "Epoch 812/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.2384 - acc: 0.9018 - val_loss: 0.8937 - val_acc: 0.6667\n",
      "Epoch 813/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.2377 - acc: 0.8896 - val_loss: 0.8242 - val_acc: 0.6296\n",
      "Epoch 814/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.2371 - acc: 0.8957 - val_loss: 0.8928 - val_acc: 0.6296\n",
      "Epoch 815/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2365 - acc: 0.9018 - val_loss: 0.8329 - val_acc: 0.6296\n",
      "Epoch 816/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.2371 - acc: 0.8957 - val_loss: 0.8854 - val_acc: 0.6296\n",
      "Epoch 817/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.2368 - acc: 0.8896 - val_loss: 0.8255 - val_acc: 0.6296\n",
      "Epoch 818/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.2370 - acc: 0.8957 - val_loss: 0.9171 - val_acc: 0.6667\n",
      "Epoch 819/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.2374 - acc: 0.8896 - val_loss: 0.8101 - val_acc: 0.6296\n",
      "Epoch 820/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.2383 - acc: 0.8957 - val_loss: 0.9181 - val_acc: 0.6667\n",
      "Epoch 821/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.2381 - acc: 0.8834 - val_loss: 0.8147 - val_acc: 0.6296\n",
      "Epoch 822/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.2369 - acc: 0.8957 - val_loss: 0.9150 - val_acc: 0.6667\n",
      "Epoch 823/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.2373 - acc: 0.8773 - val_loss: 0.8245 - val_acc: 0.6296\n",
      "Epoch 824/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2368 - acc: 0.8957 - val_loss: 0.9203 - val_acc: 0.6667\n",
      "Epoch 825/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.2366 - acc: 0.8834 - val_loss: 0.8195 - val_acc: 0.6296\n",
      "Epoch 826/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.2364 - acc: 0.9080 - val_loss: 0.9103 - val_acc: 0.6667\n",
      "Epoch 827/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.2357 - acc: 0.8834 - val_loss: 0.8321 - val_acc: 0.6296\n",
      "Epoch 828/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.2348 - acc: 0.9141 - val_loss: 0.9089 - val_acc: 0.6667\n",
      "Epoch 829/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2356 - acc: 0.8957 - val_loss: 0.8288 - val_acc: 0.6296\n",
      "Epoch 830/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.2343 - acc: 0.9141 - val_loss: 0.9045 - val_acc: 0.6667\n",
      "Epoch 831/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.2341 - acc: 0.8957 - val_loss: 0.8323 - val_acc: 0.6296\n",
      "Epoch 832/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.2332 - acc: 0.9141 - val_loss: 0.9037 - val_acc: 0.6296\n",
      "Epoch 833/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.2329 - acc: 0.9080 - val_loss: 0.8349 - val_acc: 0.6296\n",
      "Epoch 834/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.2337 - acc: 0.9080 - val_loss: 0.9160 - val_acc: 0.6667\n",
      "Epoch 835/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.2348 - acc: 0.8834 - val_loss: 0.8212 - val_acc: 0.6296\n",
      "Epoch 836/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.2352 - acc: 0.9080 - val_loss: 0.9364 - val_acc: 0.6667\n",
      "Epoch 837/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.2355 - acc: 0.8834 - val_loss: 0.8184 - val_acc: 0.6296\n",
      "Epoch 838/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.2359 - acc: 0.9018 - val_loss: 0.9329 - val_acc: 0.6667\n",
      "Epoch 839/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.2362 - acc: 0.8834 - val_loss: 0.8319 - val_acc: 0.6296\n",
      "Epoch 840/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.2344 - acc: 0.9080 - val_loss: 0.9317 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 841/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.2343 - acc: 0.8896 - val_loss: 0.8365 - val_acc: 0.6296\n",
      "Epoch 842/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.2329 - acc: 0.9080 - val_loss: 0.9229 - val_acc: 0.6667\n",
      "Epoch 843/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.2329 - acc: 0.9080 - val_loss: 0.8396 - val_acc: 0.6296\n",
      "Epoch 844/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.2326 - acc: 0.9080 - val_loss: 0.9152 - val_acc: 0.6296\n",
      "Epoch 845/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.2317 - acc: 0.9080 - val_loss: 0.8476 - val_acc: 0.6296\n",
      "Epoch 846/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2313 - acc: 0.9080 - val_loss: 0.9220 - val_acc: 0.6667\n",
      "Epoch 847/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.2318 - acc: 0.9080 - val_loss: 0.8403 - val_acc: 0.6296\n",
      "Epoch 848/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.2320 - acc: 0.9141 - val_loss: 0.9324 - val_acc: 0.6667\n",
      "Epoch 849/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.2326 - acc: 0.8896 - val_loss: 0.8345 - val_acc: 0.6296\n",
      "Epoch 850/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.2319 - acc: 0.9141 - val_loss: 0.9405 - val_acc: 0.6667\n",
      "Epoch 851/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.2328 - acc: 0.8896 - val_loss: 0.8360 - val_acc: 0.6296\n",
      "Epoch 852/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.2319 - acc: 0.9080 - val_loss: 0.9440 - val_acc: 0.6667\n",
      "Epoch 853/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.2322 - acc: 0.8896 - val_loss: 0.8365 - val_acc: 0.6296\n",
      "Epoch 854/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.2317 - acc: 0.9080 - val_loss: 0.9328 - val_acc: 0.6667\n",
      "Epoch 855/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.2314 - acc: 0.8896 - val_loss: 0.8509 - val_acc: 0.6296\n",
      "Epoch 856/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.2303 - acc: 0.9141 - val_loss: 0.9302 - val_acc: 0.6667\n",
      "Epoch 857/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2302 - acc: 0.8896 - val_loss: 0.8394 - val_acc: 0.6296\n",
      "Epoch 858/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.2302 - acc: 0.9141 - val_loss: 0.9340 - val_acc: 0.6667\n",
      "Epoch 859/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.2309 - acc: 0.8957 - val_loss: 0.8464 - val_acc: 0.6296\n",
      "Epoch 860/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.2297 - acc: 0.9202 - val_loss: 0.9353 - val_acc: 0.6667\n",
      "Epoch 861/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.2297 - acc: 0.8957 - val_loss: 0.8534 - val_acc: 0.6296\n",
      "Epoch 862/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2297 - acc: 0.9141 - val_loss: 0.9478 - val_acc: 0.6667\n",
      "Epoch 863/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2299 - acc: 0.9018 - val_loss: 0.8406 - val_acc: 0.6296\n",
      "Epoch 864/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2303 - acc: 0.9080 - val_loss: 0.9443 - val_acc: 0.6667\n",
      "Epoch 865/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.2301 - acc: 0.8896 - val_loss: 0.8441 - val_acc: 0.6296\n",
      "Epoch 866/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2286 - acc: 0.9080 - val_loss: 0.9473 - val_acc: 0.6667\n",
      "Epoch 867/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.2290 - acc: 0.8957 - val_loss: 0.8478 - val_acc: 0.6296\n",
      "Epoch 868/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.2287 - acc: 0.9080 - val_loss: 0.9364 - val_acc: 0.6667\n",
      "Epoch 869/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.2285 - acc: 0.8957 - val_loss: 0.8506 - val_acc: 0.6296\n",
      "Epoch 870/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.2281 - acc: 0.9141 - val_loss: 0.9503 - val_acc: 0.6667\n",
      "Epoch 871/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.2291 - acc: 0.8896 - val_loss: 0.8572 - val_acc: 0.6296\n",
      "Epoch 872/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.2276 - acc: 0.9202 - val_loss: 0.9465 - val_acc: 0.6667\n",
      "Epoch 873/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.2282 - acc: 0.8896 - val_loss: 0.8481 - val_acc: 0.6296\n",
      "Epoch 874/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.2274 - acc: 0.9202 - val_loss: 0.9457 - val_acc: 0.6667\n",
      "Epoch 875/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2276 - acc: 0.8896 - val_loss: 0.8560 - val_acc: 0.6296\n",
      "Epoch 876/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.2266 - acc: 0.9202 - val_loss: 0.9479 - val_acc: 0.6667\n",
      "Epoch 877/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.2270 - acc: 0.8957 - val_loss: 0.8522 - val_acc: 0.6296\n",
      "Epoch 878/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.2276 - acc: 0.9141 - val_loss: 0.9641 - val_acc: 0.6667\n",
      "Epoch 879/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.2278 - acc: 0.8896 - val_loss: 0.8510 - val_acc: 0.6296\n",
      "Epoch 880/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.2268 - acc: 0.9141 - val_loss: 0.9542 - val_acc: 0.6667\n",
      "Epoch 881/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.2279 - acc: 0.8957 - val_loss: 0.8502 - val_acc: 0.6296\n",
      "Epoch 882/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.2267 - acc: 0.9141 - val_loss: 0.9476 - val_acc: 0.6296\n",
      "Epoch 883/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.2259 - acc: 0.9018 - val_loss: 0.8655 - val_acc: 0.6296\n",
      "Epoch 884/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.2254 - acc: 0.9202 - val_loss: 0.9521 - val_acc: 0.6667\n",
      "Epoch 885/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.2254 - acc: 0.8957 - val_loss: 0.8616 - val_acc: 0.6296\n",
      "Epoch 886/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2257 - acc: 0.9202 - val_loss: 0.9503 - val_acc: 0.6667\n",
      "Epoch 887/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.2257 - acc: 0.8896 - val_loss: 0.8627 - val_acc: 0.6296\n",
      "Epoch 888/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.2244 - acc: 0.9264 - val_loss: 0.9579 - val_acc: 0.6667\n",
      "Epoch 889/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.2251 - acc: 0.8957 - val_loss: 0.8585 - val_acc: 0.6296\n",
      "Epoch 890/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.2251 - acc: 0.9202 - val_loss: 0.9524 - val_acc: 0.6667\n",
      "Epoch 891/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.2257 - acc: 0.8896 - val_loss: 0.8547 - val_acc: 0.6296\n",
      "Epoch 892/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.2240 - acc: 0.9264 - val_loss: 0.9545 - val_acc: 0.6667\n",
      "Epoch 893/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.2242 - acc: 0.9018 - val_loss: 0.8590 - val_acc: 0.6296\n",
      "Epoch 894/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.2248 - acc: 0.9141 - val_loss: 0.9725 - val_acc: 0.6667\n",
      "Epoch 895/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.2255 - acc: 0.8957 - val_loss: 0.8560 - val_acc: 0.6296\n",
      "Epoch 896/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.2252 - acc: 0.9141 - val_loss: 0.9637 - val_acc: 0.6667\n",
      "Epoch 897/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.2250 - acc: 0.8896 - val_loss: 0.8672 - val_acc: 0.6296\n",
      "Epoch 898/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.2237 - acc: 0.9264 - val_loss: 0.9630 - val_acc: 0.6667\n",
      "Epoch 899/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.2249 - acc: 0.8896 - val_loss: 0.8630 - val_acc: 0.6296\n",
      "Epoch 900/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.2231 - acc: 0.9202 - val_loss: 0.9559 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 901/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.2234 - acc: 0.9018 - val_loss: 0.8683 - val_acc: 0.6296\n",
      "Epoch 902/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.2242 - acc: 0.9202 - val_loss: 0.9672 - val_acc: 0.6667\n",
      "Epoch 903/3000\n",
      "163/163 [==============================] - 0s 53us/step - loss: 0.2236 - acc: 0.8957 - val_loss: 0.8709 - val_acc: 0.6296\n",
      "Epoch 904/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.2221 - acc: 0.9264 - val_loss: 0.9556 - val_acc: 0.6667\n",
      "Epoch 905/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.2224 - acc: 0.9080 - val_loss: 0.8657 - val_acc: 0.6296\n",
      "Epoch 906/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.2227 - acc: 0.9264 - val_loss: 0.9655 - val_acc: 0.6667\n",
      "Epoch 907/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.2229 - acc: 0.8957 - val_loss: 0.8698 - val_acc: 0.6296\n",
      "Epoch 908/3000\n",
      "163/163 [==============================] - 0s 59us/step - loss: 0.2232 - acc: 0.9202 - val_loss: 0.9771 - val_acc: 0.6667\n",
      "Epoch 909/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.2245 - acc: 0.8896 - val_loss: 0.8604 - val_acc: 0.6296\n",
      "Epoch 910/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.2228 - acc: 0.9202 - val_loss: 0.9779 - val_acc: 0.6667\n",
      "Epoch 911/3000\n",
      "163/163 [==============================] - 0s 57us/step - loss: 0.2247 - acc: 0.8957 - val_loss: 0.8638 - val_acc: 0.6296\n",
      "Epoch 912/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.2231 - acc: 0.9202 - val_loss: 0.9708 - val_acc: 0.6667\n",
      "Epoch 913/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.2225 - acc: 0.8896 - val_loss: 0.8757 - val_acc: 0.6296\n",
      "Epoch 914/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.2208 - acc: 0.9264 - val_loss: 0.9484 - val_acc: 0.6296\n",
      "Epoch 915/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.2196 - acc: 0.9080 - val_loss: 0.8982 - val_acc: 0.6296\n",
      "Epoch 916/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.2198 - acc: 0.9264 - val_loss: 0.9574 - val_acc: 0.6667\n",
      "Epoch 917/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.2193 - acc: 0.9080 - val_loss: 0.8933 - val_acc: 0.6296\n",
      "Epoch 918/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.2193 - acc: 0.9264 - val_loss: 0.9698 - val_acc: 0.6667\n",
      "Epoch 919/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.2204 - acc: 0.9018 - val_loss: 0.8741 - val_acc: 0.6296\n",
      "Epoch 920/3000\n",
      "163/163 [==============================] - 0s 58us/step - loss: 0.2218 - acc: 0.9264 - val_loss: 0.9883 - val_acc: 0.6667\n",
      "Epoch 921/3000\n",
      "163/163 [==============================] - 0s 54us/step - loss: 0.2235 - acc: 0.8896 - val_loss: 0.8636 - val_acc: 0.6667\n",
      "Epoch 922/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.2224 - acc: 0.9264 - val_loss: 0.9959 - val_acc: 0.6667\n",
      "Epoch 923/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.2243 - acc: 0.8957 - val_loss: 0.8618 - val_acc: 0.6667\n",
      "Epoch 924/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.2222 - acc: 0.9141 - val_loss: 0.9757 - val_acc: 0.6667\n",
      "Epoch 925/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.2219 - acc: 0.8896 - val_loss: 0.8842 - val_acc: 0.6296\n",
      "Epoch 926/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2200 - acc: 0.9264 - val_loss: 0.9707 - val_acc: 0.6667\n",
      "Epoch 927/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.2192 - acc: 0.9018 - val_loss: 0.8886 - val_acc: 0.6296\n",
      "Epoch 928/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.2185 - acc: 0.9202 - val_loss: 0.9705 - val_acc: 0.6667\n",
      "Epoch 929/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.2193 - acc: 0.8957 - val_loss: 0.8844 - val_acc: 0.6296\n",
      "Epoch 930/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.2190 - acc: 0.9264 - val_loss: 0.9647 - val_acc: 0.6667\n",
      "Epoch 931/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.2181 - acc: 0.9018 - val_loss: 0.8961 - val_acc: 0.6296\n",
      "Epoch 932/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.2173 - acc: 0.9264 - val_loss: 0.9607 - val_acc: 0.6667\n",
      "Epoch 933/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.2179 - acc: 0.9080 - val_loss: 0.8990 - val_acc: 0.6296\n",
      "Epoch 934/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.2182 - acc: 0.9264 - val_loss: 0.9873 - val_acc: 0.6667\n",
      "Epoch 935/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.2192 - acc: 0.8957 - val_loss: 0.8820 - val_acc: 0.6667\n",
      "Epoch 936/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.2202 - acc: 0.9141 - val_loss: 1.0145 - val_acc: 0.6667\n",
      "Epoch 937/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.2223 - acc: 0.8957 - val_loss: 0.8688 - val_acc: 0.6667\n",
      "Epoch 938/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.2213 - acc: 0.9141 - val_loss: 1.0001 - val_acc: 0.6667\n",
      "Epoch 939/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.2219 - acc: 0.8957 - val_loss: 0.8833 - val_acc: 0.6667\n",
      "Epoch 940/3000\n",
      "163/163 [==============================] - 0s 55us/step - loss: 0.2189 - acc: 0.9141 - val_loss: 0.9783 - val_acc: 0.6667\n",
      "Epoch 941/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.2181 - acc: 0.9018 - val_loss: 0.9014 - val_acc: 0.6296\n",
      "Epoch 942/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.2179 - acc: 0.9264 - val_loss: 0.9874 - val_acc: 0.6667\n",
      "Epoch 943/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.2183 - acc: 0.8957 - val_loss: 0.8845 - val_acc: 0.6296\n",
      "Epoch 944/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.2173 - acc: 0.9264 - val_loss: 0.9778 - val_acc: 0.6667\n",
      "Epoch 945/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.2168 - acc: 0.9018 - val_loss: 0.9035 - val_acc: 0.6296\n",
      "Epoch 946/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.2160 - acc: 0.9264 - val_loss: 0.9709 - val_acc: 0.6667\n",
      "Epoch 947/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.2163 - acc: 0.9018 - val_loss: 0.9024 - val_acc: 0.6296\n",
      "Epoch 948/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.2167 - acc: 0.9264 - val_loss: 0.9985 - val_acc: 0.6667\n",
      "Epoch 949/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.2181 - acc: 0.8957 - val_loss: 0.8932 - val_acc: 0.6667\n",
      "Epoch 950/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.2182 - acc: 0.9202 - val_loss: 1.0101 - val_acc: 0.6667\n",
      "Epoch 951/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.2188 - acc: 0.8957 - val_loss: 0.8904 - val_acc: 0.6667\n",
      "Epoch 952/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.2184 - acc: 0.9264 - val_loss: 1.0034 - val_acc: 0.6667\n",
      "Epoch 953/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.2192 - acc: 0.9018 - val_loss: 0.8874 - val_acc: 0.6296\n",
      "Epoch 954/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.2177 - acc: 0.9202 - val_loss: 0.9938 - val_acc: 0.6667\n",
      "Epoch 955/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.2164 - acc: 0.9018 - val_loss: 0.9101 - val_acc: 0.6296\n",
      "Epoch 956/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.2153 - acc: 0.9264 - val_loss: 0.9837 - val_acc: 0.6667\n",
      "Epoch 957/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.2153 - acc: 0.9018 - val_loss: 0.9004 - val_acc: 0.6296\n",
      "Epoch 958/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.2158 - acc: 0.9264 - val_loss: 0.9921 - val_acc: 0.6667\n",
      "Epoch 959/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.2158 - acc: 0.8957 - val_loss: 0.9087 - val_acc: 0.6296\n",
      "Epoch 960/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.2156 - acc: 0.9264 - val_loss: 0.9966 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 961/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.2161 - acc: 0.8957 - val_loss: 0.8983 - val_acc: 0.6296\n",
      "Epoch 962/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.2160 - acc: 0.9202 - val_loss: 1.0090 - val_acc: 0.6667\n",
      "Epoch 963/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.2166 - acc: 0.8957 - val_loss: 0.8889 - val_acc: 0.6296\n",
      "Epoch 964/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.2160 - acc: 0.9325 - val_loss: 1.0037 - val_acc: 0.6667\n",
      "Epoch 965/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.2162 - acc: 0.8957 - val_loss: 0.9012 - val_acc: 0.6296\n",
      "Epoch 966/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.2147 - acc: 0.9264 - val_loss: 0.9995 - val_acc: 0.6667\n",
      "Epoch 967/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.2152 - acc: 0.8957 - val_loss: 0.9017 - val_acc: 0.6296\n",
      "Epoch 968/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.2152 - acc: 0.9264 - val_loss: 1.0093 - val_acc: 0.6667\n",
      "Epoch 969/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.2161 - acc: 0.8896 - val_loss: 0.9022 - val_acc: 0.6296\n",
      "Epoch 970/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.2152 - acc: 0.9325 - val_loss: 1.0027 - val_acc: 0.6667\n",
      "Epoch 971/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.2151 - acc: 0.8896 - val_loss: 0.9123 - val_acc: 0.6296\n",
      "Epoch 972/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.2137 - acc: 0.9264 - val_loss: 0.9973 - val_acc: 0.6667\n",
      "Epoch 973/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.2140 - acc: 0.8896 - val_loss: 0.9066 - val_acc: 0.6296\n",
      "Epoch 974/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.2135 - acc: 0.9264 - val_loss: 1.0059 - val_acc: 0.6667\n",
      "Epoch 975/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.2139 - acc: 0.9018 - val_loss: 0.9113 - val_acc: 0.6296\n",
      "Epoch 976/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.2141 - acc: 0.9264 - val_loss: 1.0162 - val_acc: 0.6667\n",
      "Epoch 977/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.2152 - acc: 0.8957 - val_loss: 0.8978 - val_acc: 0.6667\n",
      "Epoch 978/3000\n",
      "163/163 [==============================] - 0s 27us/step - loss: 0.2148 - acc: 0.9264 - val_loss: 1.0130 - val_acc: 0.6667\n",
      "Epoch 979/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.2156 - acc: 0.9018 - val_loss: 0.9013 - val_acc: 0.6667\n",
      "Epoch 980/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.2146 - acc: 0.9202 - val_loss: 1.0209 - val_acc: 0.6667\n",
      "Epoch 981/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.2150 - acc: 0.9018 - val_loss: 0.9046 - val_acc: 0.6296\n",
      "Epoch 982/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.2142 - acc: 0.9264 - val_loss: 1.0215 - val_acc: 0.6667\n",
      "Epoch 983/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.2137 - acc: 0.8896 - val_loss: 0.9211 - val_acc: 0.6296\n",
      "Epoch 984/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.2117 - acc: 0.9264 - val_loss: 1.0005 - val_acc: 0.6667\n",
      "Epoch 985/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.2127 - acc: 0.8834 - val_loss: 0.9226 - val_acc: 0.6296\n",
      "Epoch 986/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.2120 - acc: 0.9264 - val_loss: 0.9976 - val_acc: 0.6667\n",
      "Epoch 987/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.2114 - acc: 0.8957 - val_loss: 0.9244 - val_acc: 0.6296\n",
      "Epoch 988/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.2116 - acc: 0.9264 - val_loss: 1.0108 - val_acc: 0.6667\n",
      "Epoch 989/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.2123 - acc: 0.8957 - val_loss: 0.9182 - val_acc: 0.6296\n",
      "Epoch 990/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.2134 - acc: 0.9202 - val_loss: 1.0296 - val_acc: 0.6667\n",
      "Epoch 991/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.2144 - acc: 0.8957 - val_loss: 0.9163 - val_acc: 0.6667\n",
      "Epoch 992/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.2143 - acc: 0.9202 - val_loss: 1.0409 - val_acc: 0.6667\n",
      "Epoch 993/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.2161 - acc: 0.8896 - val_loss: 0.8976 - val_acc: 0.6667\n",
      "Epoch 994/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.2146 - acc: 0.9264 - val_loss: 1.0252 - val_acc: 0.6667\n",
      "Epoch 995/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.2138 - acc: 0.8896 - val_loss: 0.9197 - val_acc: 0.6296\n",
      "Epoch 996/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.2111 - acc: 0.9264 - val_loss: 0.9985 - val_acc: 0.6667\n",
      "Epoch 997/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.2105 - acc: 0.8957 - val_loss: 0.9386 - val_acc: 0.6296\n",
      "Epoch 998/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.2102 - acc: 0.9264 - val_loss: 1.0082 - val_acc: 0.6667\n",
      "Epoch 999/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.2097 - acc: 0.8896 - val_loss: 0.9238 - val_acc: 0.6296\n",
      "Epoch 1000/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.2104 - acc: 0.9264 - val_loss: 1.0129 - val_acc: 0.6667\n",
      "Epoch 1001/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.2101 - acc: 0.9018 - val_loss: 0.9203 - val_acc: 0.6296\n",
      "Epoch 1002/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.2107 - acc: 0.9264 - val_loss: 1.0277 - val_acc: 0.6667\n",
      "Epoch 1003/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.2119 - acc: 0.8957 - val_loss: 0.9204 - val_acc: 0.6296\n",
      "Epoch 1004/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.2109 - acc: 0.9264 - val_loss: 1.0294 - val_acc: 0.6667\n",
      "Epoch 1005/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.2128 - acc: 0.8896 - val_loss: 0.9246 - val_acc: 0.6667\n",
      "Epoch 1006/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.2123 - acc: 0.9264 - val_loss: 1.0477 - val_acc: 0.6667\n",
      "Epoch 1007/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.2130 - acc: 0.8957 - val_loss: 0.9110 - val_acc: 0.6667\n",
      "Epoch 1008/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2127 - acc: 0.9264 - val_loss: 1.0334 - val_acc: 0.6667\n",
      "Epoch 1009/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.2122 - acc: 0.8896 - val_loss: 0.9327 - val_acc: 0.6296\n",
      "Epoch 1010/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.2100 - acc: 0.9325 - val_loss: 1.0152 - val_acc: 0.6667\n",
      "Epoch 1011/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.2090 - acc: 0.8896 - val_loss: 0.9446 - val_acc: 0.6296\n",
      "Epoch 1012/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.2080 - acc: 0.9264 - val_loss: 1.0074 - val_acc: 0.6667\n",
      "Epoch 1013/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.2077 - acc: 0.8957 - val_loss: 0.9453 - val_acc: 0.6296\n",
      "Epoch 1014/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.2080 - acc: 0.9202 - val_loss: 1.0237 - val_acc: 0.6667\n",
      "Epoch 1015/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.2086 - acc: 0.9018 - val_loss: 0.9251 - val_acc: 0.6296\n",
      "Epoch 1016/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.2101 - acc: 0.9202 - val_loss: 1.0388 - val_acc: 0.6667\n",
      "Epoch 1017/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.2118 - acc: 0.9018 - val_loss: 0.9220 - val_acc: 0.6667\n",
      "Epoch 1018/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.2111 - acc: 0.9264 - val_loss: 1.0474 - val_acc: 0.6667\n",
      "Epoch 1019/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.2127 - acc: 0.8957 - val_loss: 0.9233 - val_acc: 0.6667\n",
      "Epoch 1020/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.2112 - acc: 0.9264 - val_loss: 1.0481 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1021/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.2109 - acc: 0.8957 - val_loss: 0.9352 - val_acc: 0.6296\n",
      "Epoch 1022/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.2093 - acc: 0.9202 - val_loss: 1.0316 - val_acc: 0.6667\n",
      "Epoch 1023/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.2082 - acc: 0.8957 - val_loss: 0.9358 - val_acc: 0.6296\n",
      "Epoch 1024/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.2077 - acc: 0.9264 - val_loss: 1.0182 - val_acc: 0.6667\n",
      "Epoch 1025/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.2077 - acc: 0.8834 - val_loss: 0.9451 - val_acc: 0.6296\n",
      "Epoch 1026/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.2073 - acc: 0.9202 - val_loss: 1.0172 - val_acc: 0.6667\n",
      "Epoch 1027/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.2074 - acc: 0.8896 - val_loss: 0.9538 - val_acc: 0.6296\n",
      "Epoch 1028/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.2063 - acc: 0.9202 - val_loss: 1.0216 - val_acc: 0.6667\n",
      "Epoch 1029/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.2066 - acc: 0.8896 - val_loss: 0.9326 - val_acc: 0.6296\n",
      "Epoch 1030/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.2069 - acc: 0.9264 - val_loss: 1.0354 - val_acc: 0.6667\n",
      "Epoch 1031/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.2076 - acc: 0.8957 - val_loss: 0.9293 - val_acc: 0.6667\n",
      "Epoch 1032/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.2086 - acc: 0.9202 - val_loss: 1.0601 - val_acc: 0.6667\n",
      "Epoch 1033/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.2112 - acc: 0.8957 - val_loss: 0.9202 - val_acc: 0.6667\n",
      "Epoch 1034/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2116 - acc: 0.9202 - val_loss: 1.0694 - val_acc: 0.6667\n",
      "Epoch 1035/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.2121 - acc: 0.8896 - val_loss: 0.9327 - val_acc: 0.6667\n",
      "Epoch 1036/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.2081 - acc: 0.9264 - val_loss: 1.0411 - val_acc: 0.6667\n",
      "Epoch 1037/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.2090 - acc: 0.8957 - val_loss: 0.9370 - val_acc: 0.6296\n",
      "Epoch 1038/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.2075 - acc: 0.9264 - val_loss: 1.0302 - val_acc: 0.6667\n",
      "Epoch 1039/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2064 - acc: 0.8896 - val_loss: 0.9537 - val_acc: 0.6296\n",
      "Epoch 1040/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.2058 - acc: 0.9202 - val_loss: 1.0279 - val_acc: 0.6667\n",
      "Epoch 1041/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.2057 - acc: 0.8896 - val_loss: 0.9488 - val_acc: 0.6296\n",
      "Epoch 1042/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.2060 - acc: 0.9141 - val_loss: 1.0407 - val_acc: 0.6667\n",
      "Epoch 1043/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.2063 - acc: 0.9018 - val_loss: 0.9482 - val_acc: 0.6296\n",
      "Epoch 1044/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.2055 - acc: 0.9264 - val_loss: 1.0502 - val_acc: 0.6667\n",
      "Epoch 1045/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.2061 - acc: 0.8896 - val_loss: 0.9492 - val_acc: 0.6296\n",
      "Epoch 1046/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.2052 - acc: 0.9264 - val_loss: 1.0509 - val_acc: 0.6667\n",
      "Epoch 1047/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.2071 - acc: 0.8834 - val_loss: 0.9414 - val_acc: 0.6667\n",
      "Epoch 1048/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.2071 - acc: 0.9202 - val_loss: 1.0573 - val_acc: 0.6667\n",
      "Epoch 1049/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.2077 - acc: 0.8957 - val_loss: 0.9351 - val_acc: 0.6667\n",
      "Epoch 1050/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.2075 - acc: 0.9202 - val_loss: 1.0610 - val_acc: 0.6667\n",
      "Epoch 1051/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.2076 - acc: 0.8957 - val_loss: 0.9452 - val_acc: 0.6667\n",
      "Epoch 1052/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.2074 - acc: 0.9264 - val_loss: 1.0568 - val_acc: 0.6667\n",
      "Epoch 1053/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.2070 - acc: 0.8896 - val_loss: 0.9495 - val_acc: 0.6296\n",
      "Epoch 1054/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.2049 - acc: 0.9202 - val_loss: 1.0524 - val_acc: 0.6667\n",
      "Epoch 1055/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2054 - acc: 0.8957 - val_loss: 0.9500 - val_acc: 0.6296\n",
      "Epoch 1056/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.2045 - acc: 0.9202 - val_loss: 1.0326 - val_acc: 0.6667\n",
      "Epoch 1057/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.2043 - acc: 0.8957 - val_loss: 0.9577 - val_acc: 0.6296\n",
      "Epoch 1058/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.2037 - acc: 0.9141 - val_loss: 1.0416 - val_acc: 0.6667\n",
      "Epoch 1059/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.2041 - acc: 0.8957 - val_loss: 0.9477 - val_acc: 0.6296\n",
      "Epoch 1060/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.2045 - acc: 0.9264 - val_loss: 1.0699 - val_acc: 0.6667\n",
      "Epoch 1061/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.2058 - acc: 0.8957 - val_loss: 0.9294 - val_acc: 0.6667\n",
      "Epoch 1062/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.2068 - acc: 0.9202 - val_loss: 1.0703 - val_acc: 0.6667\n",
      "Epoch 1063/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.2069 - acc: 0.8957 - val_loss: 0.9450 - val_acc: 0.6667\n",
      "Epoch 1064/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.2042 - acc: 0.9202 - val_loss: 1.0500 - val_acc: 0.6667\n",
      "Epoch 1065/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.2064 - acc: 0.8957 - val_loss: 0.9502 - val_acc: 0.6667\n",
      "Epoch 1066/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.2055 - acc: 0.9264 - val_loss: 1.0607 - val_acc: 0.6667\n",
      "Epoch 1067/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.2059 - acc: 0.8957 - val_loss: 0.9559 - val_acc: 0.6667\n",
      "Epoch 1068/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.2049 - acc: 0.9202 - val_loss: 1.0607 - val_acc: 0.6667\n",
      "Epoch 1069/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.2048 - acc: 0.8896 - val_loss: 0.9558 - val_acc: 0.6667\n",
      "Epoch 1070/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.2032 - acc: 0.9202 - val_loss: 1.0615 - val_acc: 0.6667\n",
      "Epoch 1071/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.2039 - acc: 0.8957 - val_loss: 0.9549 - val_acc: 0.6296\n",
      "Epoch 1072/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.2029 - acc: 0.9141 - val_loss: 1.0390 - val_acc: 0.6667\n",
      "Epoch 1073/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.2023 - acc: 0.8957 - val_loss: 0.9641 - val_acc: 0.6296\n",
      "Epoch 1074/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.2011 - acc: 0.9080 - val_loss: 1.0406 - val_acc: 0.6667\n",
      "Epoch 1075/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.2013 - acc: 0.8957 - val_loss: 0.9691 - val_acc: 0.6296\n",
      "Epoch 1076/3000\n",
      "163/163 [==============================] - 0s 27us/step - loss: 0.2018 - acc: 0.9080 - val_loss: 1.0657 - val_acc: 0.6667\n",
      "Epoch 1077/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.2034 - acc: 0.8957 - val_loss: 0.9547 - val_acc: 0.6667\n",
      "Epoch 1078/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.2052 - acc: 0.9202 - val_loss: 1.0940 - val_acc: 0.6667\n",
      "Epoch 1079/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.2063 - acc: 0.8957 - val_loss: 0.9455 - val_acc: 0.6667\n",
      "Epoch 1080/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.2054 - acc: 0.9141 - val_loss: 1.0781 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1081/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.2054 - acc: 0.8957 - val_loss: 0.9501 - val_acc: 0.6667\n",
      "Epoch 1082/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.2034 - acc: 0.9202 - val_loss: 1.0619 - val_acc: 0.6667\n",
      "Epoch 1083/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.2035 - acc: 0.8957 - val_loss: 0.9634 - val_acc: 0.6296\n",
      "Epoch 1084/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.2022 - acc: 0.9141 - val_loss: 1.0569 - val_acc: 0.6667\n",
      "Epoch 1085/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.2022 - acc: 0.8896 - val_loss: 0.9792 - val_acc: 0.6296\n",
      "Epoch 1086/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.2009 - acc: 0.9202 - val_loss: 1.0594 - val_acc: 0.6667\n",
      "Epoch 1087/3000\n",
      "163/163 [==============================] - 0s 26us/step - loss: 0.2013 - acc: 0.8957 - val_loss: 0.9712 - val_acc: 0.6296\n",
      "Epoch 1088/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.2018 - acc: 0.9141 - val_loss: 1.0771 - val_acc: 0.6667\n",
      "Epoch 1089/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.2020 - acc: 0.8896 - val_loss: 0.9613 - val_acc: 0.6667\n",
      "Epoch 1090/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.2011 - acc: 0.9202 - val_loss: 1.0579 - val_acc: 0.6667\n",
      "Epoch 1091/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.2018 - acc: 0.8896 - val_loss: 0.9686 - val_acc: 0.6667\n",
      "Epoch 1092/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.2011 - acc: 0.9202 - val_loss: 1.0726 - val_acc: 0.6667\n",
      "Epoch 1093/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.2017 - acc: 0.8957 - val_loss: 0.9657 - val_acc: 0.6296\n",
      "Epoch 1094/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.2018 - acc: 0.9264 - val_loss: 1.0804 - val_acc: 0.6667\n",
      "Epoch 1095/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.2017 - acc: 0.8957 - val_loss: 0.9615 - val_acc: 0.6667\n",
      "Epoch 1096/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.2021 - acc: 0.9202 - val_loss: 1.0891 - val_acc: 0.6667\n",
      "Epoch 1097/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.2028 - acc: 0.8957 - val_loss: 0.9636 - val_acc: 0.6667\n",
      "Epoch 1098/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.2016 - acc: 0.9202 - val_loss: 1.0756 - val_acc: 0.6667\n",
      "Epoch 1099/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.2034 - acc: 0.8957 - val_loss: 0.9564 - val_acc: 0.6667\n",
      "Epoch 1100/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.2025 - acc: 0.9202 - val_loss: 1.0817 - val_acc: 0.6667\n",
      "Epoch 1101/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.2019 - acc: 0.8957 - val_loss: 0.9699 - val_acc: 0.6296\n",
      "Epoch 1102/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.1999 - acc: 0.9141 - val_loss: 1.0746 - val_acc: 0.6667\n",
      "Epoch 1103/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.2002 - acc: 0.8957 - val_loss: 0.9794 - val_acc: 0.6296\n",
      "Epoch 1104/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.1986 - acc: 0.9141 - val_loss: 1.0676 - val_acc: 0.6667\n",
      "Epoch 1105/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1993 - acc: 0.8957 - val_loss: 0.9856 - val_acc: 0.6296\n",
      "Epoch 1106/3000\n",
      "163/163 [==============================] - 0s 26us/step - loss: 0.1979 - acc: 0.9141 - val_loss: 1.0588 - val_acc: 0.6667\n",
      "Epoch 1107/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.1986 - acc: 0.8896 - val_loss: 0.9796 - val_acc: 0.6296\n",
      "Epoch 1108/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.1989 - acc: 0.9141 - val_loss: 1.0685 - val_acc: 0.6667\n",
      "Epoch 1109/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.1993 - acc: 0.8896 - val_loss: 0.9709 - val_acc: 0.6667\n",
      "Epoch 1110/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.2005 - acc: 0.9202 - val_loss: 1.0991 - val_acc: 0.6667\n",
      "Epoch 1111/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.2036 - acc: 0.8957 - val_loss: 0.9617 - val_acc: 0.6667\n",
      "Epoch 1112/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.2042 - acc: 0.9080 - val_loss: 1.1063 - val_acc: 0.6667\n",
      "Epoch 1113/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.2034 - acc: 0.8957 - val_loss: 0.9683 - val_acc: 0.6667\n",
      "Epoch 1114/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.2004 - acc: 0.9141 - val_loss: 1.0851 - val_acc: 0.6667\n",
      "Epoch 1115/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.2005 - acc: 0.8957 - val_loss: 0.9820 - val_acc: 0.6296\n",
      "Epoch 1116/3000\n",
      "163/163 [==============================] - 0s 27us/step - loss: 0.1987 - acc: 0.9141 - val_loss: 1.0779 - val_acc: 0.6667\n",
      "Epoch 1117/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1983 - acc: 0.8896 - val_loss: 0.9803 - val_acc: 0.6296\n",
      "Epoch 1118/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.1985 - acc: 0.9141 - val_loss: 1.0666 - val_acc: 0.6667\n",
      "Epoch 1119/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1975 - acc: 0.8896 - val_loss: 0.9889 - val_acc: 0.6296\n",
      "Epoch 1120/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.1966 - acc: 0.9080 - val_loss: 1.0675 - val_acc: 0.6667\n",
      "Epoch 1121/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1971 - acc: 0.8896 - val_loss: 0.9870 - val_acc: 0.6296\n",
      "Epoch 1122/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1970 - acc: 0.9141 - val_loss: 1.0726 - val_acc: 0.6667\n",
      "Epoch 1123/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.1979 - acc: 0.8957 - val_loss: 0.9879 - val_acc: 0.6296\n",
      "Epoch 1124/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1968 - acc: 0.9141 - val_loss: 1.0858 - val_acc: 0.6667\n",
      "Epoch 1125/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1982 - acc: 0.8896 - val_loss: 0.9815 - val_acc: 0.6667\n",
      "Epoch 1126/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1991 - acc: 0.9202 - val_loss: 1.1171 - val_acc: 0.6667\n",
      "Epoch 1127/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.2011 - acc: 0.8957 - val_loss: 0.9585 - val_acc: 0.6667\n",
      "Epoch 1128/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.2020 - acc: 0.9080 - val_loss: 1.1050 - val_acc: 0.6667\n",
      "Epoch 1129/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.2014 - acc: 0.8957 - val_loss: 0.9775 - val_acc: 0.6667\n",
      "Epoch 1130/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1984 - acc: 0.9202 - val_loss: 1.0857 - val_acc: 0.6667\n",
      "Epoch 1131/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.1988 - acc: 0.8957 - val_loss: 0.9862 - val_acc: 0.6667\n",
      "Epoch 1132/3000\n",
      "163/163 [==============================] - 0s 27us/step - loss: 0.1972 - acc: 0.9141 - val_loss: 1.0810 - val_acc: 0.6667\n",
      "Epoch 1133/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1971 - acc: 0.8957 - val_loss: 0.9881 - val_acc: 0.6296\n",
      "Epoch 1134/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1961 - acc: 0.9141 - val_loss: 1.0825 - val_acc: 0.6667\n",
      "Epoch 1135/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1963 - acc: 0.8957 - val_loss: 0.9968 - val_acc: 0.6296\n",
      "Epoch 1136/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1946 - acc: 0.9141 - val_loss: 1.0659 - val_acc: 0.6667\n",
      "Epoch 1137/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.1946 - acc: 0.8896 - val_loss: 1.0002 - val_acc: 0.6296\n",
      "Epoch 1138/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.1942 - acc: 0.9141 - val_loss: 1.0755 - val_acc: 0.6667\n",
      "Epoch 1139/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1952 - acc: 0.8957 - val_loss: 0.9744 - val_acc: 0.6296\n",
      "Epoch 1140/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1963 - acc: 0.9141 - val_loss: 1.0981 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1141/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.1970 - acc: 0.9018 - val_loss: 0.9674 - val_acc: 0.6667\n",
      "Epoch 1142/3000\n",
      "163/163 [==============================] - 0s 27us/step - loss: 0.1976 - acc: 0.9202 - val_loss: 1.1035 - val_acc: 0.6667\n",
      "Epoch 1143/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.1998 - acc: 0.9080 - val_loss: 0.9663 - val_acc: 0.6667\n",
      "Epoch 1144/3000\n",
      "163/163 [==============================] - 0s 26us/step - loss: 0.1984 - acc: 0.9141 - val_loss: 1.1090 - val_acc: 0.6667\n",
      "Epoch 1145/3000\n",
      "163/163 [==============================] - 0s 27us/step - loss: 0.1988 - acc: 0.8957 - val_loss: 0.9734 - val_acc: 0.6667\n",
      "Epoch 1146/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1961 - acc: 0.9202 - val_loss: 1.0962 - val_acc: 0.6667\n",
      "Epoch 1147/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.1956 - acc: 0.8957 - val_loss: 0.9902 - val_acc: 0.6296\n",
      "Epoch 1148/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.1942 - acc: 0.9141 - val_loss: 1.0822 - val_acc: 0.6667\n",
      "Epoch 1149/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1938 - acc: 0.8957 - val_loss: 0.9836 - val_acc: 0.6296\n",
      "Epoch 1150/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.1935 - acc: 0.9141 - val_loss: 1.0749 - val_acc: 0.6667\n",
      "Epoch 1151/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1949 - acc: 0.8957 - val_loss: 0.9888 - val_acc: 0.6296\n",
      "Epoch 1152/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1921 - acc: 0.9141 - val_loss: 1.0782 - val_acc: 0.6667\n",
      "Epoch 1153/3000\n",
      "163/163 [==============================] - 0s 27us/step - loss: 0.1935 - acc: 0.8957 - val_loss: 0.9837 - val_acc: 0.6296\n",
      "Epoch 1154/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.1931 - acc: 0.9080 - val_loss: 1.1002 - val_acc: 0.6667\n",
      "Epoch 1155/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.1952 - acc: 0.9018 - val_loss: 0.9751 - val_acc: 0.6667\n",
      "Epoch 1156/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1948 - acc: 0.9202 - val_loss: 1.1050 - val_acc: 0.6667\n",
      "Epoch 1157/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.1978 - acc: 0.9141 - val_loss: 0.9730 - val_acc: 0.7037\n",
      "Epoch 1158/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.1967 - acc: 0.9141 - val_loss: 1.1127 - val_acc: 0.6667\n",
      "Epoch 1159/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.1961 - acc: 0.9080 - val_loss: 0.9753 - val_acc: 0.6667\n",
      "Epoch 1160/3000\n",
      "163/163 [==============================] - 0s 25us/step - loss: 0.1951 - acc: 0.9202 - val_loss: 1.0948 - val_acc: 0.6667\n",
      "Epoch 1161/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1946 - acc: 0.9080 - val_loss: 0.9870 - val_acc: 0.6667\n",
      "Epoch 1162/3000\n",
      "163/163 [==============================] - 0s 27us/step - loss: 0.1925 - acc: 0.9141 - val_loss: 1.0726 - val_acc: 0.6667\n",
      "Epoch 1163/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1919 - acc: 0.9018 - val_loss: 1.0041 - val_acc: 0.6296\n",
      "Epoch 1164/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1905 - acc: 0.9141 - val_loss: 1.0706 - val_acc: 0.6667\n",
      "Epoch 1165/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.1911 - acc: 0.8957 - val_loss: 1.0005 - val_acc: 0.6296\n",
      "Epoch 1166/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.1905 - acc: 0.9141 - val_loss: 1.0937 - val_acc: 0.6667\n",
      "Epoch 1167/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.1927 - acc: 0.9018 - val_loss: 0.9819 - val_acc: 0.6667\n",
      "Epoch 1168/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.1917 - acc: 0.9141 - val_loss: 1.0972 - val_acc: 0.6667\n",
      "Epoch 1169/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1932 - acc: 0.9018 - val_loss: 0.9760 - val_acc: 0.6667\n",
      "Epoch 1170/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.1937 - acc: 0.9202 - val_loss: 1.1159 - val_acc: 0.6667\n",
      "Epoch 1171/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1961 - acc: 0.9141 - val_loss: 0.9811 - val_acc: 0.6667\n",
      "Epoch 1172/3000\n",
      "163/163 [==============================] - 0s 27us/step - loss: 0.1950 - acc: 0.9141 - val_loss: 1.1152 - val_acc: 0.6667\n",
      "Epoch 1173/3000\n",
      "163/163 [==============================] - 0s 25us/step - loss: 0.1962 - acc: 0.9080 - val_loss: 0.9787 - val_acc: 0.6667\n",
      "Epoch 1174/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1936 - acc: 0.9202 - val_loss: 1.1069 - val_acc: 0.6667\n",
      "Epoch 1175/3000\n",
      "163/163 [==============================] - 0s 27us/step - loss: 0.1926 - acc: 0.9080 - val_loss: 1.0082 - val_acc: 0.6296\n",
      "Epoch 1176/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.1913 - acc: 0.9141 - val_loss: 1.0888 - val_acc: 0.6667\n",
      "Epoch 1177/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.1900 - acc: 0.8957 - val_loss: 1.0153 - val_acc: 0.6296\n",
      "Epoch 1178/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1891 - acc: 0.9141 - val_loss: 1.0873 - val_acc: 0.6667\n",
      "Epoch 1179/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.1897 - acc: 0.8896 - val_loss: 1.0038 - val_acc: 0.6296\n",
      "Epoch 1180/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.1887 - acc: 0.9264 - val_loss: 1.0715 - val_acc: 0.6667\n",
      "Epoch 1181/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1890 - acc: 0.8957 - val_loss: 1.0148 - val_acc: 0.6296\n",
      "Epoch 1182/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.1883 - acc: 0.9141 - val_loss: 1.0806 - val_acc: 0.6667\n",
      "Epoch 1183/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1892 - acc: 0.8896 - val_loss: 1.0090 - val_acc: 0.6296\n",
      "Epoch 1184/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.1894 - acc: 0.9202 - val_loss: 1.1056 - val_acc: 0.6667\n",
      "Epoch 1185/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.1914 - acc: 0.9080 - val_loss: 0.9954 - val_acc: 0.6667\n",
      "Epoch 1186/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1917 - acc: 0.9264 - val_loss: 1.1441 - val_acc: 0.6667\n",
      "Epoch 1187/3000\n",
      "163/163 [==============================] - 0s 25us/step - loss: 0.1943 - acc: 0.9141 - val_loss: 0.9615 - val_acc: 0.7037\n",
      "Epoch 1188/3000\n",
      "163/163 [==============================] - 0s 27us/step - loss: 0.1968 - acc: 0.9080 - val_loss: 1.1455 - val_acc: 0.6667\n",
      "Epoch 1189/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1982 - acc: 0.9018 - val_loss: 0.9819 - val_acc: 0.6667\n",
      "Epoch 1190/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.1920 - acc: 0.9202 - val_loss: 1.1040 - val_acc: 0.6667\n",
      "Epoch 1191/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1918 - acc: 0.9141 - val_loss: 1.0030 - val_acc: 0.6667\n",
      "Epoch 1192/3000\n",
      "163/163 [==============================] - 0s 27us/step - loss: 0.1889 - acc: 0.9141 - val_loss: 1.1005 - val_acc: 0.6667\n",
      "Epoch 1193/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1885 - acc: 0.9080 - val_loss: 1.0091 - val_acc: 0.6296\n",
      "Epoch 1194/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1877 - acc: 0.9080 - val_loss: 1.0987 - val_acc: 0.6667\n",
      "Epoch 1195/3000\n",
      "163/163 [==============================] - 0s 26us/step - loss: 0.1891 - acc: 0.8957 - val_loss: 1.0170 - val_acc: 0.6296\n",
      "Epoch 1196/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.1869 - acc: 0.9141 - val_loss: 1.0977 - val_acc: 0.6667\n",
      "Epoch 1197/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.1881 - acc: 0.9018 - val_loss: 1.0214 - val_acc: 0.6296\n",
      "Epoch 1198/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.1863 - acc: 0.9141 - val_loss: 1.0975 - val_acc: 0.6667\n",
      "Epoch 1199/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.1880 - acc: 0.9018 - val_loss: 1.0190 - val_acc: 0.6667\n",
      "Epoch 1200/3000\n",
      "163/163 [==============================] - 0s 27us/step - loss: 0.1885 - acc: 0.9202 - val_loss: 1.1336 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1201/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.1906 - acc: 0.9141 - val_loss: 0.9937 - val_acc: 0.6667\n",
      "Epoch 1202/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.1912 - acc: 0.9141 - val_loss: 1.1438 - val_acc: 0.6667\n",
      "Epoch 1203/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.1940 - acc: 0.9141 - val_loss: 0.9873 - val_acc: 0.7037\n",
      "Epoch 1204/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.1925 - acc: 0.9141 - val_loss: 1.1328 - val_acc: 0.6667\n",
      "Epoch 1205/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.1919 - acc: 0.9141 - val_loss: 0.9972 - val_acc: 0.6667\n",
      "Epoch 1206/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1902 - acc: 0.9141 - val_loss: 1.1224 - val_acc: 0.6667\n",
      "Epoch 1207/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1905 - acc: 0.8957 - val_loss: 1.0138 - val_acc: 0.6296\n",
      "Epoch 1208/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.1859 - acc: 0.9141 - val_loss: 1.1041 - val_acc: 0.6667\n",
      "Epoch 1209/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.1864 - acc: 0.8957 - val_loss: 1.0281 - val_acc: 0.6296\n",
      "Epoch 1210/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1849 - acc: 0.9080 - val_loss: 1.1051 - val_acc: 0.6667\n",
      "Epoch 1211/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1868 - acc: 0.9018 - val_loss: 1.0200 - val_acc: 0.6296\n",
      "Epoch 1212/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1854 - acc: 0.9141 - val_loss: 1.1014 - val_acc: 0.6667\n",
      "Epoch 1213/3000\n",
      "163/163 [==============================] - 0s 27us/step - loss: 0.1865 - acc: 0.9018 - val_loss: 1.0198 - val_acc: 0.6296\n",
      "Epoch 1214/3000\n",
      "163/163 [==============================] - 0s 27us/step - loss: 0.1851 - acc: 0.9141 - val_loss: 1.1168 - val_acc: 0.6667\n",
      "Epoch 1215/3000\n",
      "163/163 [==============================] - 0s 27us/step - loss: 0.1881 - acc: 0.9080 - val_loss: 1.0017 - val_acc: 0.6667\n",
      "Epoch 1216/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1886 - acc: 0.9202 - val_loss: 1.1511 - val_acc: 0.6667\n",
      "Epoch 1217/3000\n",
      "163/163 [==============================] - 0s 27us/step - loss: 0.1934 - acc: 0.9080 - val_loss: 0.9917 - val_acc: 0.7037\n",
      "Epoch 1218/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1927 - acc: 0.9080 - val_loss: 1.1522 - val_acc: 0.6667\n",
      "Epoch 1219/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.1914 - acc: 0.9141 - val_loss: 1.0201 - val_acc: 0.6667\n",
      "Epoch 1220/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1874 - acc: 0.9202 - val_loss: 1.1228 - val_acc: 0.6667\n",
      "Epoch 1221/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1874 - acc: 0.9080 - val_loss: 1.0011 - val_acc: 0.6667\n",
      "Epoch 1222/3000\n",
      "163/163 [==============================] - 0s 27us/step - loss: 0.1871 - acc: 0.9141 - val_loss: 1.1174 - val_acc: 0.6667\n",
      "Epoch 1223/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1881 - acc: 0.8896 - val_loss: 1.0199 - val_acc: 0.6296\n",
      "Epoch 1224/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.1849 - acc: 0.9141 - val_loss: 1.1016 - val_acc: 0.6667\n",
      "Epoch 1225/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.1845 - acc: 0.8957 - val_loss: 1.0344 - val_acc: 0.6296\n",
      "Epoch 1226/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1831 - acc: 0.9080 - val_loss: 1.1102 - val_acc: 0.6667\n",
      "Epoch 1227/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.1846 - acc: 0.9018 - val_loss: 1.0308 - val_acc: 0.6296\n",
      "Epoch 1228/3000\n",
      "163/163 [==============================] - 0s 26us/step - loss: 0.1835 - acc: 0.9141 - val_loss: 1.1226 - val_acc: 0.6667\n",
      "Epoch 1229/3000\n",
      "163/163 [==============================] - 0s 26us/step - loss: 0.1852 - acc: 0.8957 - val_loss: 1.0249 - val_acc: 0.6667\n",
      "Epoch 1230/3000\n",
      "163/163 [==============================] - 0s 25us/step - loss: 0.1842 - acc: 0.9141 - val_loss: 1.1382 - val_acc: 0.6667\n",
      "Epoch 1231/3000\n",
      "163/163 [==============================] - 0s 26us/step - loss: 0.1869 - acc: 0.9080 - val_loss: 1.0101 - val_acc: 0.6667\n",
      "Epoch 1232/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.1875 - acc: 0.9141 - val_loss: 1.1637 - val_acc: 0.6667\n",
      "Epoch 1233/3000\n",
      "163/163 [==============================] - 0s 27us/step - loss: 0.1930 - acc: 0.9080 - val_loss: 0.9905 - val_acc: 0.7037\n",
      "Epoch 1234/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.1916 - acc: 0.9080 - val_loss: 1.1517 - val_acc: 0.6667\n",
      "Epoch 1235/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1908 - acc: 0.9141 - val_loss: 1.0121 - val_acc: 0.6667\n",
      "Epoch 1236/3000\n",
      "163/163 [==============================] - 0s 25us/step - loss: 0.1854 - acc: 0.9202 - val_loss: 1.1194 - val_acc: 0.6667\n",
      "Epoch 1237/3000\n",
      "163/163 [==============================] - 0s 23us/step - loss: 0.1852 - acc: 0.9080 - val_loss: 1.0293 - val_acc: 0.6296\n",
      "Epoch 1238/3000\n",
      "163/163 [==============================] - 0s 24us/step - loss: 0.1839 - acc: 0.9141 - val_loss: 1.1136 - val_acc: 0.6667\n",
      "Epoch 1239/3000\n",
      "163/163 [==============================] - 0s 24us/step - loss: 0.1846 - acc: 0.9141 - val_loss: 1.0403 - val_acc: 0.6296\n",
      "Epoch 1240/3000\n",
      "163/163 [==============================] - 0s 24us/step - loss: 0.1837 - acc: 0.9202 - val_loss: 1.1180 - val_acc: 0.6667\n",
      "Epoch 1241/3000\n",
      "163/163 [==============================] - 0s 26us/step - loss: 0.1833 - acc: 0.9141 - val_loss: 1.0468 - val_acc: 0.6296\n",
      "Epoch 1242/3000\n",
      "163/163 [==============================] - 0s 25us/step - loss: 0.1838 - acc: 0.9202 - val_loss: 1.1170 - val_acc: 0.6667\n",
      "Epoch 1243/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1839 - acc: 0.9080 - val_loss: 1.0355 - val_acc: 0.6296\n",
      "Epoch 1244/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1831 - acc: 0.9202 - val_loss: 1.1174 - val_acc: 0.6667\n",
      "Epoch 1245/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1839 - acc: 0.9080 - val_loss: 1.0358 - val_acc: 0.6667\n",
      "Epoch 1246/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1832 - acc: 0.9202 - val_loss: 1.1244 - val_acc: 0.6667\n",
      "Epoch 1247/3000\n",
      "163/163 [==============================] - 0s 25us/step - loss: 0.1837 - acc: 0.9080 - val_loss: 1.0302 - val_acc: 0.6667\n",
      "Epoch 1248/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.1837 - acc: 0.9202 - val_loss: 1.1524 - val_acc: 0.6667\n",
      "Epoch 1249/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1857 - acc: 0.9141 - val_loss: 1.0080 - val_acc: 0.7037\n",
      "Epoch 1250/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.1888 - acc: 0.9141 - val_loss: 1.1780 - val_acc: 0.6667\n",
      "Epoch 1251/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1914 - acc: 0.9080 - val_loss: 1.0110 - val_acc: 0.7037\n",
      "Epoch 1252/3000\n",
      "163/163 [==============================] - 0s 26us/step - loss: 0.1863 - acc: 0.9202 - val_loss: 1.1556 - val_acc: 0.6667\n",
      "Epoch 1253/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1868 - acc: 0.9080 - val_loss: 1.0169 - val_acc: 0.6667\n",
      "Epoch 1254/3000\n",
      "163/163 [==============================] - 0s 26us/step - loss: 0.1839 - acc: 0.9141 - val_loss: 1.1333 - val_acc: 0.6667\n",
      "Epoch 1255/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1835 - acc: 0.9018 - val_loss: 1.0369 - val_acc: 0.6667\n",
      "Epoch 1256/3000\n",
      "163/163 [==============================] - 0s 25us/step - loss: 0.1812 - acc: 0.9141 - val_loss: 1.1228 - val_acc: 0.6667\n",
      "Epoch 1257/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1820 - acc: 0.9018 - val_loss: 1.0460 - val_acc: 0.6296\n",
      "Epoch 1258/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1802 - acc: 0.9080 - val_loss: 1.1137 - val_acc: 0.6667\n",
      "Epoch 1259/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1809 - acc: 0.9018 - val_loss: 1.0505 - val_acc: 0.6296\n",
      "Epoch 1260/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1802 - acc: 0.9202 - val_loss: 1.1248 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1261/3000\n",
      "163/163 [==============================] - 0s 27us/step - loss: 0.1818 - acc: 0.9018 - val_loss: 1.0473 - val_acc: 0.6296\n",
      "Epoch 1262/3000\n",
      "163/163 [==============================] - 0s 24us/step - loss: 0.1800 - acc: 0.9202 - val_loss: 1.1493 - val_acc: 0.6667\n",
      "Epoch 1263/3000\n",
      "163/163 [==============================] - 0s 25us/step - loss: 0.1829 - acc: 0.9018 - val_loss: 1.0273 - val_acc: 0.6667\n",
      "Epoch 1264/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1837 - acc: 0.9202 - val_loss: 1.1852 - val_acc: 0.6667\n",
      "Epoch 1265/3000\n",
      "163/163 [==============================] - 0s 25us/step - loss: 0.1894 - acc: 0.9141 - val_loss: 1.0069 - val_acc: 0.7037\n",
      "Epoch 1266/3000\n",
      "163/163 [==============================] - 0s 24us/step - loss: 0.1892 - acc: 0.9080 - val_loss: 1.1850 - val_acc: 0.6667\n",
      "Epoch 1267/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1891 - acc: 0.9141 - val_loss: 1.0220 - val_acc: 0.6667\n",
      "Epoch 1268/3000\n",
      "163/163 [==============================] - 0s 27us/step - loss: 0.1845 - acc: 0.9202 - val_loss: 1.1432 - val_acc: 0.6667\n",
      "Epoch 1269/3000\n",
      "163/163 [==============================] - 0s 26us/step - loss: 0.1833 - acc: 0.9141 - val_loss: 1.0498 - val_acc: 0.6667\n",
      "Epoch 1270/3000\n",
      "163/163 [==============================] - 0s 26us/step - loss: 0.1802 - acc: 0.9202 - val_loss: 1.1295 - val_acc: 0.6667\n",
      "Epoch 1271/3000\n",
      "163/163 [==============================] - 0s 25us/step - loss: 0.1808 - acc: 0.9141 - val_loss: 1.0580 - val_acc: 0.6296\n",
      "Epoch 1272/3000\n",
      "163/163 [==============================] - 0s 25us/step - loss: 0.1803 - acc: 0.9202 - val_loss: 1.1209 - val_acc: 0.6667\n",
      "Epoch 1273/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1801 - acc: 0.9141 - val_loss: 1.0652 - val_acc: 0.6296\n",
      "Epoch 1274/3000\n",
      "163/163 [==============================] - 0s 27us/step - loss: 0.1799 - acc: 0.9141 - val_loss: 1.1219 - val_acc: 0.6667\n",
      "Epoch 1275/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.1783 - acc: 0.9141 - val_loss: 1.0666 - val_acc: 0.6296\n",
      "Epoch 1276/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1789 - acc: 0.9141 - val_loss: 1.1336 - val_acc: 0.6667\n",
      "Epoch 1277/3000\n",
      "163/163 [==============================] - 0s 25us/step - loss: 0.1800 - acc: 0.9080 - val_loss: 1.0579 - val_acc: 0.6667\n",
      "Epoch 1278/3000\n",
      "163/163 [==============================] - 0s 26us/step - loss: 0.1800 - acc: 0.9202 - val_loss: 1.1545 - val_acc: 0.6667\n",
      "Epoch 1279/3000\n",
      "163/163 [==============================] - 0s 25us/step - loss: 0.1816 - acc: 0.9141 - val_loss: 1.0297 - val_acc: 0.6667\n",
      "Epoch 1280/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1825 - acc: 0.9264 - val_loss: 1.1730 - val_acc: 0.6667\n",
      "Epoch 1281/3000\n",
      "163/163 [==============================] - 0s 27us/step - loss: 0.1852 - acc: 0.9141 - val_loss: 1.0279 - val_acc: 0.7037\n",
      "Epoch 1282/3000\n",
      "163/163 [==============================] - 0s 24us/step - loss: 0.1854 - acc: 0.9202 - val_loss: 1.1751 - val_acc: 0.6667\n",
      "Epoch 1283/3000\n",
      "163/163 [==============================] - 0s 25us/step - loss: 0.1853 - acc: 0.9141 - val_loss: 1.0297 - val_acc: 0.7037\n",
      "Epoch 1284/3000\n",
      "163/163 [==============================] - 0s 24us/step - loss: 0.1835 - acc: 0.9202 - val_loss: 1.1597 - val_acc: 0.6667\n",
      "Epoch 1285/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.1845 - acc: 0.9080 - val_loss: 1.0314 - val_acc: 0.7037\n",
      "Epoch 1286/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1813 - acc: 0.9202 - val_loss: 1.1596 - val_acc: 0.6667\n",
      "Epoch 1287/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1823 - acc: 0.8957 - val_loss: 1.0522 - val_acc: 0.6667\n",
      "Epoch 1288/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.1780 - acc: 0.9202 - val_loss: 1.1416 - val_acc: 0.6667\n",
      "Epoch 1289/3000\n",
      "163/163 [==============================] - 0s 25us/step - loss: 0.1785 - acc: 0.9018 - val_loss: 1.0662 - val_acc: 0.6296\n",
      "Epoch 1290/3000\n",
      "163/163 [==============================] - 0s 27us/step - loss: 0.1767 - acc: 0.9202 - val_loss: 1.1368 - val_acc: 0.6667\n",
      "Epoch 1291/3000\n",
      "163/163 [==============================] - 0s 26us/step - loss: 0.1779 - acc: 0.9080 - val_loss: 1.0525 - val_acc: 0.6667\n",
      "Epoch 1292/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1777 - acc: 0.9202 - val_loss: 1.1515 - val_acc: 0.6667\n",
      "Epoch 1293/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1796 - acc: 0.8957 - val_loss: 1.0503 - val_acc: 0.6667\n",
      "Epoch 1294/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1782 - acc: 0.9202 - val_loss: 1.1595 - val_acc: 0.6667\n",
      "Epoch 1295/3000\n",
      "163/163 [==============================] - 0s 26us/step - loss: 0.1812 - acc: 0.9141 - val_loss: 1.0429 - val_acc: 0.7037\n",
      "Epoch 1296/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.1830 - acc: 0.9202 - val_loss: 1.1918 - val_acc: 0.6667\n",
      "Epoch 1297/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.1839 - acc: 0.9141 - val_loss: 1.0456 - val_acc: 0.7037\n",
      "Epoch 1298/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1817 - acc: 0.9202 - val_loss: 1.1794 - val_acc: 0.6667\n",
      "Epoch 1299/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1822 - acc: 0.9141 - val_loss: 1.0541 - val_acc: 0.7037\n",
      "Epoch 1300/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.1797 - acc: 0.9202 - val_loss: 1.1633 - val_acc: 0.6667\n",
      "Epoch 1301/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.1797 - acc: 0.9080 - val_loss: 1.0731 - val_acc: 0.6667\n",
      "Epoch 1302/3000\n",
      "163/163 [==============================] - 0s 25us/step - loss: 0.1777 - acc: 0.9202 - val_loss: 1.1468 - val_acc: 0.6667\n",
      "Epoch 1303/3000\n",
      "163/163 [==============================] - 0s 26us/step - loss: 0.1778 - acc: 0.9202 - val_loss: 1.0671 - val_acc: 0.6296\n",
      "Epoch 1304/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1762 - acc: 0.9202 - val_loss: 1.1294 - val_acc: 0.6667\n",
      "Epoch 1305/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.1756 - acc: 0.9141 - val_loss: 1.0770 - val_acc: 0.6296\n",
      "Epoch 1306/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1752 - acc: 0.9141 - val_loss: 1.1398 - val_acc: 0.6667\n",
      "Epoch 1307/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1763 - acc: 0.9202 - val_loss: 1.0768 - val_acc: 0.6667\n",
      "Epoch 1308/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1768 - acc: 0.9202 - val_loss: 1.1584 - val_acc: 0.6667\n",
      "Epoch 1309/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.1780 - acc: 0.9141 - val_loss: 1.0559 - val_acc: 0.6667\n",
      "Epoch 1310/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1782 - acc: 0.9202 - val_loss: 1.1909 - val_acc: 0.6667\n",
      "Epoch 1311/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1808 - acc: 0.9141 - val_loss: 1.0402 - val_acc: 0.7037\n",
      "Epoch 1312/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1831 - acc: 0.9202 - val_loss: 1.2059 - val_acc: 0.6667\n",
      "Epoch 1313/3000\n",
      "163/163 [==============================] - 0s 26us/step - loss: 0.1833 - acc: 0.9141 - val_loss: 1.0576 - val_acc: 0.7037\n",
      "Epoch 1314/3000\n",
      "163/163 [==============================] - 0s 25us/step - loss: 0.1800 - acc: 0.9264 - val_loss: 1.1889 - val_acc: 0.6667\n",
      "Epoch 1315/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1824 - acc: 0.9080 - val_loss: 1.0407 - val_acc: 0.7037\n",
      "Epoch 1316/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1809 - acc: 0.9141 - val_loss: 1.1821 - val_acc: 0.6667\n",
      "Epoch 1317/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.1808 - acc: 0.9018 - val_loss: 1.0640 - val_acc: 0.6667\n",
      "Epoch 1318/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.1756 - acc: 0.9202 - val_loss: 1.1533 - val_acc: 0.6667\n",
      "Epoch 1319/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.1761 - acc: 0.9080 - val_loss: 1.0676 - val_acc: 0.6667\n",
      "Epoch 1320/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.1753 - acc: 0.9202 - val_loss: 1.1528 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1321/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.1759 - acc: 0.8957 - val_loss: 1.0768 - val_acc: 0.6296\n",
      "Epoch 1322/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1746 - acc: 0.9141 - val_loss: 1.1522 - val_acc: 0.6667\n",
      "Epoch 1323/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1744 - acc: 0.9141 - val_loss: 1.0779 - val_acc: 0.6667\n",
      "Epoch 1324/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1738 - acc: 0.9202 - val_loss: 1.1740 - val_acc: 0.6667\n",
      "Epoch 1325/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1766 - acc: 0.9018 - val_loss: 1.0640 - val_acc: 0.6667\n",
      "Epoch 1326/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1765 - acc: 0.9202 - val_loss: 1.2050 - val_acc: 0.6667\n",
      "Epoch 1327/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.1806 - acc: 0.9080 - val_loss: 1.0509 - val_acc: 0.7037\n",
      "Epoch 1328/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1805 - acc: 0.9202 - val_loss: 1.2126 - val_acc: 0.6667\n",
      "Epoch 1329/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1847 - acc: 0.9080 - val_loss: 1.0421 - val_acc: 0.7037\n",
      "Epoch 1330/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1808 - acc: 0.9202 - val_loss: 1.1820 - val_acc: 0.6667\n",
      "Epoch 1331/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1792 - acc: 0.9141 - val_loss: 1.0727 - val_acc: 0.6667\n",
      "Epoch 1332/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1746 - acc: 0.9202 - val_loss: 1.1572 - val_acc: 0.6667\n",
      "Epoch 1333/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1749 - acc: 0.9141 - val_loss: 1.0775 - val_acc: 0.6667\n",
      "Epoch 1334/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.1732 - acc: 0.9202 - val_loss: 1.1583 - val_acc: 0.6667\n",
      "Epoch 1335/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.1736 - acc: 0.9141 - val_loss: 1.0838 - val_acc: 0.6667\n",
      "Epoch 1336/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.1740 - acc: 0.9202 - val_loss: 1.1848 - val_acc: 0.6667\n",
      "Epoch 1337/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.1762 - acc: 0.8957 - val_loss: 1.0766 - val_acc: 0.6667\n",
      "Epoch 1338/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.1749 - acc: 0.9202 - val_loss: 1.1958 - val_acc: 0.6667\n",
      "Epoch 1339/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1762 - acc: 0.9080 - val_loss: 1.0740 - val_acc: 0.6667\n",
      "Epoch 1340/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1743 - acc: 0.9202 - val_loss: 1.1974 - val_acc: 0.6667\n",
      "Epoch 1341/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.1772 - acc: 0.9141 - val_loss: 1.0617 - val_acc: 0.7037\n",
      "Epoch 1342/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.1759 - acc: 0.9202 - val_loss: 1.1896 - val_acc: 0.6667\n",
      "Epoch 1343/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1779 - acc: 0.9141 - val_loss: 1.0617 - val_acc: 0.7037\n",
      "Epoch 1344/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.1765 - acc: 0.9202 - val_loss: 1.1870 - val_acc: 0.6667\n",
      "Epoch 1345/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.1774 - acc: 0.9141 - val_loss: 1.0738 - val_acc: 0.7037\n",
      "Epoch 1346/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.1740 - acc: 0.9202 - val_loss: 1.1783 - val_acc: 0.6667\n",
      "Epoch 1347/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1759 - acc: 0.9080 - val_loss: 1.0709 - val_acc: 0.7037\n",
      "Epoch 1348/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1754 - acc: 0.9202 - val_loss: 1.1932 - val_acc: 0.6667\n",
      "Epoch 1349/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1761 - acc: 0.9018 - val_loss: 1.0801 - val_acc: 0.6667\n",
      "Epoch 1350/3000\n",
      "163/163 [==============================] - 0s 26us/step - loss: 0.1728 - acc: 0.9264 - val_loss: 1.1871 - val_acc: 0.6667\n",
      "Epoch 1351/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1744 - acc: 0.9018 - val_loss: 1.0903 - val_acc: 0.6667\n",
      "Epoch 1352/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1715 - acc: 0.9264 - val_loss: 1.1884 - val_acc: 0.6667\n",
      "Epoch 1353/3000\n",
      "163/163 [==============================] - 0s 26us/step - loss: 0.1733 - acc: 0.9080 - val_loss: 1.0880 - val_acc: 0.7037\n",
      "Epoch 1354/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.1723 - acc: 0.9202 - val_loss: 1.2014 - val_acc: 0.6667\n",
      "Epoch 1355/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1754 - acc: 0.9141 - val_loss: 1.0654 - val_acc: 0.7037\n",
      "Epoch 1356/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1759 - acc: 0.9202 - val_loss: 1.2100 - val_acc: 0.6667\n",
      "Epoch 1357/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1779 - acc: 0.9141 - val_loss: 1.0709 - val_acc: 0.7037\n",
      "Epoch 1358/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.1746 - acc: 0.9264 - val_loss: 1.2036 - val_acc: 0.6667\n",
      "Epoch 1359/3000\n",
      "163/163 [==============================] - 0s 27us/step - loss: 0.1765 - acc: 0.9141 - val_loss: 1.0737 - val_acc: 0.7037\n",
      "Epoch 1360/3000\n",
      "163/163 [==============================] - 0s 27us/step - loss: 0.1743 - acc: 0.9202 - val_loss: 1.1817 - val_acc: 0.6667\n",
      "Epoch 1361/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.1732 - acc: 0.9141 - val_loss: 1.0835 - val_acc: 0.7037\n",
      "Epoch 1362/3000\n",
      "163/163 [==============================] - 0s 26us/step - loss: 0.1718 - acc: 0.9202 - val_loss: 1.1956 - val_acc: 0.6667\n",
      "Epoch 1363/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.1743 - acc: 0.8957 - val_loss: 1.0835 - val_acc: 0.7037\n",
      "Epoch 1364/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1721 - acc: 0.9202 - val_loss: 1.1818 - val_acc: 0.6667\n",
      "Epoch 1365/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.1710 - acc: 0.9080 - val_loss: 1.0949 - val_acc: 0.7037\n",
      "Epoch 1366/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1701 - acc: 0.9325 - val_loss: 1.1824 - val_acc: 0.6667\n",
      "Epoch 1367/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1712 - acc: 0.9141 - val_loss: 1.0960 - val_acc: 0.7037\n",
      "Epoch 1368/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.1715 - acc: 0.9202 - val_loss: 1.2219 - val_acc: 0.6667\n",
      "Epoch 1369/3000\n",
      "163/163 [==============================] - 0s 26us/step - loss: 0.1763 - acc: 0.9080 - val_loss: 1.0692 - val_acc: 0.7037\n",
      "Epoch 1370/3000\n",
      "163/163 [==============================] - 0s 24us/step - loss: 0.1745 - acc: 0.9202 - val_loss: 1.2202 - val_acc: 0.6296\n",
      "Epoch 1371/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1773 - acc: 0.9141 - val_loss: 1.0747 - val_acc: 0.7037\n",
      "Epoch 1372/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.1749 - acc: 0.9141 - val_loss: 1.2126 - val_acc: 0.6296\n",
      "Epoch 1373/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1738 - acc: 0.9141 - val_loss: 1.0905 - val_acc: 0.7037\n",
      "Epoch 1374/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1702 - acc: 0.9202 - val_loss: 1.1899 - val_acc: 0.6667\n",
      "Epoch 1375/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.1717 - acc: 0.9141 - val_loss: 1.0878 - val_acc: 0.7037\n",
      "Epoch 1376/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.1707 - acc: 0.9202 - val_loss: 1.1987 - val_acc: 0.6667\n",
      "Epoch 1377/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1713 - acc: 0.9080 - val_loss: 1.0943 - val_acc: 0.7037\n",
      "Epoch 1378/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.1695 - acc: 0.9202 - val_loss: 1.2112 - val_acc: 0.7037\n",
      "Epoch 1379/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.1710 - acc: 0.9141 - val_loss: 1.0946 - val_acc: 0.7037\n",
      "Epoch 1380/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.1684 - acc: 0.9264 - val_loss: 1.2150 - val_acc: 0.7037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1381/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.1701 - acc: 0.9202 - val_loss: 1.0921 - val_acc: 0.7037\n",
      "Epoch 1382/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.1685 - acc: 0.9264 - val_loss: 1.2113 - val_acc: 0.7037\n",
      "Epoch 1383/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.1691 - acc: 0.9141 - val_loss: 1.0978 - val_acc: 0.7037\n",
      "Epoch 1384/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1667 - acc: 0.9264 - val_loss: 1.1932 - val_acc: 0.7037\n",
      "Epoch 1385/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1671 - acc: 0.9202 - val_loss: 1.1058 - val_acc: 0.7037\n",
      "Epoch 1386/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1676 - acc: 0.9202 - val_loss: 1.2128 - val_acc: 0.7037\n",
      "Epoch 1387/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.1684 - acc: 0.9202 - val_loss: 1.0966 - val_acc: 0.7037\n",
      "Epoch 1388/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1686 - acc: 0.9202 - val_loss: 1.2239 - val_acc: 0.6667\n",
      "Epoch 1389/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.1715 - acc: 0.9202 - val_loss: 1.0924 - val_acc: 0.7037\n",
      "Epoch 1390/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1702 - acc: 0.9202 - val_loss: 1.2307 - val_acc: 0.6667\n",
      "Epoch 1391/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1699 - acc: 0.9264 - val_loss: 1.1011 - val_acc: 0.7037\n",
      "Epoch 1392/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1683 - acc: 0.9202 - val_loss: 1.2001 - val_acc: 0.7037\n",
      "Epoch 1393/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1651 - acc: 0.9202 - val_loss: 1.1131 - val_acc: 0.7037\n",
      "Epoch 1394/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1650 - acc: 0.9202 - val_loss: 1.2033 - val_acc: 0.7037\n",
      "Epoch 1395/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1663 - acc: 0.9202 - val_loss: 1.0982 - val_acc: 0.7037\n",
      "Epoch 1396/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1647 - acc: 0.9325 - val_loss: 1.1973 - val_acc: 0.7037\n",
      "Epoch 1397/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.1659 - acc: 0.9141 - val_loss: 1.0992 - val_acc: 0.7037\n",
      "Epoch 1398/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.1646 - acc: 0.9264 - val_loss: 1.2027 - val_acc: 0.7037\n",
      "Epoch 1399/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.1654 - acc: 0.9080 - val_loss: 1.1003 - val_acc: 0.7037\n",
      "Epoch 1400/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.1657 - acc: 0.9264 - val_loss: 1.2210 - val_acc: 0.6667\n",
      "Epoch 1401/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1684 - acc: 0.9202 - val_loss: 1.0895 - val_acc: 0.7037\n",
      "Epoch 1402/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.1688 - acc: 0.9141 - val_loss: 1.2358 - val_acc: 0.6667\n",
      "Epoch 1403/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1728 - acc: 0.9264 - val_loss: 1.0912 - val_acc: 0.7037\n",
      "Epoch 1404/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.1696 - acc: 0.9202 - val_loss: 1.2254 - val_acc: 0.6667\n",
      "Epoch 1405/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1691 - acc: 0.9202 - val_loss: 1.1068 - val_acc: 0.7037\n",
      "Epoch 1406/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1641 - acc: 0.9264 - val_loss: 1.2070 - val_acc: 0.7037\n",
      "Epoch 1407/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.1646 - acc: 0.9202 - val_loss: 1.1185 - val_acc: 0.7037\n",
      "Epoch 1408/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1623 - acc: 0.9264 - val_loss: 1.1930 - val_acc: 0.7037\n",
      "Epoch 1409/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1617 - acc: 0.9325 - val_loss: 1.1315 - val_acc: 0.7037\n",
      "Epoch 1410/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1613 - acc: 0.9325 - val_loss: 1.1983 - val_acc: 0.7037\n",
      "Epoch 1411/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1634 - acc: 0.9325 - val_loss: 1.1324 - val_acc: 0.7037\n",
      "Epoch 1412/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1633 - acc: 0.9202 - val_loss: 1.1982 - val_acc: 0.7037\n",
      "Epoch 1413/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1632 - acc: 0.9325 - val_loss: 1.1117 - val_acc: 0.7037\n",
      "Epoch 1414/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1635 - acc: 0.9325 - val_loss: 1.2089 - val_acc: 0.7037\n",
      "Epoch 1415/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1656 - acc: 0.9202 - val_loss: 1.0921 - val_acc: 0.7037\n",
      "Epoch 1416/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1669 - acc: 0.9202 - val_loss: 1.2362 - val_acc: 0.6667\n",
      "Epoch 1417/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.1688 - acc: 0.9264 - val_loss: 1.0887 - val_acc: 0.7037\n",
      "Epoch 1418/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.1682 - acc: 0.9202 - val_loss: 1.2295 - val_acc: 0.6667\n",
      "Epoch 1419/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1692 - acc: 0.9202 - val_loss: 1.1027 - val_acc: 0.7037\n",
      "Epoch 1420/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1641 - acc: 0.9202 - val_loss: 1.2145 - val_acc: 0.7037\n",
      "Epoch 1421/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1642 - acc: 0.9202 - val_loss: 1.1117 - val_acc: 0.7037\n",
      "Epoch 1422/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1620 - acc: 0.9264 - val_loss: 1.1978 - val_acc: 0.7037\n",
      "Epoch 1423/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1620 - acc: 0.9264 - val_loss: 1.1321 - val_acc: 0.7037\n",
      "Epoch 1424/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1621 - acc: 0.9202 - val_loss: 1.2075 - val_acc: 0.7037\n",
      "Epoch 1425/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1633 - acc: 0.9325 - val_loss: 1.1407 - val_acc: 0.7037\n",
      "Epoch 1426/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1615 - acc: 0.9325 - val_loss: 1.1957 - val_acc: 0.7037\n",
      "Epoch 1427/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1617 - acc: 0.9387 - val_loss: 1.1409 - val_acc: 0.7037\n",
      "Epoch 1428/3000\n",
      "163/163 [==============================] - 0s 53us/step - loss: 0.1611 - acc: 0.9264 - val_loss: 1.2237 - val_acc: 0.7037\n",
      "Epoch 1429/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1619 - acc: 0.9325 - val_loss: 1.1221 - val_acc: 0.7037\n",
      "Epoch 1430/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1626 - acc: 0.9264 - val_loss: 1.2593 - val_acc: 0.6667\n",
      "Epoch 1431/3000\n",
      "163/163 [==============================] - 0s 55us/step - loss: 0.1670 - acc: 0.9264 - val_loss: 1.0876 - val_acc: 0.7037\n",
      "Epoch 1432/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1680 - acc: 0.9202 - val_loss: 1.2591 - val_acc: 0.6667\n",
      "Epoch 1433/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1706 - acc: 0.9264 - val_loss: 1.0959 - val_acc: 0.7037\n",
      "Epoch 1434/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1673 - acc: 0.9202 - val_loss: 1.2350 - val_acc: 0.6667\n",
      "Epoch 1435/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1681 - acc: 0.9141 - val_loss: 1.1091 - val_acc: 0.7037\n",
      "Epoch 1436/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1627 - acc: 0.9202 - val_loss: 1.2216 - val_acc: 0.7037\n",
      "Epoch 1437/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1635 - acc: 0.9080 - val_loss: 1.1247 - val_acc: 0.7037\n",
      "Epoch 1438/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1606 - acc: 0.9325 - val_loss: 1.2058 - val_acc: 0.7037\n",
      "Epoch 1439/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1600 - acc: 0.9202 - val_loss: 1.1373 - val_acc: 0.7037\n",
      "Epoch 1440/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1584 - acc: 0.9325 - val_loss: 1.2115 - val_acc: 0.7037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1441/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1601 - acc: 0.9325 - val_loss: 1.1236 - val_acc: 0.7037\n",
      "Epoch 1442/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.1606 - acc: 0.9325 - val_loss: 1.2364 - val_acc: 0.7037\n",
      "Epoch 1443/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.1627 - acc: 0.9141 - val_loss: 1.1137 - val_acc: 0.7037\n",
      "Epoch 1444/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1616 - acc: 0.9264 - val_loss: 1.2488 - val_acc: 0.6667\n",
      "Epoch 1445/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1643 - acc: 0.9202 - val_loss: 1.1105 - val_acc: 0.7037\n",
      "Epoch 1446/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.1628 - acc: 0.9325 - val_loss: 1.2505 - val_acc: 0.6667\n",
      "Epoch 1447/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1668 - acc: 0.9264 - val_loss: 1.0947 - val_acc: 0.7037\n",
      "Epoch 1448/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.1651 - acc: 0.9202 - val_loss: 1.2334 - val_acc: 0.6667\n",
      "Epoch 1449/3000\n",
      "163/163 [==============================] - 0s 53us/step - loss: 0.1650 - acc: 0.9264 - val_loss: 1.1153 - val_acc: 0.7037\n",
      "Epoch 1450/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1604 - acc: 0.9264 - val_loss: 1.2146 - val_acc: 0.7037\n",
      "Epoch 1451/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1622 - acc: 0.9141 - val_loss: 1.1199 - val_acc: 0.7037\n",
      "Epoch 1452/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1599 - acc: 0.9325 - val_loss: 1.2065 - val_acc: 0.7037\n",
      "Epoch 1453/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.1597 - acc: 0.9202 - val_loss: 1.1325 - val_acc: 0.7037\n",
      "Epoch 1454/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1577 - acc: 0.9387 - val_loss: 1.2086 - val_acc: 0.6667\n",
      "Epoch 1455/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1587 - acc: 0.9325 - val_loss: 1.1412 - val_acc: 0.7037\n",
      "Epoch 1456/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1586 - acc: 0.9387 - val_loss: 1.2315 - val_acc: 0.7037\n",
      "Epoch 1457/3000\n",
      "163/163 [==============================] - 0s 53us/step - loss: 0.1602 - acc: 0.9264 - val_loss: 1.1290 - val_acc: 0.7037\n",
      "Epoch 1458/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1593 - acc: 0.9325 - val_loss: 1.2571 - val_acc: 0.7037\n",
      "Epoch 1459/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1639 - acc: 0.9202 - val_loss: 1.1124 - val_acc: 0.7407\n",
      "Epoch 1460/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1645 - acc: 0.9325 - val_loss: 1.2731 - val_acc: 0.6667\n",
      "Epoch 1461/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1679 - acc: 0.9202 - val_loss: 1.1169 - val_acc: 0.7037\n",
      "Epoch 1462/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1633 - acc: 0.9141 - val_loss: 1.2547 - val_acc: 0.6667\n",
      "Epoch 1463/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1644 - acc: 0.9264 - val_loss: 1.1247 - val_acc: 0.7037\n",
      "Epoch 1464/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1602 - acc: 0.9264 - val_loss: 1.2329 - val_acc: 0.6667\n",
      "Epoch 1465/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1606 - acc: 0.9202 - val_loss: 1.1413 - val_acc: 0.7037\n",
      "Epoch 1466/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1569 - acc: 0.9325 - val_loss: 1.2208 - val_acc: 0.6667\n",
      "Epoch 1467/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1569 - acc: 0.9325 - val_loss: 1.1551 - val_acc: 0.7037\n",
      "Epoch 1468/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1570 - acc: 0.9264 - val_loss: 1.2170 - val_acc: 0.6667\n",
      "Epoch 1469/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1568 - acc: 0.9325 - val_loss: 1.1602 - val_acc: 0.7037\n",
      "Epoch 1470/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1568 - acc: 0.9264 - val_loss: 1.2312 - val_acc: 0.7037\n",
      "Epoch 1471/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1592 - acc: 0.9387 - val_loss: 1.1238 - val_acc: 0.7037\n",
      "Epoch 1472/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1588 - acc: 0.9325 - val_loss: 1.2485 - val_acc: 0.6667\n",
      "Epoch 1473/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1602 - acc: 0.9264 - val_loss: 1.1156 - val_acc: 0.7037\n",
      "Epoch 1474/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.1599 - acc: 0.9325 - val_loss: 1.2656 - val_acc: 0.6667\n",
      "Epoch 1475/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1641 - acc: 0.9264 - val_loss: 1.1202 - val_acc: 0.7407\n",
      "Epoch 1476/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1630 - acc: 0.9202 - val_loss: 1.2662 - val_acc: 0.6667\n",
      "Epoch 1477/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1632 - acc: 0.9264 - val_loss: 1.1314 - val_acc: 0.7037\n",
      "Epoch 1478/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1590 - acc: 0.9264 - val_loss: 1.2508 - val_acc: 0.6667\n",
      "Epoch 1479/3000\n",
      "163/163 [==============================] - 0s 61us/step - loss: 0.1619 - acc: 0.9141 - val_loss: 1.1257 - val_acc: 0.7037\n",
      "Epoch 1480/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1606 - acc: 0.9202 - val_loss: 1.2464 - val_acc: 0.6296\n",
      "Epoch 1481/3000\n",
      "163/163 [==============================] - 0s 53us/step - loss: 0.1604 - acc: 0.9202 - val_loss: 1.1381 - val_acc: 0.7037\n",
      "Epoch 1482/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1569 - acc: 0.9387 - val_loss: 1.2362 - val_acc: 0.7037\n",
      "Epoch 1483/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.1580 - acc: 0.9264 - val_loss: 1.1420 - val_acc: 0.7037\n",
      "Epoch 1484/3000\n",
      "163/163 [==============================] - 0s 56us/step - loss: 0.1560 - acc: 0.9387 - val_loss: 1.2461 - val_acc: 0.7037\n",
      "Epoch 1485/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1570 - acc: 0.9325 - val_loss: 1.1412 - val_acc: 0.7037\n",
      "Epoch 1486/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1566 - acc: 0.9387 - val_loss: 1.2571 - val_acc: 0.7037\n",
      "Epoch 1487/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.1602 - acc: 0.9202 - val_loss: 1.1142 - val_acc: 0.7037\n",
      "Epoch 1488/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.1607 - acc: 0.9264 - val_loss: 1.2740 - val_acc: 0.6667\n",
      "Epoch 1489/3000\n",
      "163/163 [==============================] - 0s 55us/step - loss: 0.1629 - acc: 0.9202 - val_loss: 1.1235 - val_acc: 0.7037\n",
      "Epoch 1490/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1588 - acc: 0.9387 - val_loss: 1.2460 - val_acc: 0.6667\n",
      "Epoch 1491/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1603 - acc: 0.9264 - val_loss: 1.1289 - val_acc: 0.7037\n",
      "Epoch 1492/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1582 - acc: 0.9264 - val_loss: 1.2431 - val_acc: 0.6667\n",
      "Epoch 1493/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1585 - acc: 0.9264 - val_loss: 1.1343 - val_acc: 0.7037\n",
      "Epoch 1494/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1557 - acc: 0.9325 - val_loss: 1.2240 - val_acc: 0.7037\n",
      "Epoch 1495/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1553 - acc: 0.9325 - val_loss: 1.1424 - val_acc: 0.7037\n",
      "Epoch 1496/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1552 - acc: 0.9387 - val_loss: 1.2255 - val_acc: 0.6667\n",
      "Epoch 1497/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1555 - acc: 0.9325 - val_loss: 1.1581 - val_acc: 0.7037\n",
      "Epoch 1498/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1555 - acc: 0.9387 - val_loss: 1.2624 - val_acc: 0.7037\n",
      "Epoch 1499/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.1588 - acc: 0.9264 - val_loss: 1.1375 - val_acc: 0.7037\n",
      "Epoch 1500/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1592 - acc: 0.9387 - val_loss: 1.2867 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1501/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1615 - acc: 0.9202 - val_loss: 1.1351 - val_acc: 0.7407\n",
      "Epoch 1502/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.1588 - acc: 0.9387 - val_loss: 1.2820 - val_acc: 0.6667\n",
      "Epoch 1503/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1614 - acc: 0.9202 - val_loss: 1.1321 - val_acc: 0.7037\n",
      "Epoch 1504/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1572 - acc: 0.9325 - val_loss: 1.2632 - val_acc: 0.7037\n",
      "Epoch 1505/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1581 - acc: 0.9264 - val_loss: 1.1441 - val_acc: 0.7037\n",
      "Epoch 1506/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1555 - acc: 0.9387 - val_loss: 1.2473 - val_acc: 0.6667\n",
      "Epoch 1507/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1554 - acc: 0.9264 - val_loss: 1.1612 - val_acc: 0.7037\n",
      "Epoch 1508/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1531 - acc: 0.9387 - val_loss: 1.2501 - val_acc: 0.7037\n",
      "Epoch 1509/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1552 - acc: 0.9387 - val_loss: 1.1378 - val_acc: 0.7037\n",
      "Epoch 1510/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.1550 - acc: 0.9387 - val_loss: 1.2649 - val_acc: 0.6667\n",
      "Epoch 1511/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1581 - acc: 0.9202 - val_loss: 1.1354 - val_acc: 0.7037\n",
      "Epoch 1512/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1554 - acc: 0.9387 - val_loss: 1.2684 - val_acc: 0.7037\n",
      "Epoch 1513/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1588 - acc: 0.9202 - val_loss: 1.1331 - val_acc: 0.7037\n",
      "Epoch 1514/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1566 - acc: 0.9387 - val_loss: 1.2644 - val_acc: 0.6667\n",
      "Epoch 1515/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1578 - acc: 0.9264 - val_loss: 1.1390 - val_acc: 0.7407\n",
      "Epoch 1516/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1559 - acc: 0.9387 - val_loss: 1.2616 - val_acc: 0.6667\n",
      "Epoch 1517/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1594 - acc: 0.9264 - val_loss: 1.1324 - val_acc: 0.7407\n",
      "Epoch 1518/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1572 - acc: 0.9387 - val_loss: 1.2630 - val_acc: 0.6667\n",
      "Epoch 1519/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.1579 - acc: 0.9264 - val_loss: 1.1438 - val_acc: 0.7037\n",
      "Epoch 1520/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1544 - acc: 0.9387 - val_loss: 1.2371 - val_acc: 0.6667\n",
      "Epoch 1521/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.1538 - acc: 0.9325 - val_loss: 1.1574 - val_acc: 0.7037\n",
      "Epoch 1522/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1527 - acc: 0.9387 - val_loss: 1.2340 - val_acc: 0.6667\n",
      "Epoch 1523/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1525 - acc: 0.9325 - val_loss: 1.1579 - val_acc: 0.7037\n",
      "Epoch 1524/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.1528 - acc: 0.9387 - val_loss: 1.2422 - val_acc: 0.6667\n",
      "Epoch 1525/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1543 - acc: 0.9325 - val_loss: 1.1517 - val_acc: 0.7037\n",
      "Epoch 1526/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1540 - acc: 0.9387 - val_loss: 1.2548 - val_acc: 0.6296\n",
      "Epoch 1527/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1541 - acc: 0.9202 - val_loss: 1.1645 - val_acc: 0.7407\n",
      "Epoch 1528/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1539 - acc: 0.9387 - val_loss: 1.3090 - val_acc: 0.6667\n",
      "Epoch 1529/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1605 - acc: 0.9264 - val_loss: 1.1294 - val_acc: 0.7407\n",
      "Epoch 1530/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1615 - acc: 0.9264 - val_loss: 1.3040 - val_acc: 0.6296\n",
      "Epoch 1531/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.1634 - acc: 0.9202 - val_loss: 1.1349 - val_acc: 0.7407\n",
      "Epoch 1532/3000\n",
      "163/163 [==============================] - 0s 62us/step - loss: 0.1574 - acc: 0.9325 - val_loss: 1.2600 - val_acc: 0.6667\n",
      "Epoch 1533/3000\n",
      "163/163 [==============================] - 0s 57us/step - loss: 0.1562 - acc: 0.9202 - val_loss: 1.1541 - val_acc: 0.7037\n",
      "Epoch 1534/3000\n",
      "163/163 [==============================] - 0s 59us/step - loss: 0.1516 - acc: 0.9387 - val_loss: 1.2433 - val_acc: 0.6667\n",
      "Epoch 1535/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1522 - acc: 0.9325 - val_loss: 1.1649 - val_acc: 0.7037\n",
      "Epoch 1536/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1519 - acc: 0.9387 - val_loss: 1.2280 - val_acc: 0.6667\n",
      "Epoch 1537/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1526 - acc: 0.9325 - val_loss: 1.1935 - val_acc: 0.6667\n",
      "Epoch 1538/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1506 - acc: 0.9387 - val_loss: 1.2288 - val_acc: 0.6667\n",
      "Epoch 1539/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1498 - acc: 0.9325 - val_loss: 1.1976 - val_acc: 0.6296\n",
      "Epoch 1540/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.1492 - acc: 0.9325 - val_loss: 1.2374 - val_acc: 0.6667\n",
      "Epoch 1541/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1490 - acc: 0.9387 - val_loss: 1.1897 - val_acc: 0.7037\n",
      "Epoch 1542/3000\n",
      "163/163 [==============================] - 0s 54us/step - loss: 0.1486 - acc: 0.9448 - val_loss: 1.2668 - val_acc: 0.6667\n",
      "Epoch 1543/3000\n",
      "163/163 [==============================] - 0s 53us/step - loss: 0.1520 - acc: 0.9387 - val_loss: 1.1501 - val_acc: 0.7407\n",
      "Epoch 1544/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1567 - acc: 0.9325 - val_loss: 1.3465 - val_acc: 0.6667\n",
      "Epoch 1545/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1671 - acc: 0.9141 - val_loss: 1.1295 - val_acc: 0.7407\n",
      "Epoch 1546/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1654 - acc: 0.9325 - val_loss: 1.3309 - val_acc: 0.6667\n",
      "Epoch 1547/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1649 - acc: 0.9141 - val_loss: 1.1403 - val_acc: 0.7407\n",
      "Epoch 1548/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1545 - acc: 0.9325 - val_loss: 1.2545 - val_acc: 0.7037\n",
      "Epoch 1549/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.1531 - acc: 0.9325 - val_loss: 1.1675 - val_acc: 0.7037\n",
      "Epoch 1550/3000\n",
      "163/163 [==============================] - 0s 61us/step - loss: 0.1497 - acc: 0.9387 - val_loss: 1.2250 - val_acc: 0.6667\n",
      "Epoch 1551/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1491 - acc: 0.9387 - val_loss: 1.1890 - val_acc: 0.7037\n",
      "Epoch 1552/3000\n",
      "163/163 [==============================] - 0s 57us/step - loss: 0.1480 - acc: 0.9448 - val_loss: 1.2218 - val_acc: 0.6667\n",
      "Epoch 1553/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1483 - acc: 0.9387 - val_loss: 1.1891 - val_acc: 0.7037\n",
      "Epoch 1554/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1498 - acc: 0.9325 - val_loss: 1.2260 - val_acc: 0.6667\n",
      "Epoch 1555/3000\n",
      "163/163 [==============================] - 0s 57us/step - loss: 0.1501 - acc: 0.9387 - val_loss: 1.1869 - val_acc: 0.7037\n",
      "Epoch 1556/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1484 - acc: 0.9448 - val_loss: 1.2354 - val_acc: 0.6667\n",
      "Epoch 1557/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.1481 - acc: 0.9387 - val_loss: 1.1793 - val_acc: 0.7407\n",
      "Epoch 1558/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1499 - acc: 0.9325 - val_loss: 1.2802 - val_acc: 0.6667\n",
      "Epoch 1559/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.1536 - acc: 0.9264 - val_loss: 1.1447 - val_acc: 0.7407\n",
      "Epoch 1560/3000\n",
      "163/163 [==============================] - 0s 54us/step - loss: 0.1551 - acc: 0.9325 - val_loss: 1.3257 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1561/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.1626 - acc: 0.9141 - val_loss: 1.1339 - val_acc: 0.7407\n",
      "Epoch 1562/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.1596 - acc: 0.9264 - val_loss: 1.2996 - val_acc: 0.6667\n",
      "Epoch 1563/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.1592 - acc: 0.9264 - val_loss: 1.1562 - val_acc: 0.7407\n",
      "Epoch 1564/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1513 - acc: 0.9387 - val_loss: 1.2690 - val_acc: 0.6667\n",
      "Epoch 1565/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1512 - acc: 0.9264 - val_loss: 1.1853 - val_acc: 0.6667\n",
      "Epoch 1566/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1502 - acc: 0.9387 - val_loss: 1.2594 - val_acc: 0.6667\n",
      "Epoch 1567/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1508 - acc: 0.9325 - val_loss: 1.1948 - val_acc: 0.6667\n",
      "Epoch 1568/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1489 - acc: 0.9325 - val_loss: 1.2670 - val_acc: 0.6667\n",
      "Epoch 1569/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1491 - acc: 0.9325 - val_loss: 1.1756 - val_acc: 0.7407\n",
      "Epoch 1570/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1482 - acc: 0.9448 - val_loss: 1.2711 - val_acc: 0.6667\n",
      "Epoch 1571/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1492 - acc: 0.9387 - val_loss: 1.1656 - val_acc: 0.7407\n",
      "Epoch 1572/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1503 - acc: 0.9387 - val_loss: 1.3015 - val_acc: 0.6667\n",
      "Epoch 1573/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1567 - acc: 0.9202 - val_loss: 1.1499 - val_acc: 0.7407\n",
      "Epoch 1574/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1558 - acc: 0.9325 - val_loss: 1.3138 - val_acc: 0.6667\n",
      "Epoch 1575/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1559 - acc: 0.9202 - val_loss: 1.1660 - val_acc: 0.7407\n",
      "Epoch 1576/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1509 - acc: 0.9387 - val_loss: 1.2879 - val_acc: 0.7037\n",
      "Epoch 1577/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1530 - acc: 0.9325 - val_loss: 1.1658 - val_acc: 0.7407\n",
      "Epoch 1578/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1488 - acc: 0.9387 - val_loss: 1.2801 - val_acc: 0.6667\n",
      "Epoch 1579/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1503 - acc: 0.9264 - val_loss: 1.1719 - val_acc: 0.7037\n",
      "Epoch 1580/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1492 - acc: 0.9387 - val_loss: 1.2669 - val_acc: 0.6667\n",
      "Epoch 1581/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.1493 - acc: 0.9325 - val_loss: 1.1840 - val_acc: 0.7037\n",
      "Epoch 1582/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.1468 - acc: 0.9448 - val_loss: 1.2647 - val_acc: 0.6667\n",
      "Epoch 1583/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.1476 - acc: 0.9325 - val_loss: 1.1831 - val_acc: 0.7037\n",
      "Epoch 1584/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1473 - acc: 0.9387 - val_loss: 1.3069 - val_acc: 0.6296\n",
      "Epoch 1585/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.1499 - acc: 0.9202 - val_loss: 1.1851 - val_acc: 0.7037\n",
      "Epoch 1586/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1494 - acc: 0.9387 - val_loss: 1.3297 - val_acc: 0.6296\n",
      "Epoch 1587/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.1550 - acc: 0.9325 - val_loss: 1.1676 - val_acc: 0.7037\n",
      "Epoch 1588/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1528 - acc: 0.9325 - val_loss: 1.3333 - val_acc: 0.6296\n",
      "Epoch 1589/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.1554 - acc: 0.9264 - val_loss: 1.1670 - val_acc: 0.7407\n",
      "Epoch 1590/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1512 - acc: 0.9325 - val_loss: 1.3028 - val_acc: 0.6296\n",
      "Epoch 1591/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1518 - acc: 0.9325 - val_loss: 1.1834 - val_acc: 0.7407\n",
      "Epoch 1592/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1463 - acc: 0.9387 - val_loss: 1.2594 - val_acc: 0.6667\n",
      "Epoch 1593/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1446 - acc: 0.9387 - val_loss: 1.1986 - val_acc: 0.7037\n",
      "Epoch 1594/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1446 - acc: 0.9387 - val_loss: 1.2596 - val_acc: 0.6667\n",
      "Epoch 1595/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.1469 - acc: 0.9325 - val_loss: 1.1957 - val_acc: 0.6667\n",
      "Epoch 1596/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1466 - acc: 0.9448 - val_loss: 1.2752 - val_acc: 0.6667\n",
      "Epoch 1597/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1475 - acc: 0.9264 - val_loss: 1.1837 - val_acc: 0.7407\n",
      "Epoch 1598/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.1463 - acc: 0.9387 - val_loss: 1.3073 - val_acc: 0.6667\n",
      "Epoch 1599/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1504 - acc: 0.9202 - val_loss: 1.1684 - val_acc: 0.7407\n",
      "Epoch 1600/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.1512 - acc: 0.9325 - val_loss: 1.3347 - val_acc: 0.6667\n",
      "Epoch 1601/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.1551 - acc: 0.9264 - val_loss: 1.1666 - val_acc: 0.7407\n",
      "Epoch 1602/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.1524 - acc: 0.9264 - val_loss: 1.3232 - val_acc: 0.6667\n",
      "Epoch 1603/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.1552 - acc: 0.9264 - val_loss: 1.1697 - val_acc: 0.7407\n",
      "Epoch 1604/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.1481 - acc: 0.9325 - val_loss: 1.2937 - val_acc: 0.6667\n",
      "Epoch 1605/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.1475 - acc: 0.9387 - val_loss: 1.1865 - val_acc: 0.7037\n",
      "Epoch 1606/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1453 - acc: 0.9387 - val_loss: 1.2641 - val_acc: 0.6667\n",
      "Epoch 1607/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1436 - acc: 0.9387 - val_loss: 1.2003 - val_acc: 0.7037\n",
      "Epoch 1608/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1432 - acc: 0.9448 - val_loss: 1.2979 - val_acc: 0.6296\n",
      "Epoch 1609/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1445 - acc: 0.9325 - val_loss: 1.2225 - val_acc: 0.6667\n",
      "Epoch 1610/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1446 - acc: 0.9448 - val_loss: 1.3157 - val_acc: 0.6296\n",
      "Epoch 1611/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1481 - acc: 0.9264 - val_loss: 1.1906 - val_acc: 0.7037\n",
      "Epoch 1612/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1469 - acc: 0.9448 - val_loss: 1.3274 - val_acc: 0.6296\n",
      "Epoch 1613/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1513 - acc: 0.9202 - val_loss: 1.1833 - val_acc: 0.7037\n",
      "Epoch 1614/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1499 - acc: 0.9325 - val_loss: 1.3387 - val_acc: 0.6296\n",
      "Epoch 1615/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1532 - acc: 0.9264 - val_loss: 1.1837 - val_acc: 0.7037\n",
      "Epoch 1616/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1477 - acc: 0.9387 - val_loss: 1.3211 - val_acc: 0.6296\n",
      "Epoch 1617/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1486 - acc: 0.9387 - val_loss: 1.1945 - val_acc: 0.7407\n",
      "Epoch 1618/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1456 - acc: 0.9448 - val_loss: 1.3041 - val_acc: 0.6296\n",
      "Epoch 1619/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1464 - acc: 0.9325 - val_loss: 1.2049 - val_acc: 0.7407\n",
      "Epoch 1620/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.1448 - acc: 0.9448 - val_loss: 1.2864 - val_acc: 0.6296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1621/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1427 - acc: 0.9448 - val_loss: 1.2207 - val_acc: 0.7037\n",
      "Epoch 1622/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1420 - acc: 0.9448 - val_loss: 1.2865 - val_acc: 0.6296\n",
      "Epoch 1623/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1430 - acc: 0.9448 - val_loss: 1.2147 - val_acc: 0.7407\n",
      "Epoch 1624/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1431 - acc: 0.9509 - val_loss: 1.2851 - val_acc: 0.6296\n",
      "Epoch 1625/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1435 - acc: 0.9448 - val_loss: 1.2099 - val_acc: 0.7407\n",
      "Epoch 1626/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1444 - acc: 0.9448 - val_loss: 1.3252 - val_acc: 0.6296\n",
      "Epoch 1627/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1473 - acc: 0.9325 - val_loss: 1.1889 - val_acc: 0.7407\n",
      "Epoch 1628/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.1493 - acc: 0.9325 - val_loss: 1.3692 - val_acc: 0.6296\n",
      "Epoch 1629/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1543 - acc: 0.9264 - val_loss: 1.1739 - val_acc: 0.7407\n",
      "Epoch 1630/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1511 - acc: 0.9325 - val_loss: 1.3457 - val_acc: 0.6296\n",
      "Epoch 1631/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1528 - acc: 0.9325 - val_loss: 1.1847 - val_acc: 0.7407\n",
      "Epoch 1632/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1480 - acc: 0.9387 - val_loss: 1.3175 - val_acc: 0.6296\n",
      "Epoch 1633/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1476 - acc: 0.9202 - val_loss: 1.2032 - val_acc: 0.7407\n",
      "Epoch 1634/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.1425 - acc: 0.9448 - val_loss: 1.2880 - val_acc: 0.6667\n",
      "Epoch 1635/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1430 - acc: 0.9325 - val_loss: 1.1956 - val_acc: 0.7407\n",
      "Epoch 1636/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.1420 - acc: 0.9509 - val_loss: 1.2712 - val_acc: 0.6667\n",
      "Epoch 1637/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1423 - acc: 0.9325 - val_loss: 1.1984 - val_acc: 0.7407\n",
      "Epoch 1638/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1406 - acc: 0.9571 - val_loss: 1.2966 - val_acc: 0.6296\n",
      "Epoch 1639/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1422 - acc: 0.9448 - val_loss: 1.2161 - val_acc: 0.7037\n",
      "Epoch 1640/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1427 - acc: 0.9448 - val_loss: 1.3077 - val_acc: 0.6296\n",
      "Epoch 1641/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1434 - acc: 0.9387 - val_loss: 1.2124 - val_acc: 0.7037\n",
      "Epoch 1642/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1437 - acc: 0.9448 - val_loss: 1.3578 - val_acc: 0.6296\n",
      "Epoch 1643/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1506 - acc: 0.9325 - val_loss: 1.1857 - val_acc: 0.7037\n",
      "Epoch 1644/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1495 - acc: 0.9325 - val_loss: 1.3628 - val_acc: 0.6296\n",
      "Epoch 1645/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1516 - acc: 0.9264 - val_loss: 1.1983 - val_acc: 0.7037\n",
      "Epoch 1646/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1465 - acc: 0.9448 - val_loss: 1.3302 - val_acc: 0.5926\n",
      "Epoch 1647/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1464 - acc: 0.9264 - val_loss: 1.2129 - val_acc: 0.7037\n",
      "Epoch 1648/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1422 - acc: 0.9509 - val_loss: 1.2959 - val_acc: 0.6667\n",
      "Epoch 1649/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1421 - acc: 0.9387 - val_loss: 1.2311 - val_acc: 0.6667\n",
      "Epoch 1650/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.1398 - acc: 0.9571 - val_loss: 1.2771 - val_acc: 0.6667\n",
      "Epoch 1651/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1398 - acc: 0.9387 - val_loss: 1.2462 - val_acc: 0.6296\n",
      "Epoch 1652/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1388 - acc: 0.9387 - val_loss: 1.2737 - val_acc: 0.6667\n",
      "Epoch 1653/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.1378 - acc: 0.9509 - val_loss: 1.2532 - val_acc: 0.6296\n",
      "Epoch 1654/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1375 - acc: 0.9509 - val_loss: 1.2708 - val_acc: 0.6667\n",
      "Epoch 1655/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1382 - acc: 0.9448 - val_loss: 1.2448 - val_acc: 0.6296\n",
      "Epoch 1656/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1383 - acc: 0.9509 - val_loss: 1.2416 - val_acc: 0.7037\n",
      "Epoch 1657/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1380 - acc: 0.9448 - val_loss: 1.2715 - val_acc: 0.6296\n",
      "Epoch 1658/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1378 - acc: 0.9448 - val_loss: 1.2102 - val_acc: 0.7407\n",
      "Epoch 1659/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1415 - acc: 0.9448 - val_loss: 1.3757 - val_acc: 0.6296\n",
      "Epoch 1660/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1527 - acc: 0.9325 - val_loss: 1.1897 - val_acc: 0.7037\n",
      "Epoch 1661/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1638 - acc: 0.9387 - val_loss: 1.4575 - val_acc: 0.5926\n",
      "Epoch 1662/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1654 - acc: 0.9202 - val_loss: 1.2127 - val_acc: 0.6667\n",
      "Epoch 1663/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1440 - acc: 0.9387 - val_loss: 1.3124 - val_acc: 0.6296\n",
      "Epoch 1664/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.1415 - acc: 0.9448 - val_loss: 1.2461 - val_acc: 0.6667\n",
      "Epoch 1665/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1385 - acc: 0.9571 - val_loss: 1.3019 - val_acc: 0.6296\n",
      "Epoch 1666/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1397 - acc: 0.9387 - val_loss: 1.2538 - val_acc: 0.6667\n",
      "Epoch 1667/3000\n",
      "163/163 [==============================] - 0s 54us/step - loss: 0.1384 - acc: 0.9387 - val_loss: 1.2984 - val_acc: 0.6296\n",
      "Epoch 1668/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1380 - acc: 0.9448 - val_loss: 1.2653 - val_acc: 0.6667\n",
      "Epoch 1669/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.1368 - acc: 0.9448 - val_loss: 1.2944 - val_acc: 0.6296\n",
      "Epoch 1670/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1362 - acc: 0.9509 - val_loss: 1.2629 - val_acc: 0.6667\n",
      "Epoch 1671/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1358 - acc: 0.9448 - val_loss: 1.2927 - val_acc: 0.6296\n",
      "Epoch 1672/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1366 - acc: 0.9509 - val_loss: 1.2630 - val_acc: 0.6667\n",
      "Epoch 1673/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.1372 - acc: 0.9387 - val_loss: 1.3069 - val_acc: 0.6296\n",
      "Epoch 1674/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.1372 - acc: 0.9448 - val_loss: 1.2489 - val_acc: 0.7037\n",
      "Epoch 1675/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.1380 - acc: 0.9571 - val_loss: 1.3431 - val_acc: 0.6296\n",
      "Epoch 1676/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1427 - acc: 0.9325 - val_loss: 1.2104 - val_acc: 0.7037\n",
      "Epoch 1677/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1529 - acc: 0.9387 - val_loss: 1.4712 - val_acc: 0.6296\n",
      "Epoch 1678/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1677 - acc: 0.9202 - val_loss: 1.1912 - val_acc: 0.7037\n",
      "Epoch 1679/3000\n",
      "163/163 [==============================] - 0s 56us/step - loss: 0.1480 - acc: 0.9509 - val_loss: 1.3448 - val_acc: 0.6296\n",
      "Epoch 1680/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1434 - acc: 0.9448 - val_loss: 1.2212 - val_acc: 0.7037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1681/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.1383 - acc: 0.9509 - val_loss: 1.2966 - val_acc: 0.6296\n",
      "Epoch 1682/3000\n",
      "163/163 [==============================] - 0s 55us/step - loss: 0.1386 - acc: 0.9448 - val_loss: 1.2313 - val_acc: 0.7037\n",
      "Epoch 1683/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1362 - acc: 0.9571 - val_loss: 1.2770 - val_acc: 0.6296\n",
      "Epoch 1684/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1362 - acc: 0.9509 - val_loss: 1.2334 - val_acc: 0.7037\n",
      "Epoch 1685/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1358 - acc: 0.9571 - val_loss: 1.2907 - val_acc: 0.6296\n",
      "Epoch 1686/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1374 - acc: 0.9509 - val_loss: 1.2282 - val_acc: 0.7037\n",
      "Epoch 1687/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1380 - acc: 0.9509 - val_loss: 1.3267 - val_acc: 0.6296\n",
      "Epoch 1688/3000\n",
      "163/163 [==============================] - 0s 55us/step - loss: 0.1406 - acc: 0.9387 - val_loss: 1.2179 - val_acc: 0.7037\n",
      "Epoch 1689/3000\n",
      "163/163 [==============================] - 0s 56us/step - loss: 0.1404 - acc: 0.9509 - val_loss: 1.3553 - val_acc: 0.6296\n",
      "Epoch 1690/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.1474 - acc: 0.9325 - val_loss: 1.1995 - val_acc: 0.7407\n",
      "Epoch 1691/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1454 - acc: 0.9387 - val_loss: 1.3557 - val_acc: 0.6296\n",
      "Epoch 1692/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1458 - acc: 0.9325 - val_loss: 1.2037 - val_acc: 0.7407\n",
      "Epoch 1693/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1413 - acc: 0.9448 - val_loss: 1.3105 - val_acc: 0.6296\n",
      "Epoch 1694/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1417 - acc: 0.9387 - val_loss: 1.2662 - val_acc: 0.7037\n",
      "Epoch 1695/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1375 - acc: 0.9509 - val_loss: 1.3433 - val_acc: 0.6296\n",
      "Epoch 1696/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.1376 - acc: 0.9509 - val_loss: 1.2700 - val_acc: 0.7037\n",
      "Epoch 1697/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1365 - acc: 0.9509 - val_loss: 1.3311 - val_acc: 0.6296\n",
      "Epoch 1698/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1367 - acc: 0.9509 - val_loss: 1.2720 - val_acc: 0.7037\n",
      "Epoch 1699/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1355 - acc: 0.9448 - val_loss: 1.3278 - val_acc: 0.6296\n",
      "Epoch 1700/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1364 - acc: 0.9509 - val_loss: 1.2769 - val_acc: 0.7037\n",
      "Epoch 1701/3000\n",
      "163/163 [==============================] - 0s 56us/step - loss: 0.1354 - acc: 0.9509 - val_loss: 1.3287 - val_acc: 0.6296\n",
      "Epoch 1702/3000\n",
      "163/163 [==============================] - 0s 68us/step - loss: 0.1346 - acc: 0.9509 - val_loss: 1.2769 - val_acc: 0.7037\n",
      "Epoch 1703/3000\n",
      "163/163 [==============================] - 0s 53us/step - loss: 0.1373 - acc: 0.9387 - val_loss: 1.3838 - val_acc: 0.5926\n",
      "Epoch 1704/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.1409 - acc: 0.9387 - val_loss: 1.2377 - val_acc: 0.7037\n",
      "Epoch 1705/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1422 - acc: 0.9387 - val_loss: 1.4281 - val_acc: 0.6296\n",
      "Epoch 1706/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.1507 - acc: 0.9264 - val_loss: 1.2023 - val_acc: 0.7037\n",
      "Epoch 1707/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.1492 - acc: 0.9387 - val_loss: 1.3603 - val_acc: 0.6296\n",
      "Epoch 1708/3000\n",
      "163/163 [==============================] - 0s 54us/step - loss: 0.1478 - acc: 0.9325 - val_loss: 1.2252 - val_acc: 0.7037\n",
      "Epoch 1709/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.1388 - acc: 0.9448 - val_loss: 1.2950 - val_acc: 0.6667\n",
      "Epoch 1710/3000\n",
      "163/163 [==============================] - 0s 57us/step - loss: 0.1359 - acc: 0.9448 - val_loss: 1.2416 - val_acc: 0.7037\n",
      "Epoch 1711/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.1335 - acc: 0.9571 - val_loss: 1.3354 - val_acc: 0.6296\n",
      "Epoch 1712/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.1340 - acc: 0.9509 - val_loss: 1.2934 - val_acc: 0.7037\n",
      "Epoch 1713/3000\n",
      "163/163 [==============================] - 0s 54us/step - loss: 0.1344 - acc: 0.9509 - val_loss: 1.3357 - val_acc: 0.6296\n",
      "Epoch 1714/3000\n",
      "163/163 [==============================] - 0s 53us/step - loss: 0.1369 - acc: 0.9448 - val_loss: 1.2906 - val_acc: 0.7037\n",
      "Epoch 1715/3000\n",
      "163/163 [==============================] - 0s 55us/step - loss: 0.1350 - acc: 0.9509 - val_loss: 1.3313 - val_acc: 0.6296\n",
      "Epoch 1716/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.1343 - acc: 0.9448 - val_loss: 1.2857 - val_acc: 0.7037\n",
      "Epoch 1717/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.1337 - acc: 0.9571 - val_loss: 1.3621 - val_acc: 0.6296\n",
      "Epoch 1718/3000\n",
      "163/163 [==============================] - 0s 55us/step - loss: 0.1364 - acc: 0.9448 - val_loss: 1.2680 - val_acc: 0.7037\n",
      "Epoch 1719/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.1390 - acc: 0.9448 - val_loss: 1.4322 - val_acc: 0.6296\n",
      "Epoch 1720/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1476 - acc: 0.9325 - val_loss: 1.2493 - val_acc: 0.7037\n",
      "Epoch 1721/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.1468 - acc: 0.9387 - val_loss: 1.4327 - val_acc: 0.6296\n",
      "Epoch 1722/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1478 - acc: 0.9264 - val_loss: 1.2520 - val_acc: 0.7037\n",
      "Epoch 1723/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1394 - acc: 0.9448 - val_loss: 1.3731 - val_acc: 0.5926\n",
      "Epoch 1724/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1394 - acc: 0.9387 - val_loss: 1.2722 - val_acc: 0.7037\n",
      "Epoch 1725/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1336 - acc: 0.9571 - val_loss: 1.3301 - val_acc: 0.6296\n",
      "Epoch 1726/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1322 - acc: 0.9509 - val_loss: 1.2937 - val_acc: 0.7037\n",
      "Epoch 1727/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1318 - acc: 0.9387 - val_loss: 1.3278 - val_acc: 0.6296\n",
      "Epoch 1728/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1329 - acc: 0.9448 - val_loss: 1.2907 - val_acc: 0.6667\n",
      "Epoch 1729/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1333 - acc: 0.9448 - val_loss: 1.3157 - val_acc: 0.6296\n",
      "Epoch 1730/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.1336 - acc: 0.9448 - val_loss: 1.2947 - val_acc: 0.6667\n",
      "Epoch 1731/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1327 - acc: 0.9448 - val_loss: 1.3163 - val_acc: 0.6296\n",
      "Epoch 1732/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1322 - acc: 0.9448 - val_loss: 1.2729 - val_acc: 0.7037\n",
      "Epoch 1733/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1321 - acc: 0.9509 - val_loss: 1.3466 - val_acc: 0.6296\n",
      "Epoch 1734/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1345 - acc: 0.9448 - val_loss: 1.2626 - val_acc: 0.7037\n",
      "Epoch 1735/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1382 - acc: 0.9448 - val_loss: 1.4378 - val_acc: 0.6296\n",
      "Epoch 1736/3000\n",
      "163/163 [==============================] - 0s 63us/step - loss: 0.1490 - acc: 0.9325 - val_loss: 1.2235 - val_acc: 0.7037\n",
      "Epoch 1737/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1535 - acc: 0.9448 - val_loss: 1.4240 - val_acc: 0.6296\n",
      "Epoch 1738/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1540 - acc: 0.9202 - val_loss: 1.2262 - val_acc: 0.7037\n",
      "Epoch 1739/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.1382 - acc: 0.9448 - val_loss: 1.3339 - val_acc: 0.6296\n",
      "Epoch 1740/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1350 - acc: 0.9448 - val_loss: 1.2544 - val_acc: 0.7037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1741/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.1310 - acc: 0.9571 - val_loss: 1.2897 - val_acc: 0.6296\n",
      "Epoch 1742/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.1300 - acc: 0.9509 - val_loss: 1.2609 - val_acc: 0.7037\n",
      "Epoch 1743/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1296 - acc: 0.9448 - val_loss: 1.2834 - val_acc: 0.6296\n",
      "Epoch 1744/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1305 - acc: 0.9509 - val_loss: 1.2663 - val_acc: 0.7037\n",
      "Epoch 1745/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1304 - acc: 0.9448 - val_loss: 1.3111 - val_acc: 0.6296\n",
      "Epoch 1746/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1328 - acc: 0.9448 - val_loss: 1.2508 - val_acc: 0.7037\n",
      "Epoch 1747/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1323 - acc: 0.9571 - val_loss: 1.3107 - val_acc: 0.6296\n",
      "Epoch 1748/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1338 - acc: 0.9448 - val_loss: 1.2401 - val_acc: 0.7037\n",
      "Epoch 1749/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1324 - acc: 0.9571 - val_loss: 1.3229 - val_acc: 0.5926\n",
      "Epoch 1750/3000\n",
      "163/163 [==============================] - 0s 57us/step - loss: 0.1340 - acc: 0.9448 - val_loss: 1.2344 - val_acc: 0.7037\n",
      "Epoch 1751/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.1359 - acc: 0.9448 - val_loss: 1.3866 - val_acc: 0.6296\n",
      "Epoch 1752/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.1433 - acc: 0.9325 - val_loss: 1.2130 - val_acc: 0.7037\n",
      "Epoch 1753/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.1458 - acc: 0.9387 - val_loss: 1.3992 - val_acc: 0.6296\n",
      "Epoch 1754/3000\n",
      "163/163 [==============================] - 0s 57us/step - loss: 0.1506 - acc: 0.9202 - val_loss: 1.2564 - val_acc: 0.7037\n",
      "Epoch 1755/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1392 - acc: 0.9387 - val_loss: 1.3872 - val_acc: 0.5926\n",
      "Epoch 1756/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1360 - acc: 0.9448 - val_loss: 1.2806 - val_acc: 0.7037\n",
      "Epoch 1757/3000\n",
      "163/163 [==============================] - 0s 62us/step - loss: 0.1307 - acc: 0.9571 - val_loss: 1.3289 - val_acc: 0.6296\n",
      "Epoch 1758/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1289 - acc: 0.9509 - val_loss: 1.2863 - val_acc: 0.7037\n",
      "Epoch 1759/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1289 - acc: 0.9448 - val_loss: 1.3256 - val_acc: 0.6296\n",
      "Epoch 1760/3000\n",
      "163/163 [==============================] - 0s 57us/step - loss: 0.1299 - acc: 0.9448 - val_loss: 1.2947 - val_acc: 0.7037\n",
      "Epoch 1761/3000\n",
      "163/163 [==============================] - 0s 54us/step - loss: 0.1302 - acc: 0.9387 - val_loss: 1.3359 - val_acc: 0.6296\n",
      "Epoch 1762/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1324 - acc: 0.9448 - val_loss: 1.2861 - val_acc: 0.6667\n",
      "Epoch 1763/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1305 - acc: 0.9509 - val_loss: 1.3324 - val_acc: 0.6296\n",
      "Epoch 1764/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1308 - acc: 0.9448 - val_loss: 1.2515 - val_acc: 0.7037\n",
      "Epoch 1765/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1308 - acc: 0.9571 - val_loss: 1.3376 - val_acc: 0.6296\n",
      "Epoch 1766/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.1326 - acc: 0.9387 - val_loss: 1.2362 - val_acc: 0.7037\n",
      "Epoch 1767/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1343 - acc: 0.9448 - val_loss: 1.4051 - val_acc: 0.6296\n",
      "Epoch 1768/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1449 - acc: 0.9264 - val_loss: 1.2344 - val_acc: 0.7037\n",
      "Epoch 1769/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1485 - acc: 0.9448 - val_loss: 1.4295 - val_acc: 0.6296\n",
      "Epoch 1770/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1499 - acc: 0.9264 - val_loss: 1.2303 - val_acc: 0.7037\n",
      "Epoch 1771/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1357 - acc: 0.9448 - val_loss: 1.3293 - val_acc: 0.5926\n",
      "Epoch 1772/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.1323 - acc: 0.9448 - val_loss: 1.2487 - val_acc: 0.7037\n",
      "Epoch 1773/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.1288 - acc: 0.9571 - val_loss: 1.2794 - val_acc: 0.6667\n",
      "Epoch 1774/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1281 - acc: 0.9509 - val_loss: 1.2451 - val_acc: 0.7037\n",
      "Epoch 1775/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.1271 - acc: 0.9448 - val_loss: 1.2675 - val_acc: 0.6667\n",
      "Epoch 1776/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.1272 - acc: 0.9509 - val_loss: 1.2395 - val_acc: 0.7037\n",
      "Epoch 1777/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1276 - acc: 0.9448 - val_loss: 1.3428 - val_acc: 0.6296\n",
      "Epoch 1778/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1304 - acc: 0.9448 - val_loss: 1.2894 - val_acc: 0.7037\n",
      "Epoch 1779/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1296 - acc: 0.9571 - val_loss: 1.3577 - val_acc: 0.6296\n",
      "Epoch 1780/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1320 - acc: 0.9448 - val_loss: 1.2783 - val_acc: 0.7037\n",
      "Epoch 1781/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1327 - acc: 0.9509 - val_loss: 1.3909 - val_acc: 0.5926\n",
      "Epoch 1782/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.1347 - acc: 0.9325 - val_loss: 1.2589 - val_acc: 0.7037\n",
      "Epoch 1783/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.1354 - acc: 0.9448 - val_loss: 1.4377 - val_acc: 0.6296\n",
      "Epoch 1784/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1450 - acc: 0.9202 - val_loss: 1.2443 - val_acc: 0.7037\n",
      "Epoch 1785/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1418 - acc: 0.9448 - val_loss: 1.4244 - val_acc: 0.6296\n",
      "Epoch 1786/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1441 - acc: 0.9264 - val_loss: 1.2540 - val_acc: 0.7037\n",
      "Epoch 1787/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.1333 - acc: 0.9448 - val_loss: 1.3570 - val_acc: 0.5926\n",
      "Epoch 1788/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1305 - acc: 0.9509 - val_loss: 1.2803 - val_acc: 0.7037\n",
      "Epoch 1789/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1280 - acc: 0.9571 - val_loss: 1.3209 - val_acc: 0.6296\n",
      "Epoch 1790/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.1275 - acc: 0.9509 - val_loss: 1.2989 - val_acc: 0.7037\n",
      "Epoch 1791/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.1276 - acc: 0.9387 - val_loss: 1.3315 - val_acc: 0.6296\n",
      "Epoch 1792/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.1282 - acc: 0.9509 - val_loss: 1.2851 - val_acc: 0.7037\n",
      "Epoch 1793/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1282 - acc: 0.9448 - val_loss: 1.3219 - val_acc: 0.6296\n",
      "Epoch 1794/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.1286 - acc: 0.9509 - val_loss: 1.2838 - val_acc: 0.7037\n",
      "Epoch 1795/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1279 - acc: 0.9448 - val_loss: 1.3326 - val_acc: 0.6296\n",
      "Epoch 1796/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1274 - acc: 0.9509 - val_loss: 1.2563 - val_acc: 0.7037\n",
      "Epoch 1797/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1293 - acc: 0.9509 - val_loss: 1.3451 - val_acc: 0.5926\n",
      "Epoch 1798/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1310 - acc: 0.9448 - val_loss: 1.2355 - val_acc: 0.7037\n",
      "Epoch 1799/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1342 - acc: 0.9387 - val_loss: 1.4082 - val_acc: 0.6296\n",
      "Epoch 1800/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1434 - acc: 0.9325 - val_loss: 1.2096 - val_acc: 0.7037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1801/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1417 - acc: 0.9448 - val_loss: 1.3920 - val_acc: 0.6296\n",
      "Epoch 1802/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.1424 - acc: 0.9264 - val_loss: 1.2139 - val_acc: 0.7037\n",
      "Epoch 1803/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1337 - acc: 0.9448 - val_loss: 1.3227 - val_acc: 0.5926\n",
      "Epoch 1804/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1327 - acc: 0.9387 - val_loss: 1.2416 - val_acc: 0.7037\n",
      "Epoch 1805/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1281 - acc: 0.9509 - val_loss: 1.3042 - val_acc: 0.6296\n",
      "Epoch 1806/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1270 - acc: 0.9448 - val_loss: 1.2432 - val_acc: 0.7037\n",
      "Epoch 1807/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.1261 - acc: 0.9509 - val_loss: 1.2842 - val_acc: 0.6296\n",
      "Epoch 1808/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1269 - acc: 0.9448 - val_loss: 1.2503 - val_acc: 0.6667\n",
      "Epoch 1809/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1259 - acc: 0.9448 - val_loss: 1.2701 - val_acc: 0.6296\n",
      "Epoch 1810/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.1252 - acc: 0.9448 - val_loss: 1.2498 - val_acc: 0.6667\n",
      "Epoch 1811/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1247 - acc: 0.9448 - val_loss: 1.2707 - val_acc: 0.6296\n",
      "Epoch 1812/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1245 - acc: 0.9509 - val_loss: 1.2506 - val_acc: 0.6667\n",
      "Epoch 1813/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.1245 - acc: 0.9448 - val_loss: 1.2751 - val_acc: 0.6296\n",
      "Epoch 1814/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.1249 - acc: 0.9448 - val_loss: 1.2389 - val_acc: 0.6667\n",
      "Epoch 1815/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1253 - acc: 0.9448 - val_loss: 1.3004 - val_acc: 0.6296\n",
      "Epoch 1816/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.1271 - acc: 0.9448 - val_loss: 1.2196 - val_acc: 0.7037\n",
      "Epoch 1817/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1320 - acc: 0.9448 - val_loss: 1.4235 - val_acc: 0.6296\n",
      "Epoch 1818/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1472 - acc: 0.9202 - val_loss: 1.2448 - val_acc: 0.7037\n",
      "Epoch 1819/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1561 - acc: 0.9448 - val_loss: 1.4744 - val_acc: 0.6296\n",
      "Epoch 1820/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.1508 - acc: 0.9202 - val_loss: 1.2547 - val_acc: 0.7037\n",
      "Epoch 1821/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.1308 - acc: 0.9448 - val_loss: 1.3591 - val_acc: 0.5926\n",
      "Epoch 1822/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.1275 - acc: 0.9509 - val_loss: 1.2847 - val_acc: 0.7037\n",
      "Epoch 1823/3000\n",
      "163/163 [==============================] - 0s 54us/step - loss: 0.1234 - acc: 0.9509 - val_loss: 1.3159 - val_acc: 0.6296\n",
      "Epoch 1824/3000\n",
      "163/163 [==============================] - 0s 54us/step - loss: 0.1225 - acc: 0.9509 - val_loss: 1.2893 - val_acc: 0.7037\n",
      "Epoch 1825/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1224 - acc: 0.9448 - val_loss: 1.3151 - val_acc: 0.6296\n",
      "Epoch 1826/3000\n",
      "163/163 [==============================] - 0s 54us/step - loss: 0.1233 - acc: 0.9509 - val_loss: 1.2804 - val_acc: 0.6667\n",
      "Epoch 1827/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.1239 - acc: 0.9448 - val_loss: 1.3166 - val_acc: 0.6296\n",
      "Epoch 1828/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.1255 - acc: 0.9448 - val_loss: 1.2736 - val_acc: 0.6667\n",
      "Epoch 1829/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1250 - acc: 0.9387 - val_loss: 1.3085 - val_acc: 0.6296\n",
      "Epoch 1830/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.1243 - acc: 0.9448 - val_loss: 1.2573 - val_acc: 0.7037\n",
      "Epoch 1831/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.1238 - acc: 0.9509 - val_loss: 1.3265 - val_acc: 0.6296\n",
      "Epoch 1832/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1253 - acc: 0.9448 - val_loss: 1.2382 - val_acc: 0.7037\n",
      "Epoch 1833/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1269 - acc: 0.9448 - val_loss: 1.3824 - val_acc: 0.6296\n",
      "Epoch 1834/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1347 - acc: 0.9264 - val_loss: 1.2125 - val_acc: 0.7037\n",
      "Epoch 1835/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.1408 - acc: 0.9448 - val_loss: 1.4327 - val_acc: 0.6296\n",
      "Epoch 1836/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1471 - acc: 0.9202 - val_loss: 1.2268 - val_acc: 0.7037\n",
      "Epoch 1837/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1343 - acc: 0.9448 - val_loss: 1.3593 - val_acc: 0.5926\n",
      "Epoch 1838/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1305 - acc: 0.9325 - val_loss: 1.2337 - val_acc: 0.7037\n",
      "Epoch 1839/3000\n",
      "163/163 [==============================] - 0s 55us/step - loss: 0.1242 - acc: 0.9509 - val_loss: 1.2804 - val_acc: 0.6667\n",
      "Epoch 1840/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1239 - acc: 0.9448 - val_loss: 1.2348 - val_acc: 0.7037\n",
      "Epoch 1841/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1222 - acc: 0.9448 - val_loss: 1.2641 - val_acc: 0.6667\n",
      "Epoch 1842/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1234 - acc: 0.9448 - val_loss: 1.2405 - val_acc: 0.7037\n",
      "Epoch 1843/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1225 - acc: 0.9448 - val_loss: 1.2564 - val_acc: 0.6667\n",
      "Epoch 1844/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.1223 - acc: 0.9509 - val_loss: 1.2391 - val_acc: 0.6667\n",
      "Epoch 1845/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1217 - acc: 0.9509 - val_loss: 1.3104 - val_acc: 0.7037\n",
      "Epoch 1846/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.1208 - acc: 0.9509 - val_loss: 1.3140 - val_acc: 0.6296\n",
      "Epoch 1847/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1210 - acc: 0.9509 - val_loss: 1.2932 - val_acc: 0.7037\n",
      "Epoch 1848/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1214 - acc: 0.9448 - val_loss: 1.3456 - val_acc: 0.6296\n",
      "Epoch 1849/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1244 - acc: 0.9509 - val_loss: 1.2573 - val_acc: 0.7037\n",
      "Epoch 1850/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1270 - acc: 0.9448 - val_loss: 1.4352 - val_acc: 0.6296\n",
      "Epoch 1851/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1384 - acc: 0.9264 - val_loss: 1.2314 - val_acc: 0.7037\n",
      "Epoch 1852/3000\n",
      "163/163 [==============================] - 0s 55us/step - loss: 0.1475 - acc: 0.9448 - val_loss: 1.4715 - val_acc: 0.6296\n",
      "Epoch 1853/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1467 - acc: 0.9325 - val_loss: 1.2410 - val_acc: 0.7037\n",
      "Epoch 1854/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1289 - acc: 0.9448 - val_loss: 1.3572 - val_acc: 0.5926\n",
      "Epoch 1855/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1247 - acc: 0.9448 - val_loss: 1.2657 - val_acc: 0.6667\n",
      "Epoch 1856/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1221 - acc: 0.9509 - val_loss: 1.3115 - val_acc: 0.6296\n",
      "Epoch 1857/3000\n",
      "163/163 [==============================] - 0s 53us/step - loss: 0.1231 - acc: 0.9448 - val_loss: 1.2665 - val_acc: 0.6667\n",
      "Epoch 1858/3000\n",
      "163/163 [==============================] - 0s 56us/step - loss: 0.1210 - acc: 0.9509 - val_loss: 1.3072 - val_acc: 0.6296\n",
      "Epoch 1859/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1224 - acc: 0.9448 - val_loss: 1.2568 - val_acc: 0.6667\n",
      "Epoch 1860/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.1211 - acc: 0.9509 - val_loss: 1.3060 - val_acc: 0.6296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1861/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1221 - acc: 0.9448 - val_loss: 1.2590 - val_acc: 0.6667\n",
      "Epoch 1862/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1216 - acc: 0.9509 - val_loss: 1.3150 - val_acc: 0.6296\n",
      "Epoch 1863/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1221 - acc: 0.9448 - val_loss: 1.2232 - val_acc: 0.7037\n",
      "Epoch 1864/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1224 - acc: 0.9571 - val_loss: 1.3319 - val_acc: 0.5926\n",
      "Epoch 1865/3000\n",
      "163/163 [==============================] - 0s 54us/step - loss: 0.1257 - acc: 0.9387 - val_loss: 1.2060 - val_acc: 0.7037\n",
      "Epoch 1866/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1274 - acc: 0.9448 - val_loss: 1.3734 - val_acc: 0.6296\n",
      "Epoch 1867/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1336 - acc: 0.9264 - val_loss: 1.2060 - val_acc: 0.7037\n",
      "Epoch 1868/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1372 - acc: 0.9387 - val_loss: 1.4008 - val_acc: 0.6296\n",
      "Epoch 1869/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1379 - acc: 0.9325 - val_loss: 1.2078 - val_acc: 0.7037\n",
      "Epoch 1870/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.1277 - acc: 0.9448 - val_loss: 1.3442 - val_acc: 0.6296\n",
      "Epoch 1871/3000\n",
      "163/163 [==============================] - 0s 53us/step - loss: 0.1260 - acc: 0.9448 - val_loss: 1.2150 - val_acc: 0.7037\n",
      "Epoch 1872/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.1217 - acc: 0.9571 - val_loss: 1.2812 - val_acc: 0.6296\n",
      "Epoch 1873/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1210 - acc: 0.9448 - val_loss: 1.2230 - val_acc: 0.6667\n",
      "Epoch 1874/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1198 - acc: 0.9509 - val_loss: 1.2889 - val_acc: 0.6296\n",
      "Epoch 1875/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.1214 - acc: 0.9448 - val_loss: 1.2180 - val_acc: 0.7037\n",
      "Epoch 1876/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.1205 - acc: 0.9571 - val_loss: 1.2943 - val_acc: 0.6296\n",
      "Epoch 1877/3000\n",
      "163/163 [==============================] - 0s 53us/step - loss: 0.1223 - acc: 0.9448 - val_loss: 1.2048 - val_acc: 0.7037\n",
      "Epoch 1878/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1216 - acc: 0.9571 - val_loss: 1.3090 - val_acc: 0.5926\n",
      "Epoch 1879/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1235 - acc: 0.9448 - val_loss: 1.1985 - val_acc: 0.7037\n",
      "Epoch 1880/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1227 - acc: 0.9509 - val_loss: 1.3060 - val_acc: 0.5926\n",
      "Epoch 1881/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1249 - acc: 0.9387 - val_loss: 1.2119 - val_acc: 0.7037\n",
      "Epoch 1882/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1277 - acc: 0.9448 - val_loss: 1.3661 - val_acc: 0.6296\n",
      "Epoch 1883/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1349 - acc: 0.9387 - val_loss: 1.1829 - val_acc: 0.7037\n",
      "Epoch 1884/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1323 - acc: 0.9387 - val_loss: 1.3547 - val_acc: 0.6296\n",
      "Epoch 1885/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1339 - acc: 0.9325 - val_loss: 1.1836 - val_acc: 0.7037\n",
      "Epoch 1886/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.1246 - acc: 0.9448 - val_loss: 1.3014 - val_acc: 0.5926\n",
      "Epoch 1887/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1235 - acc: 0.9448 - val_loss: 1.2078 - val_acc: 0.7037\n",
      "Epoch 1888/3000\n",
      "163/163 [==============================] - 0s 55us/step - loss: 0.1206 - acc: 0.9571 - val_loss: 1.2468 - val_acc: 0.6667\n",
      "Epoch 1889/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1212 - acc: 0.9509 - val_loss: 1.2257 - val_acc: 0.7037\n",
      "Epoch 1890/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1198 - acc: 0.9387 - val_loss: 1.2490 - val_acc: 0.6667\n",
      "Epoch 1891/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1200 - acc: 0.9509 - val_loss: 1.2155 - val_acc: 0.7037\n",
      "Epoch 1892/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1189 - acc: 0.9448 - val_loss: 1.2396 - val_acc: 0.6667\n",
      "Epoch 1893/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1188 - acc: 0.9509 - val_loss: 1.2702 - val_acc: 0.7037\n",
      "Epoch 1894/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1189 - acc: 0.9509 - val_loss: 1.3190 - val_acc: 0.6296\n",
      "Epoch 1895/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1191 - acc: 0.9509 - val_loss: 1.2456 - val_acc: 0.7037\n",
      "Epoch 1896/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1201 - acc: 0.9571 - val_loss: 1.3422 - val_acc: 0.5926\n",
      "Epoch 1897/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1228 - acc: 0.9448 - val_loss: 1.2345 - val_acc: 0.7037\n",
      "Epoch 1898/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1264 - acc: 0.9448 - val_loss: 1.4358 - val_acc: 0.6296\n",
      "Epoch 1899/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1353 - acc: 0.9387 - val_loss: 1.2013 - val_acc: 0.7037\n",
      "Epoch 1900/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1352 - acc: 0.9448 - val_loss: 1.4257 - val_acc: 0.6296\n",
      "Epoch 1901/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1366 - acc: 0.9325 - val_loss: 1.2033 - val_acc: 0.7037\n",
      "Epoch 1902/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.1274 - acc: 0.9448 - val_loss: 1.3514 - val_acc: 0.5926\n",
      "Epoch 1903/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1271 - acc: 0.9387 - val_loss: 1.2198 - val_acc: 0.7037\n",
      "Epoch 1904/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1203 - acc: 0.9448 - val_loss: 1.2962 - val_acc: 0.6296\n",
      "Epoch 1905/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1193 - acc: 0.9448 - val_loss: 1.2328 - val_acc: 0.6667\n",
      "Epoch 1906/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1175 - acc: 0.9509 - val_loss: 1.2735 - val_acc: 0.6296\n",
      "Epoch 1907/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1176 - acc: 0.9448 - val_loss: 1.2347 - val_acc: 0.6667\n",
      "Epoch 1908/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1170 - acc: 0.9448 - val_loss: 1.2777 - val_acc: 0.6296\n",
      "Epoch 1909/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1175 - acc: 0.9448 - val_loss: 1.2300 - val_acc: 0.6667\n",
      "Epoch 1910/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1171 - acc: 0.9509 - val_loss: 1.2774 - val_acc: 0.6296\n",
      "Epoch 1911/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1181 - acc: 0.9448 - val_loss: 1.2147 - val_acc: 0.6667\n",
      "Epoch 1912/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1188 - acc: 0.9448 - val_loss: 1.2769 - val_acc: 0.6296\n",
      "Epoch 1913/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1185 - acc: 0.9448 - val_loss: 1.1877 - val_acc: 0.7037\n",
      "Epoch 1914/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1192 - acc: 0.9571 - val_loss: 1.3434 - val_acc: 0.6296\n",
      "Epoch 1915/3000\n",
      "163/163 [==============================] - 0s 53us/step - loss: 0.1277 - acc: 0.9325 - val_loss: 1.2139 - val_acc: 0.7037\n",
      "Epoch 1916/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.1354 - acc: 0.9448 - val_loss: 1.4737 - val_acc: 0.6296\n",
      "Epoch 1917/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1454 - acc: 0.9202 - val_loss: 1.2089 - val_acc: 0.7037\n",
      "Epoch 1918/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1292 - acc: 0.9448 - val_loss: 1.3638 - val_acc: 0.5926\n",
      "Epoch 1919/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1222 - acc: 0.9387 - val_loss: 1.2452 - val_acc: 0.6667\n",
      "Epoch 1920/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1173 - acc: 0.9571 - val_loss: 1.3107 - val_acc: 0.6296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1921/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1174 - acc: 0.9448 - val_loss: 1.2529 - val_acc: 0.6667\n",
      "Epoch 1922/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1155 - acc: 0.9509 - val_loss: 1.2899 - val_acc: 0.6296\n",
      "Epoch 1923/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1164 - acc: 0.9509 - val_loss: 1.2523 - val_acc: 0.6667\n",
      "Epoch 1924/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.1159 - acc: 0.9448 - val_loss: 1.2886 - val_acc: 0.6296\n",
      "Epoch 1925/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1167 - acc: 0.9448 - val_loss: 1.2603 - val_acc: 0.6667\n",
      "Epoch 1926/3000\n",
      "163/163 [==============================] - 0s 53us/step - loss: 0.1162 - acc: 0.9448 - val_loss: 1.2863 - val_acc: 0.6296\n",
      "Epoch 1927/3000\n",
      "163/163 [==============================] - 0s 55us/step - loss: 0.1157 - acc: 0.9509 - val_loss: 1.2577 - val_acc: 0.6667\n",
      "Epoch 1928/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.1154 - acc: 0.9448 - val_loss: 1.2921 - val_acc: 0.6296\n",
      "Epoch 1929/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1156 - acc: 0.9509 - val_loss: 1.2542 - val_acc: 0.6667\n",
      "Epoch 1930/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1160 - acc: 0.9509 - val_loss: 1.3084 - val_acc: 0.6296\n",
      "Epoch 1931/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1161 - acc: 0.9448 - val_loss: 1.2245 - val_acc: 0.7037\n",
      "Epoch 1932/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1179 - acc: 0.9509 - val_loss: 1.4124 - val_acc: 0.6296\n",
      "Epoch 1933/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1298 - acc: 0.9264 - val_loss: 1.1985 - val_acc: 0.7037\n",
      "Epoch 1934/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1457 - acc: 0.9448 - val_loss: 1.4957 - val_acc: 0.6296\n",
      "Epoch 1935/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1491 - acc: 0.9325 - val_loss: 1.2159 - val_acc: 0.7037\n",
      "Epoch 1936/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1208 - acc: 0.9448 - val_loss: 1.3133 - val_acc: 0.5926\n",
      "Epoch 1937/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1153 - acc: 0.9509 - val_loss: 1.2464 - val_acc: 0.6667\n",
      "Epoch 1938/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1136 - acc: 0.9509 - val_loss: 1.2867 - val_acc: 0.6296\n",
      "Epoch 1939/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1146 - acc: 0.9509 - val_loss: 1.2525 - val_acc: 0.6667\n",
      "Epoch 1940/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.1148 - acc: 0.9448 - val_loss: 1.2767 - val_acc: 0.6296\n",
      "Epoch 1941/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.1154 - acc: 0.9448 - val_loss: 1.2536 - val_acc: 0.6667\n",
      "Epoch 1942/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1152 - acc: 0.9448 - val_loss: 1.2710 - val_acc: 0.6296\n",
      "Epoch 1943/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1143 - acc: 0.9509 - val_loss: 1.2480 - val_acc: 0.6667\n",
      "Epoch 1944/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1135 - acc: 0.9448 - val_loss: 1.2771 - val_acc: 0.6296\n",
      "Epoch 1945/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1146 - acc: 0.9509 - val_loss: 1.2458 - val_acc: 0.6667\n",
      "Epoch 1946/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1147 - acc: 0.9509 - val_loss: 1.2881 - val_acc: 0.6296\n",
      "Epoch 1947/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.1145 - acc: 0.9448 - val_loss: 1.2163 - val_acc: 0.7037\n",
      "Epoch 1948/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1149 - acc: 0.9571 - val_loss: 1.3338 - val_acc: 0.5926\n",
      "Epoch 1949/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.1193 - acc: 0.9325 - val_loss: 1.2016 - val_acc: 0.7037\n",
      "Epoch 1950/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1307 - acc: 0.9448 - val_loss: 1.4836 - val_acc: 0.6296\n",
      "Epoch 1951/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.1513 - acc: 0.9264 - val_loss: 1.1673 - val_acc: 0.7037\n",
      "Epoch 1952/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.1279 - acc: 0.9509 - val_loss: 1.3343 - val_acc: 0.6296\n",
      "Epoch 1953/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1232 - acc: 0.9448 - val_loss: 1.1915 - val_acc: 0.7037\n",
      "Epoch 1954/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.1165 - acc: 0.9448 - val_loss: 1.2521 - val_acc: 0.6667\n",
      "Epoch 1955/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.1143 - acc: 0.9509 - val_loss: 1.1975 - val_acc: 0.7037\n",
      "Epoch 1956/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.1134 - acc: 0.9509 - val_loss: 1.3304 - val_acc: 0.6296\n",
      "Epoch 1957/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.1150 - acc: 0.9448 - val_loss: 1.2680 - val_acc: 0.6667\n",
      "Epoch 1958/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.1143 - acc: 0.9509 - val_loss: 1.3248 - val_acc: 0.6296\n",
      "Epoch 1959/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1147 - acc: 0.9448 - val_loss: 1.2628 - val_acc: 0.6667\n",
      "Epoch 1960/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1133 - acc: 0.9509 - val_loss: 1.3310 - val_acc: 0.6296\n",
      "Epoch 1961/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.1142 - acc: 0.9448 - val_loss: 1.2545 - val_acc: 0.7037\n",
      "Epoch 1962/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.1143 - acc: 0.9571 - val_loss: 1.3439 - val_acc: 0.5926\n",
      "Epoch 1963/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1160 - acc: 0.9448 - val_loss: 1.2406 - val_acc: 0.7037\n",
      "Epoch 1964/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1163 - acc: 0.9509 - val_loss: 1.3757 - val_acc: 0.5926\n",
      "Epoch 1965/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.1193 - acc: 0.9387 - val_loss: 1.2382 - val_acc: 0.7037\n",
      "Epoch 1966/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.1242 - acc: 0.9448 - val_loss: 1.4736 - val_acc: 0.6296\n",
      "Epoch 1967/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1389 - acc: 0.9325 - val_loss: 1.2120 - val_acc: 0.7037\n",
      "Epoch 1968/3000\n",
      "163/163 [==============================] - 0s 26us/step - loss: 0.1264 - acc: 0.9448 - val_loss: 1.4050 - val_acc: 0.6296\n",
      "Epoch 1969/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1242 - acc: 0.9448 - val_loss: 1.2332 - val_acc: 0.7037\n",
      "Epoch 1970/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1169 - acc: 0.9448 - val_loss: 1.3300 - val_acc: 0.5926\n",
      "Epoch 1971/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1135 - acc: 0.9509 - val_loss: 1.2491 - val_acc: 0.6667\n",
      "Epoch 1972/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1119 - acc: 0.9509 - val_loss: 1.3206 - val_acc: 0.6296\n",
      "Epoch 1973/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.1138 - acc: 0.9571 - val_loss: 1.2496 - val_acc: 0.6667\n",
      "Epoch 1974/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1124 - acc: 0.9571 - val_loss: 1.3207 - val_acc: 0.6296\n",
      "Epoch 1975/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.1148 - acc: 0.9448 - val_loss: 1.2141 - val_acc: 0.7037\n",
      "Epoch 1976/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.1146 - acc: 0.9571 - val_loss: 1.3018 - val_acc: 0.5926\n",
      "Epoch 1977/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.1156 - acc: 0.9448 - val_loss: 1.2141 - val_acc: 0.6667\n",
      "Epoch 1978/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1144 - acc: 0.9571 - val_loss: 1.3074 - val_acc: 0.5926\n",
      "Epoch 1979/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.1153 - acc: 0.9509 - val_loss: 1.2078 - val_acc: 0.7037\n",
      "Epoch 1980/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.1146 - acc: 0.9509 - val_loss: 1.3294 - val_acc: 0.5926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1981/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1168 - acc: 0.9448 - val_loss: 1.2140 - val_acc: 0.7037\n",
      "Epoch 1982/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1205 - acc: 0.9448 - val_loss: 1.3989 - val_acc: 0.6296\n",
      "Epoch 1983/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.1280 - acc: 0.9387 - val_loss: 1.1905 - val_acc: 0.7037\n",
      "Epoch 1984/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.1298 - acc: 0.9448 - val_loss: 1.4104 - val_acc: 0.6296\n",
      "Epoch 1985/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1292 - acc: 0.9448 - val_loss: 1.1983 - val_acc: 0.7037\n",
      "Epoch 1986/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1188 - acc: 0.9448 - val_loss: 1.3184 - val_acc: 0.5926\n",
      "Epoch 1987/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.1152 - acc: 0.9571 - val_loss: 1.2122 - val_acc: 0.6667\n",
      "Epoch 1988/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.1124 - acc: 0.9571 - val_loss: 1.2845 - val_acc: 0.5926\n",
      "Epoch 1989/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1134 - acc: 0.9448 - val_loss: 1.2182 - val_acc: 0.6667\n",
      "Epoch 1990/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.1119 - acc: 0.9509 - val_loss: 1.2687 - val_acc: 0.6296\n",
      "Epoch 1991/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.1129 - acc: 0.9448 - val_loss: 1.2295 - val_acc: 0.6667\n",
      "Epoch 1992/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.1122 - acc: 0.9571 - val_loss: 1.2637 - val_acc: 0.6296\n",
      "Epoch 1993/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.1115 - acc: 0.9509 - val_loss: 1.2351 - val_acc: 0.6667\n",
      "Epoch 1994/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.1104 - acc: 0.9509 - val_loss: 1.2545 - val_acc: 0.6296\n",
      "Epoch 1995/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1106 - acc: 0.9448 - val_loss: 1.2446 - val_acc: 0.6667\n",
      "Epoch 1996/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1115 - acc: 0.9509 - val_loss: 1.2481 - val_acc: 0.6667\n",
      "Epoch 1997/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1106 - acc: 0.9448 - val_loss: 1.2414 - val_acc: 0.6667\n",
      "Epoch 1998/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1097 - acc: 0.9509 - val_loss: 1.2577 - val_acc: 0.6296\n",
      "Epoch 1999/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1101 - acc: 0.9448 - val_loss: 1.2657 - val_acc: 0.6296\n",
      "Epoch 2000/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1116 - acc: 0.9571 - val_loss: 1.2201 - val_acc: 0.7037\n",
      "Epoch 2001/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1141 - acc: 0.9571 - val_loss: 1.3811 - val_acc: 0.6296\n",
      "Epoch 2002/3000\n",
      "163/163 [==============================] - 0s 54us/step - loss: 0.1266 - acc: 0.9387 - val_loss: 1.1479 - val_acc: 0.7037\n",
      "Epoch 2003/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1456 - acc: 0.9448 - val_loss: 1.4745 - val_acc: 0.6296\n",
      "Epoch 2004/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1467 - acc: 0.9325 - val_loss: 1.1777 - val_acc: 0.7037\n",
      "Epoch 2005/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1167 - acc: 0.9448 - val_loss: 1.2617 - val_acc: 0.5926\n",
      "Epoch 2006/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1117 - acc: 0.9571 - val_loss: 1.2776 - val_acc: 0.6667\n",
      "Epoch 2007/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1098 - acc: 0.9509 - val_loss: 1.3265 - val_acc: 0.5926\n",
      "Epoch 2008/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1108 - acc: 0.9509 - val_loss: 1.2786 - val_acc: 0.6667\n",
      "Epoch 2009/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1104 - acc: 0.9509 - val_loss: 1.3379 - val_acc: 0.5926\n",
      "Epoch 2010/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1122 - acc: 0.9509 - val_loss: 1.2703 - val_acc: 0.6667\n",
      "Epoch 2011/3000\n",
      "163/163 [==============================] - 0s 62us/step - loss: 0.1109 - acc: 0.9571 - val_loss: 1.3504 - val_acc: 0.5926\n",
      "Epoch 2012/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.1128 - acc: 0.9509 - val_loss: 1.2564 - val_acc: 0.7037\n",
      "Epoch 2013/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1117 - acc: 0.9632 - val_loss: 1.3665 - val_acc: 0.5926\n",
      "Epoch 2014/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1137 - acc: 0.9509 - val_loss: 1.2587 - val_acc: 0.7037\n",
      "Epoch 2015/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1159 - acc: 0.9448 - val_loss: 1.4038 - val_acc: 0.5926\n",
      "Epoch 2016/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1185 - acc: 0.9387 - val_loss: 1.2423 - val_acc: 0.7037\n",
      "Epoch 2017/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1163 - acc: 0.9448 - val_loss: 1.4219 - val_acc: 0.6296\n",
      "Epoch 2018/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1227 - acc: 0.9387 - val_loss: 1.2185 - val_acc: 0.7037\n",
      "Epoch 2019/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1227 - acc: 0.9387 - val_loss: 1.4304 - val_acc: 0.6296\n",
      "Epoch 2020/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1271 - acc: 0.9264 - val_loss: 1.2212 - val_acc: 0.7037\n",
      "Epoch 2021/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1170 - acc: 0.9448 - val_loss: 1.3488 - val_acc: 0.5926\n",
      "Epoch 2022/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1145 - acc: 0.9448 - val_loss: 1.2460 - val_acc: 0.7037\n",
      "Epoch 2023/3000\n",
      "163/163 [==============================] - 0s 53us/step - loss: 0.1105 - acc: 0.9571 - val_loss: 1.3075 - val_acc: 0.6296\n",
      "Epoch 2024/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1112 - acc: 0.9509 - val_loss: 1.2484 - val_acc: 0.7037\n",
      "Epoch 2025/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1099 - acc: 0.9571 - val_loss: 1.2921 - val_acc: 0.6667\n",
      "Epoch 2026/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.1110 - acc: 0.9448 - val_loss: 1.2554 - val_acc: 0.7037\n",
      "Epoch 2027/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1094 - acc: 0.9509 - val_loss: 1.2894 - val_acc: 0.6667\n",
      "Epoch 2028/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.1100 - acc: 0.9509 - val_loss: 1.2591 - val_acc: 0.7037\n",
      "Epoch 2029/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1092 - acc: 0.9509 - val_loss: 1.2831 - val_acc: 0.6667\n",
      "Epoch 2030/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.1093 - acc: 0.9509 - val_loss: 1.2582 - val_acc: 0.7037\n",
      "Epoch 2031/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1082 - acc: 0.9509 - val_loss: 1.3473 - val_acc: 0.6296\n",
      "Epoch 2032/3000\n",
      "163/163 [==============================] - 0s 57us/step - loss: 0.1084 - acc: 0.9448 - val_loss: 1.3141 - val_acc: 0.6667\n",
      "Epoch 2033/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1085 - acc: 0.9509 - val_loss: 1.3423 - val_acc: 0.6667\n",
      "Epoch 2034/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1081 - acc: 0.9509 - val_loss: 1.3187 - val_acc: 0.6667\n",
      "Epoch 2035/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1081 - acc: 0.9509 - val_loss: 1.3468 - val_acc: 0.6296\n",
      "Epoch 2036/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.1087 - acc: 0.9448 - val_loss: 1.3225 - val_acc: 0.6296\n",
      "Epoch 2037/3000\n",
      "163/163 [==============================] - 0s 56us/step - loss: 0.1094 - acc: 0.9509 - val_loss: 1.3291 - val_acc: 0.6667\n",
      "Epoch 2038/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1091 - acc: 0.9448 - val_loss: 1.3706 - val_acc: 0.5926\n",
      "Epoch 2039/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1121 - acc: 0.9571 - val_loss: 1.2736 - val_acc: 0.7037\n",
      "Epoch 2040/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1294 - acc: 0.9509 - val_loss: 1.6055 - val_acc: 0.6296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2041/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1586 - acc: 0.9325 - val_loss: 1.2546 - val_acc: 0.7037\n",
      "Epoch 2042/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1285 - acc: 0.9448 - val_loss: 1.4550 - val_acc: 0.6296\n",
      "Epoch 2043/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1237 - acc: 0.9325 - val_loss: 1.2811 - val_acc: 0.6667\n",
      "Epoch 2044/3000\n",
      "163/163 [==============================] - 0s 55us/step - loss: 0.1112 - acc: 0.9448 - val_loss: 1.3683 - val_acc: 0.5926\n",
      "Epoch 2045/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1096 - acc: 0.9509 - val_loss: 1.3030 - val_acc: 0.6667\n",
      "Epoch 2046/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1077 - acc: 0.9571 - val_loss: 1.3605 - val_acc: 0.6296\n",
      "Epoch 2047/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.1088 - acc: 0.9571 - val_loss: 1.2987 - val_acc: 0.6667\n",
      "Epoch 2048/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1075 - acc: 0.9571 - val_loss: 1.3670 - val_acc: 0.5926\n",
      "Epoch 2049/3000\n",
      "163/163 [==============================] - 0s 53us/step - loss: 0.1090 - acc: 0.9571 - val_loss: 1.2946 - val_acc: 0.6667\n",
      "Epoch 2050/3000\n",
      "163/163 [==============================] - 0s 55us/step - loss: 0.1081 - acc: 0.9571 - val_loss: 1.3731 - val_acc: 0.5926\n",
      "Epoch 2051/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1095 - acc: 0.9509 - val_loss: 1.2795 - val_acc: 0.7037\n",
      "Epoch 2052/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1094 - acc: 0.9632 - val_loss: 1.3937 - val_acc: 0.5926\n",
      "Epoch 2053/3000\n",
      "163/163 [==============================] - 0s 55us/step - loss: 0.1116 - acc: 0.9509 - val_loss: 1.2857 - val_acc: 0.7037\n",
      "Epoch 2054/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1129 - acc: 0.9509 - val_loss: 1.4442 - val_acc: 0.5926\n",
      "Epoch 2055/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.1181 - acc: 0.9387 - val_loss: 1.2639 - val_acc: 0.7037\n",
      "Epoch 2056/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1180 - acc: 0.9448 - val_loss: 1.4502 - val_acc: 0.6296\n",
      "Epoch 2057/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1220 - acc: 0.9448 - val_loss: 1.2499 - val_acc: 0.7037\n",
      "Epoch 2058/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.1205 - acc: 0.9387 - val_loss: 1.4455 - val_acc: 0.6296\n",
      "Epoch 2059/3000\n",
      "163/163 [==============================] - 0s 55us/step - loss: 0.1211 - acc: 0.9387 - val_loss: 1.2615 - val_acc: 0.7037\n",
      "Epoch 2060/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1126 - acc: 0.9448 - val_loss: 1.3846 - val_acc: 0.5926\n",
      "Epoch 2061/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1100 - acc: 0.9571 - val_loss: 1.2892 - val_acc: 0.6667\n",
      "Epoch 2062/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1074 - acc: 0.9632 - val_loss: 1.3527 - val_acc: 0.5926\n",
      "Epoch 2063/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1088 - acc: 0.9509 - val_loss: 1.2875 - val_acc: 0.6667\n",
      "Epoch 2064/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1081 - acc: 0.9571 - val_loss: 1.3382 - val_acc: 0.6296\n",
      "Epoch 2065/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1095 - acc: 0.9448 - val_loss: 1.2896 - val_acc: 0.6667\n",
      "Epoch 2066/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1082 - acc: 0.9571 - val_loss: 1.3342 - val_acc: 0.6296\n",
      "Epoch 2067/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1075 - acc: 0.9571 - val_loss: 1.2937 - val_acc: 0.6667\n",
      "Epoch 2068/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.1063 - acc: 0.9571 - val_loss: 1.3401 - val_acc: 0.6296\n",
      "Epoch 2069/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1067 - acc: 0.9571 - val_loss: 1.2821 - val_acc: 0.7037\n",
      "Epoch 2070/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1065 - acc: 0.9571 - val_loss: 1.3758 - val_acc: 0.5926\n",
      "Epoch 2071/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1095 - acc: 0.9571 - val_loss: 1.2663 - val_acc: 0.7037\n",
      "Epoch 2072/3000\n",
      "163/163 [==============================] - 0s 53us/step - loss: 0.1149 - acc: 0.9509 - val_loss: 1.4622 - val_acc: 0.5926\n",
      "Epoch 2073/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1221 - acc: 0.9387 - val_loss: 1.2442 - val_acc: 0.7037\n",
      "Epoch 2074/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1265 - acc: 0.9448 - val_loss: 1.5050 - val_acc: 0.6296\n",
      "Epoch 2075/3000\n",
      "163/163 [==============================] - 0s 56us/step - loss: 0.1373 - acc: 0.9264 - val_loss: 1.2337 - val_acc: 0.7037\n",
      "Epoch 2076/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.1157 - acc: 0.9448 - val_loss: 1.3680 - val_acc: 0.5926\n",
      "Epoch 2077/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1100 - acc: 0.9571 - val_loss: 1.2656 - val_acc: 0.7037\n",
      "Epoch 2078/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1064 - acc: 0.9632 - val_loss: 1.3097 - val_acc: 0.6296\n",
      "Epoch 2079/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1060 - acc: 0.9571 - val_loss: 1.2637 - val_acc: 0.7037\n",
      "Epoch 2080/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1061 - acc: 0.9571 - val_loss: 1.2935 - val_acc: 0.6667\n",
      "Epoch 2081/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.1080 - acc: 0.9387 - val_loss: 1.2708 - val_acc: 0.7037\n",
      "Epoch 2082/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1075 - acc: 0.9509 - val_loss: 1.2833 - val_acc: 0.7037\n",
      "Epoch 2083/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1065 - acc: 0.9509 - val_loss: 1.2761 - val_acc: 0.7037\n",
      "Epoch 2084/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1056 - acc: 0.9509 - val_loss: 1.2734 - val_acc: 0.7037\n",
      "Epoch 2085/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1057 - acc: 0.9509 - val_loss: 1.2926 - val_acc: 0.6296\n",
      "Epoch 2086/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1062 - acc: 0.9509 - val_loss: 1.2547 - val_acc: 0.7037\n",
      "Epoch 2087/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.1069 - acc: 0.9509 - val_loss: 1.3314 - val_acc: 0.6296\n",
      "Epoch 2088/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1109 - acc: 0.9571 - val_loss: 1.2377 - val_acc: 0.7037\n",
      "Epoch 2089/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.1167 - acc: 0.9448 - val_loss: 1.4244 - val_acc: 0.6667\n",
      "Epoch 2090/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1241 - acc: 0.9448 - val_loss: 1.2158 - val_acc: 0.7037\n",
      "Epoch 2091/3000\n",
      "163/163 [==============================] - 0s 56us/step - loss: 0.1311 - acc: 0.9448 - val_loss: 1.5087 - val_acc: 0.6296\n",
      "Epoch 2092/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1332 - acc: 0.9325 - val_loss: 1.2839 - val_acc: 0.7037\n",
      "Epoch 2093/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.1115 - acc: 0.9448 - val_loss: 1.3904 - val_acc: 0.5926\n",
      "Epoch 2094/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.1068 - acc: 0.9509 - val_loss: 1.3072 - val_acc: 0.6667\n",
      "Epoch 2095/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1067 - acc: 0.9571 - val_loss: 1.3710 - val_acc: 0.5926\n",
      "Epoch 2096/3000\n",
      "163/163 [==============================] - 0s 54us/step - loss: 0.1080 - acc: 0.9509 - val_loss: 1.3049 - val_acc: 0.6667\n",
      "Epoch 2097/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1059 - acc: 0.9571 - val_loss: 1.3667 - val_acc: 0.5926\n",
      "Epoch 2098/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1064 - acc: 0.9509 - val_loss: 1.3070 - val_acc: 0.7037\n",
      "Epoch 2099/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1050 - acc: 0.9571 - val_loss: 1.3758 - val_acc: 0.5926\n",
      "Epoch 2100/3000\n",
      "163/163 [==============================] - 0s 56us/step - loss: 0.1063 - acc: 0.9571 - val_loss: 1.2989 - val_acc: 0.7037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2101/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1061 - acc: 0.9632 - val_loss: 1.3925 - val_acc: 0.5926\n",
      "Epoch 2102/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1074 - acc: 0.9509 - val_loss: 1.2966 - val_acc: 0.7037\n",
      "Epoch 2103/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.1090 - acc: 0.9509 - val_loss: 1.4424 - val_acc: 0.5926\n",
      "Epoch 2104/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1130 - acc: 0.9387 - val_loss: 1.2754 - val_acc: 0.7037\n",
      "Epoch 2105/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.1136 - acc: 0.9509 - val_loss: 1.4640 - val_acc: 0.5926\n",
      "Epoch 2106/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1179 - acc: 0.9325 - val_loss: 1.2730 - val_acc: 0.7037\n",
      "Epoch 2107/3000\n",
      "163/163 [==============================] - 0s 55us/step - loss: 0.1166 - acc: 0.9387 - val_loss: 1.4633 - val_acc: 0.6296\n",
      "Epoch 2108/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1196 - acc: 0.9448 - val_loss: 1.2710 - val_acc: 0.7037\n",
      "Epoch 2109/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1148 - acc: 0.9448 - val_loss: 1.4321 - val_acc: 0.5926\n",
      "Epoch 2110/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1133 - acc: 0.9509 - val_loss: 1.2861 - val_acc: 0.7037\n",
      "Epoch 2111/3000\n",
      "163/163 [==============================] - 0s 54us/step - loss: 0.1073 - acc: 0.9571 - val_loss: 1.3878 - val_acc: 0.5926\n",
      "Epoch 2112/3000\n",
      "163/163 [==============================] - 0s 56us/step - loss: 0.1064 - acc: 0.9509 - val_loss: 1.3090 - val_acc: 0.6667\n",
      "Epoch 2113/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1058 - acc: 0.9509 - val_loss: 1.3773 - val_acc: 0.5926\n",
      "Epoch 2114/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1068 - acc: 0.9509 - val_loss: 1.2998 - val_acc: 0.7037\n",
      "Epoch 2115/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1053 - acc: 0.9571 - val_loss: 1.3684 - val_acc: 0.5926\n",
      "Epoch 2116/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.1069 - acc: 0.9509 - val_loss: 1.2996 - val_acc: 0.6667\n",
      "Epoch 2117/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1058 - acc: 0.9571 - val_loss: 1.3539 - val_acc: 0.6296\n",
      "Epoch 2118/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1048 - acc: 0.9509 - val_loss: 1.3055 - val_acc: 0.7037\n",
      "Epoch 2119/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1039 - acc: 0.9571 - val_loss: 1.3568 - val_acc: 0.5926\n",
      "Epoch 2120/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1042 - acc: 0.9571 - val_loss: 1.2913 - val_acc: 0.7037\n",
      "Epoch 2121/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.1042 - acc: 0.9571 - val_loss: 1.3907 - val_acc: 0.5926\n",
      "Epoch 2122/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1072 - acc: 0.9571 - val_loss: 1.2545 - val_acc: 0.7037\n",
      "Epoch 2123/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.1125 - acc: 0.9509 - val_loss: 1.4847 - val_acc: 0.6667\n",
      "Epoch 2124/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1266 - acc: 0.9325 - val_loss: 1.2505 - val_acc: 0.7037\n",
      "Epoch 2125/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1315 - acc: 0.9448 - val_loss: 1.5037 - val_acc: 0.6296\n",
      "Epoch 2126/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1293 - acc: 0.9325 - val_loss: 1.2565 - val_acc: 0.7037\n",
      "Epoch 2127/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1139 - acc: 0.9448 - val_loss: 1.3949 - val_acc: 0.5926\n",
      "Epoch 2128/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1071 - acc: 0.9509 - val_loss: 1.3034 - val_acc: 0.7037\n",
      "Epoch 2129/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.1030 - acc: 0.9509 - val_loss: 1.3437 - val_acc: 0.6296\n",
      "Epoch 2130/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1028 - acc: 0.9571 - val_loss: 1.3017 - val_acc: 0.7037\n",
      "Epoch 2131/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1032 - acc: 0.9509 - val_loss: 1.3373 - val_acc: 0.6296\n",
      "Epoch 2132/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.1052 - acc: 0.9509 - val_loss: 1.2935 - val_acc: 0.7037\n",
      "Epoch 2133/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1046 - acc: 0.9571 - val_loss: 1.3334 - val_acc: 0.6667\n",
      "Epoch 2134/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.1058 - acc: 0.9448 - val_loss: 1.3002 - val_acc: 0.6667\n",
      "Epoch 2135/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1049 - acc: 0.9509 - val_loss: 1.3240 - val_acc: 0.6667\n",
      "Epoch 2136/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1038 - acc: 0.9509 - val_loss: 1.3043 - val_acc: 0.6667\n",
      "Epoch 2137/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.1026 - acc: 0.9509 - val_loss: 1.3188 - val_acc: 0.7037\n",
      "Epoch 2138/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1035 - acc: 0.9509 - val_loss: 1.3139 - val_acc: 0.6296\n",
      "Epoch 2139/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1033 - acc: 0.9509 - val_loss: 1.3068 - val_acc: 0.7037\n",
      "Epoch 2140/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1033 - acc: 0.9509 - val_loss: 1.3417 - val_acc: 0.5926\n",
      "Epoch 2141/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1033 - acc: 0.9571 - val_loss: 1.2635 - val_acc: 0.7037\n",
      "Epoch 2142/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1065 - acc: 0.9571 - val_loss: 1.4612 - val_acc: 0.6667\n",
      "Epoch 2143/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1202 - acc: 0.9387 - val_loss: 1.2299 - val_acc: 0.7037\n",
      "Epoch 2144/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1341 - acc: 0.9448 - val_loss: 1.5357 - val_acc: 0.6667\n",
      "Epoch 2145/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1372 - acc: 0.9387 - val_loss: 1.2473 - val_acc: 0.7037\n",
      "Epoch 2146/3000\n",
      "163/163 [==============================] - 0s 56us/step - loss: 0.1098 - acc: 0.9509 - val_loss: 1.3567 - val_acc: 0.5926\n",
      "Epoch 2147/3000\n",
      "163/163 [==============================] - 0s 53us/step - loss: 0.1044 - acc: 0.9571 - val_loss: 1.2690 - val_acc: 0.7037\n",
      "Epoch 2148/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1027 - acc: 0.9571 - val_loss: 1.3295 - val_acc: 0.5926\n",
      "Epoch 2149/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.1041 - acc: 0.9509 - val_loss: 1.2648 - val_acc: 0.7037\n",
      "Epoch 2150/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1035 - acc: 0.9571 - val_loss: 1.3300 - val_acc: 0.6296\n",
      "Epoch 2151/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1053 - acc: 0.9509 - val_loss: 1.2546 - val_acc: 0.7037\n",
      "Epoch 2152/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.1037 - acc: 0.9632 - val_loss: 1.3481 - val_acc: 0.6296\n",
      "Epoch 2153/3000\n",
      "163/163 [==============================] - 0s 53us/step - loss: 0.1061 - acc: 0.9509 - val_loss: 1.2372 - val_acc: 0.7037\n",
      "Epoch 2154/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.1050 - acc: 0.9571 - val_loss: 1.3607 - val_acc: 0.6296\n",
      "Epoch 2155/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1074 - acc: 0.9448 - val_loss: 1.2224 - val_acc: 0.7037\n",
      "Epoch 2156/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1078 - acc: 0.9571 - val_loss: 1.3992 - val_acc: 0.6296\n",
      "Epoch 2157/3000\n",
      "163/163 [==============================] - 0s 53us/step - loss: 0.1135 - acc: 0.9325 - val_loss: 1.2233 - val_acc: 0.7037\n",
      "Epoch 2158/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1138 - acc: 0.9509 - val_loss: 1.3933 - val_acc: 0.6296\n",
      "Epoch 2159/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1103 - acc: 0.9448 - val_loss: 1.2255 - val_acc: 0.7037\n",
      "Epoch 2160/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1077 - acc: 0.9509 - val_loss: 1.3752 - val_acc: 0.6296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2161/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1095 - acc: 0.9448 - val_loss: 1.2439 - val_acc: 0.7037\n",
      "Epoch 2162/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1059 - acc: 0.9571 - val_loss: 1.3615 - val_acc: 0.6296\n",
      "Epoch 2163/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1057 - acc: 0.9509 - val_loss: 1.2440 - val_acc: 0.7037\n",
      "Epoch 2164/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1047 - acc: 0.9632 - val_loss: 1.3596 - val_acc: 0.6296\n",
      "Epoch 2165/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1079 - acc: 0.9509 - val_loss: 1.2343 - val_acc: 0.7037\n",
      "Epoch 2166/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1053 - acc: 0.9571 - val_loss: 1.3517 - val_acc: 0.6296\n",
      "Epoch 2167/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1064 - acc: 0.9509 - val_loss: 1.2288 - val_acc: 0.7037\n",
      "Epoch 2168/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1050 - acc: 0.9571 - val_loss: 1.3715 - val_acc: 0.6296\n",
      "Epoch 2169/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1078 - acc: 0.9448 - val_loss: 1.2232 - val_acc: 0.7037\n",
      "Epoch 2170/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1073 - acc: 0.9509 - val_loss: 1.3804 - val_acc: 0.6296\n",
      "Epoch 2171/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1106 - acc: 0.9387 - val_loss: 1.2308 - val_acc: 0.7037\n",
      "Epoch 2172/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1090 - acc: 0.9509 - val_loss: 1.3742 - val_acc: 0.6296\n",
      "Epoch 2173/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1084 - acc: 0.9448 - val_loss: 1.2242 - val_acc: 0.7037\n",
      "Epoch 2174/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1071 - acc: 0.9509 - val_loss: 1.3982 - val_acc: 0.6667\n",
      "Epoch 2175/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.1153 - acc: 0.9448 - val_loss: 1.1945 - val_acc: 0.7037\n",
      "Epoch 2176/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1154 - acc: 0.9448 - val_loss: 1.3772 - val_acc: 0.6296\n",
      "Epoch 2177/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1118 - acc: 0.9448 - val_loss: 1.2099 - val_acc: 0.7037\n",
      "Epoch 2178/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1072 - acc: 0.9509 - val_loss: 1.3291 - val_acc: 0.6296\n",
      "Epoch 2179/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1077 - acc: 0.9509 - val_loss: 1.2250 - val_acc: 0.7037\n",
      "Epoch 2180/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1045 - acc: 0.9571 - val_loss: 1.2778 - val_acc: 0.6667\n",
      "Epoch 2181/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.1034 - acc: 0.9571 - val_loss: 1.2332 - val_acc: 0.7037\n",
      "Epoch 2182/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.1025 - acc: 0.9571 - val_loss: 1.2556 - val_acc: 0.7037\n",
      "Epoch 2183/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.1018 - acc: 0.9509 - val_loss: 1.3253 - val_acc: 0.7037\n",
      "Epoch 2184/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.1016 - acc: 0.9509 - val_loss: 1.3458 - val_acc: 0.6296\n",
      "Epoch 2185/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1022 - acc: 0.9509 - val_loss: 1.3132 - val_acc: 0.7037\n",
      "Epoch 2186/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1019 - acc: 0.9571 - val_loss: 1.3637 - val_acc: 0.6296\n",
      "Epoch 2187/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1016 - acc: 0.9571 - val_loss: 1.3038 - val_acc: 0.7037\n",
      "Epoch 2188/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1047 - acc: 0.9509 - val_loss: 1.4360 - val_acc: 0.6296\n",
      "Epoch 2189/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1101 - acc: 0.9448 - val_loss: 1.2676 - val_acc: 0.7037\n",
      "Epoch 2190/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.1123 - acc: 0.9509 - val_loss: 1.4783 - val_acc: 0.6667\n",
      "Epoch 2191/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1185 - acc: 0.9387 - val_loss: 1.2642 - val_acc: 0.7037\n",
      "Epoch 2192/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1219 - acc: 0.9448 - val_loss: 1.4668 - val_acc: 0.6667\n",
      "Epoch 2193/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1205 - acc: 0.9387 - val_loss: 1.2697 - val_acc: 0.7037\n",
      "Epoch 2194/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.1068 - acc: 0.9509 - val_loss: 1.3611 - val_acc: 0.6667\n",
      "Epoch 2195/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1019 - acc: 0.9571 - val_loss: 1.2887 - val_acc: 0.7037\n",
      "Epoch 2196/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.0993 - acc: 0.9571 - val_loss: 1.3269 - val_acc: 0.6667\n",
      "Epoch 2197/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0992 - acc: 0.9571 - val_loss: 1.2874 - val_acc: 0.7407\n",
      "Epoch 2198/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1003 - acc: 0.9571 - val_loss: 1.3391 - val_acc: 0.6667\n",
      "Epoch 2199/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1039 - acc: 0.9509 - val_loss: 1.2624 - val_acc: 0.7037\n",
      "Epoch 2200/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.1039 - acc: 0.9632 - val_loss: 1.3677 - val_acc: 0.6667\n",
      "Epoch 2201/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1076 - acc: 0.9509 - val_loss: 1.2490 - val_acc: 0.7037\n",
      "Epoch 2202/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1039 - acc: 0.9571 - val_loss: 1.4247 - val_acc: 0.6296\n",
      "Epoch 2203/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1055 - acc: 0.9448 - val_loss: 1.2907 - val_acc: 0.7037\n",
      "Epoch 2204/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.1055 - acc: 0.9509 - val_loss: 1.4434 - val_acc: 0.6296\n",
      "Epoch 2205/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.1073 - acc: 0.9387 - val_loss: 1.2866 - val_acc: 0.7037\n",
      "Epoch 2206/3000\n",
      "163/163 [==============================] - 0s 54us/step - loss: 0.1063 - acc: 0.9509 - val_loss: 1.4645 - val_acc: 0.6296\n",
      "Epoch 2207/3000\n",
      "163/163 [==============================] - 0s 56us/step - loss: 0.1124 - acc: 0.9448 - val_loss: 1.2817 - val_acc: 0.7037\n",
      "Epoch 2208/3000\n",
      "163/163 [==============================] - 0s 56us/step - loss: 0.1110 - acc: 0.9448 - val_loss: 1.4801 - val_acc: 0.6667\n",
      "Epoch 2209/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1176 - acc: 0.9387 - val_loss: 1.2808 - val_acc: 0.7037\n",
      "Epoch 2210/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1084 - acc: 0.9509 - val_loss: 1.4280 - val_acc: 0.6296\n",
      "Epoch 2211/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.1073 - acc: 0.9509 - val_loss: 1.3023 - val_acc: 0.7037\n",
      "Epoch 2212/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1034 - acc: 0.9509 - val_loss: 1.4072 - val_acc: 0.6296\n",
      "Epoch 2213/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1019 - acc: 0.9571 - val_loss: 1.3148 - val_acc: 0.7037\n",
      "Epoch 2214/3000\n",
      "163/163 [==============================] - 0s 56us/step - loss: 0.1005 - acc: 0.9571 - val_loss: 1.3806 - val_acc: 0.6667\n",
      "Epoch 2215/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.1013 - acc: 0.9571 - val_loss: 1.3093 - val_acc: 0.7407\n",
      "Epoch 2216/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.1003 - acc: 0.9571 - val_loss: 1.3729 - val_acc: 0.6667\n",
      "Epoch 2217/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1011 - acc: 0.9509 - val_loss: 1.3126 - val_acc: 0.7407\n",
      "Epoch 2218/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1001 - acc: 0.9571 - val_loss: 1.3718 - val_acc: 0.6667\n",
      "Epoch 2219/3000\n",
      "163/163 [==============================] - 0s 55us/step - loss: 0.1003 - acc: 0.9509 - val_loss: 1.3090 - val_acc: 0.7407\n",
      "Epoch 2220/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.0998 - acc: 0.9571 - val_loss: 1.3825 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2221/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1002 - acc: 0.9509 - val_loss: 1.2998 - val_acc: 0.7037\n",
      "Epoch 2222/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0998 - acc: 0.9571 - val_loss: 1.4205 - val_acc: 0.6296\n",
      "Epoch 2223/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1037 - acc: 0.9509 - val_loss: 1.2653 - val_acc: 0.7037\n",
      "Epoch 2224/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1103 - acc: 0.9509 - val_loss: 1.5420 - val_acc: 0.6667\n",
      "Epoch 2225/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1284 - acc: 0.9264 - val_loss: 1.2765 - val_acc: 0.7037\n",
      "Epoch 2226/3000\n",
      "163/163 [==============================] - 0s 56us/step - loss: 0.1341 - acc: 0.9509 - val_loss: 1.5198 - val_acc: 0.6667\n",
      "Epoch 2227/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1260 - acc: 0.9387 - val_loss: 1.2937 - val_acc: 0.7037\n",
      "Epoch 2228/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1028 - acc: 0.9509 - val_loss: 1.3955 - val_acc: 0.6296\n",
      "Epoch 2229/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.0999 - acc: 0.9571 - val_loss: 1.3277 - val_acc: 0.7407\n",
      "Epoch 2230/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.0986 - acc: 0.9571 - val_loss: 1.3598 - val_acc: 0.7037\n",
      "Epoch 2231/3000\n",
      "163/163 [==============================] - 0s 55us/step - loss: 0.0987 - acc: 0.9509 - val_loss: 1.3228 - val_acc: 0.7407\n",
      "Epoch 2232/3000\n",
      "163/163 [==============================] - 0s 57us/step - loss: 0.0990 - acc: 0.9509 - val_loss: 1.3576 - val_acc: 0.7037\n",
      "Epoch 2233/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.1003 - acc: 0.9509 - val_loss: 1.3207 - val_acc: 0.7037\n",
      "Epoch 2234/3000\n",
      "163/163 [==============================] - 0s 54us/step - loss: 0.1003 - acc: 0.9509 - val_loss: 1.3531 - val_acc: 0.7407\n",
      "Epoch 2235/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.0996 - acc: 0.9509 - val_loss: 1.3227 - val_acc: 0.7407\n",
      "Epoch 2236/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.0985 - acc: 0.9509 - val_loss: 1.3567 - val_acc: 0.6667\n",
      "Epoch 2237/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.0985 - acc: 0.9509 - val_loss: 1.3204 - val_acc: 0.7407\n",
      "Epoch 2238/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.0985 - acc: 0.9509 - val_loss: 1.3560 - val_acc: 0.7407\n",
      "Epoch 2239/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.0987 - acc: 0.9509 - val_loss: 1.3303 - val_acc: 0.7407\n",
      "Epoch 2240/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.0977 - acc: 0.9509 - val_loss: 1.3567 - val_acc: 0.6667\n",
      "Epoch 2241/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.0991 - acc: 0.9509 - val_loss: 1.3316 - val_acc: 0.7037\n",
      "Epoch 2242/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.0986 - acc: 0.9509 - val_loss: 1.3457 - val_acc: 0.7407\n",
      "Epoch 2243/3000\n",
      "163/163 [==============================] - 0s 57us/step - loss: 0.0989 - acc: 0.9509 - val_loss: 1.3606 - val_acc: 0.6296\n",
      "Epoch 2244/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1008 - acc: 0.9571 - val_loss: 1.2858 - val_acc: 0.7037\n",
      "Epoch 2245/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1054 - acc: 0.9509 - val_loss: 1.5209 - val_acc: 0.6296\n",
      "Epoch 2246/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1208 - acc: 0.9387 - val_loss: 1.2737 - val_acc: 0.7037\n",
      "Epoch 2247/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1382 - acc: 0.9448 - val_loss: 1.5556 - val_acc: 0.6667\n",
      "Epoch 2248/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.1351 - acc: 0.9325 - val_loss: 1.2752 - val_acc: 0.7037\n",
      "Epoch 2249/3000\n",
      "163/163 [==============================] - 0s 56us/step - loss: 0.1057 - acc: 0.9509 - val_loss: 1.3958 - val_acc: 0.6296\n",
      "Epoch 2250/3000\n",
      "163/163 [==============================] - 0s 60us/step - loss: 0.1007 - acc: 0.9571 - val_loss: 1.3089 - val_acc: 0.7407\n",
      "Epoch 2251/3000\n",
      "163/163 [==============================] - 0s 56us/step - loss: 0.0984 - acc: 0.9571 - val_loss: 1.3616 - val_acc: 0.6667\n",
      "Epoch 2252/3000\n",
      "163/163 [==============================] - 0s 54us/step - loss: 0.0987 - acc: 0.9571 - val_loss: 1.3136 - val_acc: 0.7407\n",
      "Epoch 2253/3000\n",
      "163/163 [==============================] - 0s 64us/step - loss: 0.0978 - acc: 0.9509 - val_loss: 1.3619 - val_acc: 0.6667\n",
      "Epoch 2254/3000\n",
      "163/163 [==============================] - 0s 62us/step - loss: 0.0987 - acc: 0.9571 - val_loss: 1.3103 - val_acc: 0.7407\n",
      "Epoch 2255/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.0977 - acc: 0.9571 - val_loss: 1.3754 - val_acc: 0.6296\n",
      "Epoch 2256/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.0994 - acc: 0.9571 - val_loss: 1.2944 - val_acc: 0.7407\n",
      "Epoch 2257/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.0987 - acc: 0.9632 - val_loss: 1.3971 - val_acc: 0.6296\n",
      "Epoch 2258/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1008 - acc: 0.9571 - val_loss: 1.2752 - val_acc: 0.7407\n",
      "Epoch 2259/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1006 - acc: 0.9571 - val_loss: 1.4235 - val_acc: 0.6296\n",
      "Epoch 2260/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.1043 - acc: 0.9448 - val_loss: 1.2591 - val_acc: 0.7037\n",
      "Epoch 2261/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.1049 - acc: 0.9509 - val_loss: 1.4656 - val_acc: 0.6296\n",
      "Epoch 2262/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.1114 - acc: 0.9325 - val_loss: 1.2537 - val_acc: 0.7037\n",
      "Epoch 2263/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1113 - acc: 0.9509 - val_loss: 1.4693 - val_acc: 0.6296\n",
      "Epoch 2264/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1142 - acc: 0.9325 - val_loss: 1.2572 - val_acc: 0.7037\n",
      "Epoch 2265/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.1071 - acc: 0.9509 - val_loss: 1.4178 - val_acc: 0.6296\n",
      "Epoch 2266/3000\n",
      "163/163 [==============================] - 0s 69us/step - loss: 0.1066 - acc: 0.9448 - val_loss: 1.2808 - val_acc: 0.7037\n",
      "Epoch 2267/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1018 - acc: 0.9509 - val_loss: 1.3895 - val_acc: 0.6296\n",
      "Epoch 2268/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.0990 - acc: 0.9571 - val_loss: 1.2957 - val_acc: 0.7407\n",
      "Epoch 2269/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.0976 - acc: 0.9571 - val_loss: 1.3522 - val_acc: 0.6667\n",
      "Epoch 2270/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.0988 - acc: 0.9571 - val_loss: 1.2821 - val_acc: 0.7407\n",
      "Epoch 2271/3000\n",
      "163/163 [==============================] - 0s 64us/step - loss: 0.0980 - acc: 0.9571 - val_loss: 1.3535 - val_acc: 0.6667\n",
      "Epoch 2272/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.0998 - acc: 0.9571 - val_loss: 1.2641 - val_acc: 0.7407\n",
      "Epoch 2273/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.0992 - acc: 0.9632 - val_loss: 1.3549 - val_acc: 0.6667\n",
      "Epoch 2274/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1009 - acc: 0.9571 - val_loss: 1.2583 - val_acc: 0.7407\n",
      "Epoch 2275/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.0997 - acc: 0.9571 - val_loss: 1.3672 - val_acc: 0.6667\n",
      "Epoch 2276/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1015 - acc: 0.9571 - val_loss: 1.2388 - val_acc: 0.7407\n",
      "Epoch 2277/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1018 - acc: 0.9571 - val_loss: 1.4231 - val_acc: 0.6296\n",
      "Epoch 2278/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.1091 - acc: 0.9325 - val_loss: 1.2249 - val_acc: 0.7037\n",
      "Epoch 2279/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1140 - acc: 0.9509 - val_loss: 1.4442 - val_acc: 0.7037\n",
      "Epoch 2280/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1226 - acc: 0.9325 - val_loss: 1.2333 - val_acc: 0.7037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2281/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1123 - acc: 0.9509 - val_loss: 1.4506 - val_acc: 0.6296\n",
      "Epoch 2282/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1047 - acc: 0.9448 - val_loss: 1.3199 - val_acc: 0.7037\n",
      "Epoch 2283/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.0984 - acc: 0.9571 - val_loss: 1.3918 - val_acc: 0.6296\n",
      "Epoch 2284/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0969 - acc: 0.9571 - val_loss: 1.3320 - val_acc: 0.7407\n",
      "Epoch 2285/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0959 - acc: 0.9571 - val_loss: 1.3853 - val_acc: 0.6667\n",
      "Epoch 2286/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0973 - acc: 0.9571 - val_loss: 1.3260 - val_acc: 0.7407\n",
      "Epoch 2287/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.0973 - acc: 0.9571 - val_loss: 1.3883 - val_acc: 0.6667\n",
      "Epoch 2288/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.0989 - acc: 0.9448 - val_loss: 1.3116 - val_acc: 0.7407\n",
      "Epoch 2289/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.0986 - acc: 0.9571 - val_loss: 1.3926 - val_acc: 0.6667\n",
      "Epoch 2290/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.0988 - acc: 0.9509 - val_loss: 1.3113 - val_acc: 0.7407\n",
      "Epoch 2291/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.0975 - acc: 0.9571 - val_loss: 1.4157 - val_acc: 0.6667\n",
      "Epoch 2292/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.0994 - acc: 0.9632 - val_loss: 1.2932 - val_acc: 0.7037\n",
      "Epoch 2293/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.0990 - acc: 0.9571 - val_loss: 1.4458 - val_acc: 0.6296\n",
      "Epoch 2294/3000\n",
      "163/163 [==============================] - 0s 56us/step - loss: 0.1022 - acc: 0.9448 - val_loss: 1.2809 - val_acc: 0.7037\n",
      "Epoch 2295/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1073 - acc: 0.9509 - val_loss: 1.5299 - val_acc: 0.6667\n",
      "Epoch 2296/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1229 - acc: 0.9325 - val_loss: 1.2892 - val_acc: 0.7037\n",
      "Epoch 2297/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1278 - acc: 0.9509 - val_loss: 1.5232 - val_acc: 0.6667\n",
      "Epoch 2298/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1235 - acc: 0.9387 - val_loss: 1.3002 - val_acc: 0.7037\n",
      "Epoch 2299/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1001 - acc: 0.9509 - val_loss: 1.3946 - val_acc: 0.6296\n",
      "Epoch 2300/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0965 - acc: 0.9571 - val_loss: 1.3366 - val_acc: 0.7407\n",
      "Epoch 2301/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0953 - acc: 0.9571 - val_loss: 1.3709 - val_acc: 0.6667\n",
      "Epoch 2302/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.0953 - acc: 0.9509 - val_loss: 1.3346 - val_acc: 0.7407\n",
      "Epoch 2303/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.0955 - acc: 0.9509 - val_loss: 1.3741 - val_acc: 0.6667\n",
      "Epoch 2304/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.0966 - acc: 0.9509 - val_loss: 1.3246 - val_acc: 0.7407\n",
      "Epoch 2305/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.0964 - acc: 0.9509 - val_loss: 1.3733 - val_acc: 0.6667\n",
      "Epoch 2306/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.0976 - acc: 0.9509 - val_loss: 1.3268 - val_acc: 0.7407\n",
      "Epoch 2307/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0971 - acc: 0.9509 - val_loss: 1.3724 - val_acc: 0.6667\n",
      "Epoch 2308/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.0971 - acc: 0.9509 - val_loss: 1.3314 - val_acc: 0.7407\n",
      "Epoch 2309/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.0968 - acc: 0.9509 - val_loss: 1.3664 - val_acc: 0.7037\n",
      "Epoch 2310/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.0961 - acc: 0.9509 - val_loss: 1.3390 - val_acc: 0.7407\n",
      "Epoch 2311/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.0944 - acc: 0.9509 - val_loss: 1.3643 - val_acc: 0.7037\n",
      "Epoch 2312/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.0952 - acc: 0.9509 - val_loss: 1.3369 - val_acc: 0.7407\n",
      "Epoch 2313/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0954 - acc: 0.9509 - val_loss: 1.3683 - val_acc: 0.7407\n",
      "Epoch 2314/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.0957 - acc: 0.9509 - val_loss: 1.3397 - val_acc: 0.7037\n",
      "Epoch 2315/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.0957 - acc: 0.9509 - val_loss: 1.3646 - val_acc: 0.7407\n",
      "Epoch 2316/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.0959 - acc: 0.9509 - val_loss: 1.3403 - val_acc: 0.6667\n",
      "Epoch 2317/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.0954 - acc: 0.9509 - val_loss: 1.3562 - val_acc: 0.7037\n",
      "Epoch 2318/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.0965 - acc: 0.9509 - val_loss: 1.3733 - val_acc: 0.6296\n",
      "Epoch 2319/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0979 - acc: 0.9509 - val_loss: 1.2796 - val_acc: 0.7037\n",
      "Epoch 2320/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.1071 - acc: 0.9509 - val_loss: 1.6287 - val_acc: 0.6667\n",
      "Epoch 2321/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1429 - acc: 0.9448 - val_loss: 1.2980 - val_acc: 0.7037\n",
      "Epoch 2322/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1454 - acc: 0.9509 - val_loss: 1.5220 - val_acc: 0.6667\n",
      "Epoch 2323/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.1218 - acc: 0.9387 - val_loss: 1.3079 - val_acc: 0.7037\n",
      "Epoch 2324/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.0976 - acc: 0.9509 - val_loss: 1.3834 - val_acc: 0.6296\n",
      "Epoch 2325/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.0951 - acc: 0.9571 - val_loss: 1.3361 - val_acc: 0.7407\n",
      "Epoch 2326/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0946 - acc: 0.9509 - val_loss: 1.3706 - val_acc: 0.6667\n",
      "Epoch 2327/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0956 - acc: 0.9509 - val_loss: 1.3295 - val_acc: 0.7407\n",
      "Epoch 2328/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.0955 - acc: 0.9571 - val_loss: 1.3750 - val_acc: 0.6667\n",
      "Epoch 2329/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.0969 - acc: 0.9509 - val_loss: 1.3205 - val_acc: 0.7407\n",
      "Epoch 2330/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.0958 - acc: 0.9571 - val_loss: 1.3682 - val_acc: 0.6667\n",
      "Epoch 2331/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.0958 - acc: 0.9571 - val_loss: 1.3178 - val_acc: 0.7407\n",
      "Epoch 2332/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.0949 - acc: 0.9571 - val_loss: 1.3856 - val_acc: 0.6667\n",
      "Epoch 2333/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.0959 - acc: 0.9571 - val_loss: 1.3022 - val_acc: 0.7407\n",
      "Epoch 2334/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.0962 - acc: 0.9632 - val_loss: 1.4215 - val_acc: 0.6296\n",
      "Epoch 2335/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0997 - acc: 0.9509 - val_loss: 1.2817 - val_acc: 0.7037\n",
      "Epoch 2336/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.1031 - acc: 0.9509 - val_loss: 1.4748 - val_acc: 0.6296\n",
      "Epoch 2337/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.1083 - acc: 0.9387 - val_loss: 1.2681 - val_acc: 0.7037\n",
      "Epoch 2338/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1067 - acc: 0.9571 - val_loss: 1.4755 - val_acc: 0.6296\n",
      "Epoch 2339/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1087 - acc: 0.9448 - val_loss: 1.2673 - val_acc: 0.7037\n",
      "Epoch 2340/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1049 - acc: 0.9509 - val_loss: 1.4435 - val_acc: 0.6296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2341/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.1062 - acc: 0.9448 - val_loss: 1.2694 - val_acc: 0.7407\n",
      "Epoch 2342/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.0999 - acc: 0.9571 - val_loss: 1.4251 - val_acc: 0.6296\n",
      "Epoch 2343/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.0981 - acc: 0.9509 - val_loss: 1.3132 - val_acc: 0.7407\n",
      "Epoch 2344/3000\n",
      "163/163 [==============================] - 0s 57us/step - loss: 0.0954 - acc: 0.9571 - val_loss: 1.3921 - val_acc: 0.6667\n",
      "Epoch 2345/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.0950 - acc: 0.9571 - val_loss: 1.3149 - val_acc: 0.7407\n",
      "Epoch 2346/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.0947 - acc: 0.9571 - val_loss: 1.3977 - val_acc: 0.6667\n",
      "Epoch 2347/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0973 - acc: 0.9571 - val_loss: 1.2966 - val_acc: 0.7407\n",
      "Epoch 2348/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.0978 - acc: 0.9571 - val_loss: 1.4248 - val_acc: 0.6667\n",
      "Epoch 2349/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.1017 - acc: 0.9509 - val_loss: 1.2766 - val_acc: 0.7407\n",
      "Epoch 2350/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.0996 - acc: 0.9571 - val_loss: 1.4285 - val_acc: 0.6667\n",
      "Epoch 2351/3000\n",
      "163/163 [==============================] - 0s 53us/step - loss: 0.1005 - acc: 0.9448 - val_loss: 1.2811 - val_acc: 0.7407\n",
      "Epoch 2352/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.0982 - acc: 0.9571 - val_loss: 1.4482 - val_acc: 0.6296\n",
      "Epoch 2353/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1015 - acc: 0.9448 - val_loss: 1.2786 - val_acc: 0.7037\n",
      "Epoch 2354/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1026 - acc: 0.9509 - val_loss: 1.4675 - val_acc: 0.6296\n",
      "Epoch 2355/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.1088 - acc: 0.9387 - val_loss: 1.2871 - val_acc: 0.7037\n",
      "Epoch 2356/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1084 - acc: 0.9509 - val_loss: 1.4817 - val_acc: 0.6667\n",
      "Epoch 2357/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1111 - acc: 0.9448 - val_loss: 1.2779 - val_acc: 0.7407\n",
      "Epoch 2358/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1067 - acc: 0.9448 - val_loss: 1.4473 - val_acc: 0.6296\n",
      "Epoch 2359/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1030 - acc: 0.9448 - val_loss: 1.2933 - val_acc: 0.7407\n",
      "Epoch 2360/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.0958 - acc: 0.9571 - val_loss: 1.3788 - val_acc: 0.6296\n",
      "Epoch 2361/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.0952 - acc: 0.9509 - val_loss: 1.3050 - val_acc: 0.7407\n",
      "Epoch 2362/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.0935 - acc: 0.9571 - val_loss: 1.3651 - val_acc: 0.6667\n",
      "Epoch 2363/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.0938 - acc: 0.9571 - val_loss: 1.3104 - val_acc: 0.7407\n",
      "Epoch 2364/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.0938 - acc: 0.9571 - val_loss: 1.3561 - val_acc: 0.6667\n",
      "Epoch 2365/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.0961 - acc: 0.9448 - val_loss: 1.2962 - val_acc: 0.7407\n",
      "Epoch 2366/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.0965 - acc: 0.9571 - val_loss: 1.3604 - val_acc: 0.6667\n",
      "Epoch 2367/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0980 - acc: 0.9509 - val_loss: 1.2935 - val_acc: 0.7407\n",
      "Epoch 2368/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.0958 - acc: 0.9571 - val_loss: 1.3771 - val_acc: 0.6667\n",
      "Epoch 2369/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.0958 - acc: 0.9632 - val_loss: 1.2834 - val_acc: 0.7407\n",
      "Epoch 2370/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0964 - acc: 0.9571 - val_loss: 1.4544 - val_acc: 0.6296\n",
      "Epoch 2371/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1043 - acc: 0.9387 - val_loss: 1.2437 - val_acc: 0.7037\n",
      "Epoch 2372/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1101 - acc: 0.9571 - val_loss: 1.4886 - val_acc: 0.6296\n",
      "Epoch 2373/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1145 - acc: 0.9387 - val_loss: 1.2649 - val_acc: 0.7037\n",
      "Epoch 2374/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.1106 - acc: 0.9509 - val_loss: 1.4644 - val_acc: 0.6667\n",
      "Epoch 2375/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.1081 - acc: 0.9448 - val_loss: 1.2649 - val_acc: 0.7037\n",
      "Epoch 2376/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.0991 - acc: 0.9509 - val_loss: 1.3834 - val_acc: 0.6296\n",
      "Epoch 2377/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.0948 - acc: 0.9571 - val_loss: 1.2920 - val_acc: 0.7407\n",
      "Epoch 2378/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.0927 - acc: 0.9571 - val_loss: 1.3267 - val_acc: 0.6667\n",
      "Epoch 2379/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.0930 - acc: 0.9509 - val_loss: 1.2899 - val_acc: 0.7407\n",
      "Epoch 2380/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.0932 - acc: 0.9571 - val_loss: 1.3229 - val_acc: 0.6667\n",
      "Epoch 2381/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.0949 - acc: 0.9571 - val_loss: 1.2822 - val_acc: 0.7407\n",
      "Epoch 2382/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.0952 - acc: 0.9571 - val_loss: 1.3233 - val_acc: 0.6667\n",
      "Epoch 2383/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.0969 - acc: 0.9448 - val_loss: 1.2800 - val_acc: 0.7407\n",
      "Epoch 2384/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.0956 - acc: 0.9571 - val_loss: 1.3227 - val_acc: 0.6667\n",
      "Epoch 2385/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.0947 - acc: 0.9509 - val_loss: 1.2659 - val_acc: 0.7407\n",
      "Epoch 2386/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.0938 - acc: 0.9571 - val_loss: 1.3542 - val_acc: 0.6667\n",
      "Epoch 2387/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0957 - acc: 0.9571 - val_loss: 1.3073 - val_acc: 0.7037\n",
      "Epoch 2388/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.0998 - acc: 0.9571 - val_loss: 1.5310 - val_acc: 0.6296\n",
      "Epoch 2389/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1140 - acc: 0.9387 - val_loss: 1.3058 - val_acc: 0.7037\n",
      "Epoch 2390/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1211 - acc: 0.9509 - val_loss: 1.5331 - val_acc: 0.6667\n",
      "Epoch 2391/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.1177 - acc: 0.9387 - val_loss: 1.3165 - val_acc: 0.7037\n",
      "Epoch 2392/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.1011 - acc: 0.9509 - val_loss: 1.4354 - val_acc: 0.6296\n",
      "Epoch 2393/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.0969 - acc: 0.9509 - val_loss: 1.3343 - val_acc: 0.7407\n",
      "Epoch 2394/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.0929 - acc: 0.9571 - val_loss: 1.4037 - val_acc: 0.6667\n",
      "Epoch 2395/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0925 - acc: 0.9571 - val_loss: 1.3459 - val_acc: 0.7407\n",
      "Epoch 2396/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0921 - acc: 0.9571 - val_loss: 1.3988 - val_acc: 0.6667\n",
      "Epoch 2397/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.0934 - acc: 0.9571 - val_loss: 1.3318 - val_acc: 0.7407\n",
      "Epoch 2398/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.0939 - acc: 0.9571 - val_loss: 1.4014 - val_acc: 0.6667\n",
      "Epoch 2399/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.0956 - acc: 0.9448 - val_loss: 1.3198 - val_acc: 0.7407\n",
      "Epoch 2400/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.0948 - acc: 0.9571 - val_loss: 1.3990 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2401/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.0944 - acc: 0.9571 - val_loss: 1.3109 - val_acc: 0.7407\n",
      "Epoch 2402/3000\n",
      "163/163 [==============================] - 0s 57us/step - loss: 0.0936 - acc: 0.9571 - val_loss: 1.4162 - val_acc: 0.6667\n",
      "Epoch 2403/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.0950 - acc: 0.9571 - val_loss: 1.2988 - val_acc: 0.7407\n",
      "Epoch 2404/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.0989 - acc: 0.9571 - val_loss: 1.4955 - val_acc: 0.6667\n",
      "Epoch 2405/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1104 - acc: 0.9387 - val_loss: 1.2827 - val_acc: 0.7037\n",
      "Epoch 2406/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.1168 - acc: 0.9509 - val_loss: 1.5320 - val_acc: 0.6667\n",
      "Epoch 2407/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1284 - acc: 0.9264 - val_loss: 1.2715 - val_acc: 0.7037\n",
      "Epoch 2408/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1013 - acc: 0.9571 - val_loss: 1.4304 - val_acc: 0.6296\n",
      "Epoch 2409/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0941 - acc: 0.9571 - val_loss: 1.3482 - val_acc: 0.7407\n",
      "Epoch 2410/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.0916 - acc: 0.9571 - val_loss: 1.4038 - val_acc: 0.6667\n",
      "Epoch 2411/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.0920 - acc: 0.9509 - val_loss: 1.3573 - val_acc: 0.7407\n",
      "Epoch 2412/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.0914 - acc: 0.9571 - val_loss: 1.3997 - val_acc: 0.6667\n",
      "Epoch 2413/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.0922 - acc: 0.9509 - val_loss: 1.3509 - val_acc: 0.7037\n",
      "Epoch 2414/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.0923 - acc: 0.9571 - val_loss: 1.3995 - val_acc: 0.7037\n",
      "Epoch 2415/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.0926 - acc: 0.9509 - val_loss: 1.3513 - val_acc: 0.7037\n",
      "Epoch 2416/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.0926 - acc: 0.9509 - val_loss: 1.4031 - val_acc: 0.6667\n",
      "Epoch 2417/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.0931 - acc: 0.9509 - val_loss: 1.3465 - val_acc: 0.7037\n",
      "Epoch 2418/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.0931 - acc: 0.9571 - val_loss: 1.4028 - val_acc: 0.6667\n",
      "Epoch 2419/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.0926 - acc: 0.9509 - val_loss: 1.3478 - val_acc: 0.7407\n",
      "Epoch 2420/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.0917 - acc: 0.9571 - val_loss: 1.4370 - val_acc: 0.6667\n",
      "Epoch 2421/3000\n",
      "163/163 [==============================] - 0s 55us/step - loss: 0.0942 - acc: 0.9632 - val_loss: 1.3090 - val_acc: 0.7407\n",
      "Epoch 2422/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0986 - acc: 0.9509 - val_loss: 1.5412 - val_acc: 0.6296\n",
      "Epoch 2423/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.1130 - acc: 0.9325 - val_loss: 1.3068 - val_acc: 0.7037\n",
      "Epoch 2424/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1205 - acc: 0.9509 - val_loss: 1.5541 - val_acc: 0.6667\n",
      "Epoch 2425/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1234 - acc: 0.9325 - val_loss: 1.3131 - val_acc: 0.7037\n",
      "Epoch 2426/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1016 - acc: 0.9509 - val_loss: 1.4608 - val_acc: 0.6296\n",
      "Epoch 2427/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.0955 - acc: 0.9509 - val_loss: 1.3502 - val_acc: 0.7407\n",
      "Epoch 2428/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.0917 - acc: 0.9571 - val_loss: 1.4175 - val_acc: 0.6667\n",
      "Epoch 2429/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.0911 - acc: 0.9571 - val_loss: 1.3611 - val_acc: 0.7407\n",
      "Epoch 2430/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.0906 - acc: 0.9571 - val_loss: 1.4106 - val_acc: 0.6667\n",
      "Epoch 2431/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.0915 - acc: 0.9571 - val_loss: 1.3479 - val_acc: 0.7407\n",
      "Epoch 2432/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.0916 - acc: 0.9571 - val_loss: 1.4144 - val_acc: 0.6667\n",
      "Epoch 2433/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.0926 - acc: 0.9509 - val_loss: 1.3471 - val_acc: 0.7407\n",
      "Epoch 2434/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.0927 - acc: 0.9571 - val_loss: 1.4154 - val_acc: 0.6667\n",
      "Epoch 2435/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0927 - acc: 0.9509 - val_loss: 1.3402 - val_acc: 0.7407\n",
      "Epoch 2436/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0919 - acc: 0.9571 - val_loss: 1.4398 - val_acc: 0.6667\n",
      "Epoch 2437/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.0933 - acc: 0.9632 - val_loss: 1.3203 - val_acc: 0.7407\n",
      "Epoch 2438/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.0960 - acc: 0.9571 - val_loss: 1.5182 - val_acc: 0.6296\n",
      "Epoch 2439/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.1070 - acc: 0.9387 - val_loss: 1.2948 - val_acc: 0.7037\n",
      "Epoch 2440/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1143 - acc: 0.9509 - val_loss: 1.5507 - val_acc: 0.6667\n",
      "Epoch 2441/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1216 - acc: 0.9264 - val_loss: 1.3031 - val_acc: 0.7407\n",
      "Epoch 2442/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1041 - acc: 0.9509 - val_loss: 1.4488 - val_acc: 0.6296\n",
      "Epoch 2443/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.0971 - acc: 0.9509 - val_loss: 1.3338 - val_acc: 0.7407\n",
      "Epoch 2444/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0915 - acc: 0.9571 - val_loss: 1.4130 - val_acc: 0.6667\n",
      "Epoch 2445/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.0903 - acc: 0.9571 - val_loss: 1.3572 - val_acc: 0.7407\n",
      "Epoch 2446/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.0897 - acc: 0.9571 - val_loss: 1.4081 - val_acc: 0.6667\n",
      "Epoch 2447/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.0901 - acc: 0.9509 - val_loss: 1.3534 - val_acc: 0.7037\n",
      "Epoch 2448/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.0910 - acc: 0.9571 - val_loss: 1.4150 - val_acc: 0.6667\n",
      "Epoch 2449/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.0922 - acc: 0.9509 - val_loss: 1.3465 - val_acc: 0.7037\n",
      "Epoch 2450/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.0924 - acc: 0.9571 - val_loss: 1.4186 - val_acc: 0.6667\n",
      "Epoch 2451/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.0931 - acc: 0.9448 - val_loss: 1.3444 - val_acc: 0.7037\n",
      "Epoch 2452/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.0920 - acc: 0.9571 - val_loss: 1.4123 - val_acc: 0.6667\n",
      "Epoch 2453/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0912 - acc: 0.9509 - val_loss: 1.3473 - val_acc: 0.7407\n",
      "Epoch 2454/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0899 - acc: 0.9571 - val_loss: 1.4445 - val_acc: 0.6667\n",
      "Epoch 2455/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.0920 - acc: 0.9632 - val_loss: 1.3240 - val_acc: 0.7407\n",
      "Epoch 2456/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.0977 - acc: 0.9509 - val_loss: 1.5350 - val_acc: 0.6296\n",
      "Epoch 2457/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1075 - acc: 0.9448 - val_loss: 1.3178 - val_acc: 0.7037\n",
      "Epoch 2458/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1191 - acc: 0.9509 - val_loss: 1.5774 - val_acc: 0.6667\n",
      "Epoch 2459/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1260 - acc: 0.9264 - val_loss: 1.2980 - val_acc: 0.7407\n",
      "Epoch 2460/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1095 - acc: 0.9509 - val_loss: 1.4695 - val_acc: 0.6296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2461/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.0981 - acc: 0.9448 - val_loss: 1.3375 - val_acc: 0.7407\n",
      "Epoch 2462/3000\n",
      "163/163 [==============================] - 0s 61us/step - loss: 0.0907 - acc: 0.9571 - val_loss: 1.4045 - val_acc: 0.6667\n",
      "Epoch 2463/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.0902 - acc: 0.9571 - val_loss: 1.3514 - val_acc: 0.7037\n",
      "Epoch 2464/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.0895 - acc: 0.9509 - val_loss: 1.3932 - val_acc: 0.7037\n",
      "Epoch 2465/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0896 - acc: 0.9509 - val_loss: 1.3597 - val_acc: 0.7037\n",
      "Epoch 2466/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.0896 - acc: 0.9509 - val_loss: 1.3964 - val_acc: 0.7037\n",
      "Epoch 2467/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.0892 - acc: 0.9509 - val_loss: 1.3706 - val_acc: 0.6667\n",
      "Epoch 2468/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.0888 - acc: 0.9509 - val_loss: 1.3907 - val_acc: 0.7037\n",
      "Epoch 2469/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.0893 - acc: 0.9509 - val_loss: 1.3679 - val_acc: 0.6667\n",
      "Epoch 2470/3000\n",
      "163/163 [==============================] - 0s 54us/step - loss: 0.0899 - acc: 0.9509 - val_loss: 1.3904 - val_acc: 0.7037\n",
      "Epoch 2471/3000\n",
      "163/163 [==============================] - 0s 55us/step - loss: 0.0901 - acc: 0.9509 - val_loss: 1.3798 - val_acc: 0.6667\n",
      "Epoch 2472/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.0896 - acc: 0.9509 - val_loss: 1.3817 - val_acc: 0.7407\n",
      "Epoch 2473/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.0910 - acc: 0.9571 - val_loss: 1.4195 - val_acc: 0.6296\n",
      "Epoch 2474/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.0943 - acc: 0.9571 - val_loss: 1.3278 - val_acc: 0.7407\n",
      "Epoch 2475/3000\n",
      "163/163 [==============================] - 0s 59us/step - loss: 0.0993 - acc: 0.9509 - val_loss: 1.5265 - val_acc: 0.6296\n",
      "Epoch 2476/3000\n",
      "163/163 [==============================] - 0s 58us/step - loss: 0.1095 - acc: 0.9387 - val_loss: 1.3431 - val_acc: 0.7037\n",
      "Epoch 2477/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1145 - acc: 0.9509 - val_loss: 1.5259 - val_acc: 0.6296\n",
      "Epoch 2478/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.1091 - acc: 0.9448 - val_loss: 1.3455 - val_acc: 0.7407\n",
      "Epoch 2479/3000\n",
      "163/163 [==============================] - 0s 56us/step - loss: 0.0973 - acc: 0.9509 - val_loss: 1.4673 - val_acc: 0.6296\n",
      "Epoch 2480/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.0946 - acc: 0.9509 - val_loss: 1.3484 - val_acc: 0.7407\n",
      "Epoch 2481/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.0917 - acc: 0.9571 - val_loss: 1.4385 - val_acc: 0.6667\n",
      "Epoch 2482/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.0940 - acc: 0.9571 - val_loss: 1.3325 - val_acc: 0.7407\n",
      "Epoch 2483/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.0942 - acc: 0.9571 - val_loss: 1.4506 - val_acc: 0.6667\n",
      "Epoch 2484/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.0967 - acc: 0.9571 - val_loss: 1.3312 - val_acc: 0.7407\n",
      "Epoch 2485/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.0924 - acc: 0.9571 - val_loss: 1.4496 - val_acc: 0.6667\n",
      "Epoch 2486/3000\n",
      "163/163 [==============================] - 0s 62us/step - loss: 0.0921 - acc: 0.9632 - val_loss: 1.3454 - val_acc: 0.7407\n",
      "Epoch 2487/3000\n",
      "163/163 [==============================] - 0s 63us/step - loss: 0.0904 - acc: 0.9571 - val_loss: 1.4434 - val_acc: 0.6667\n",
      "Epoch 2488/3000\n",
      "163/163 [==============================] - 0s 53us/step - loss: 0.0923 - acc: 0.9571 - val_loss: 1.3381 - val_acc: 0.7407\n",
      "Epoch 2489/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.0915 - acc: 0.9571 - val_loss: 1.4574 - val_acc: 0.6667\n",
      "Epoch 2490/3000\n",
      "163/163 [==============================] - 0s 65us/step - loss: 0.0929 - acc: 0.9509 - val_loss: 1.3307 - val_acc: 0.7407\n",
      "Epoch 2491/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.0951 - acc: 0.9571 - val_loss: 1.4894 - val_acc: 0.6296\n",
      "Epoch 2492/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.1023 - acc: 0.9448 - val_loss: 1.3094 - val_acc: 0.7407\n",
      "Epoch 2493/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1038 - acc: 0.9509 - val_loss: 1.5172 - val_acc: 0.6296\n",
      "Epoch 2494/3000\n",
      "163/163 [==============================] - 0s 55us/step - loss: 0.1050 - acc: 0.9387 - val_loss: 1.3262 - val_acc: 0.7407\n",
      "Epoch 2495/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.1012 - acc: 0.9509 - val_loss: 1.4802 - val_acc: 0.6667\n",
      "Epoch 2496/3000\n",
      "163/163 [==============================] - 0s 59us/step - loss: 0.1003 - acc: 0.9387 - val_loss: 1.3240 - val_acc: 0.7407\n",
      "Epoch 2497/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.0923 - acc: 0.9571 - val_loss: 1.4345 - val_acc: 0.6667\n",
      "Epoch 2498/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.0906 - acc: 0.9632 - val_loss: 1.3549 - val_acc: 0.7407\n",
      "Epoch 2499/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.0895 - acc: 0.9509 - val_loss: 1.4239 - val_acc: 0.6667\n",
      "Epoch 2500/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0888 - acc: 0.9571 - val_loss: 1.3537 - val_acc: 0.7407\n",
      "Epoch 2501/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.0881 - acc: 0.9571 - val_loss: 1.4107 - val_acc: 0.6667\n",
      "Epoch 2502/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.0886 - acc: 0.9509 - val_loss: 1.3461 - val_acc: 0.7037\n",
      "Epoch 2503/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.0886 - acc: 0.9571 - val_loss: 1.4057 - val_acc: 0.6667\n",
      "Epoch 2504/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.0888 - acc: 0.9509 - val_loss: 1.3679 - val_acc: 0.7037\n",
      "Epoch 2505/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.0883 - acc: 0.9571 - val_loss: 1.4344 - val_acc: 0.6667\n",
      "Epoch 2506/3000\n",
      "163/163 [==============================] - 0s 56us/step - loss: 0.0888 - acc: 0.9509 - val_loss: 1.3523 - val_acc: 0.7407\n",
      "Epoch 2507/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.0897 - acc: 0.9571 - val_loss: 1.4656 - val_acc: 0.6667\n",
      "Epoch 2508/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.0915 - acc: 0.9632 - val_loss: 1.3279 - val_acc: 0.7407\n",
      "Epoch 2509/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.0952 - acc: 0.9571 - val_loss: 1.5647 - val_acc: 0.6296\n",
      "Epoch 2510/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1134 - acc: 0.9325 - val_loss: 1.3305 - val_acc: 0.7407\n",
      "Epoch 2511/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1276 - acc: 0.9509 - val_loss: 1.5923 - val_acc: 0.6667\n",
      "Epoch 2512/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1292 - acc: 0.9387 - val_loss: 1.3314 - val_acc: 0.7037\n",
      "Epoch 2513/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0945 - acc: 0.9509 - val_loss: 1.4407 - val_acc: 0.6667\n",
      "Epoch 2514/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.0890 - acc: 0.9632 - val_loss: 1.3767 - val_acc: 0.7407\n",
      "Epoch 2515/3000\n",
      "163/163 [==============================] - 0s 54us/step - loss: 0.0873 - acc: 0.9571 - val_loss: 1.4182 - val_acc: 0.6667\n",
      "Epoch 2516/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.0870 - acc: 0.9509 - val_loss: 1.3800 - val_acc: 0.7037\n",
      "Epoch 2517/3000\n",
      "163/163 [==============================] - 0s 54us/step - loss: 0.0872 - acc: 0.9509 - val_loss: 1.4141 - val_acc: 0.6667\n",
      "Epoch 2518/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.0874 - acc: 0.9509 - val_loss: 1.3822 - val_acc: 0.7037\n",
      "Epoch 2519/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.0876 - acc: 0.9509 - val_loss: 1.4127 - val_acc: 0.7037\n",
      "Epoch 2520/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.0874 - acc: 0.9509 - val_loss: 1.3844 - val_acc: 0.7037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2521/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.0872 - acc: 0.9509 - val_loss: 1.4122 - val_acc: 0.7037\n",
      "Epoch 2522/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.0878 - acc: 0.9509 - val_loss: 1.3812 - val_acc: 0.6667\n",
      "Epoch 2523/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.0892 - acc: 0.9509 - val_loss: 1.4160 - val_acc: 0.7037\n",
      "Epoch 2524/3000\n",
      "163/163 [==============================] - 0s 59us/step - loss: 0.0896 - acc: 0.9509 - val_loss: 1.3878 - val_acc: 0.6667\n",
      "Epoch 2525/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.0892 - acc: 0.9509 - val_loss: 1.3995 - val_acc: 0.7037\n",
      "Epoch 2526/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.0892 - acc: 0.9571 - val_loss: 1.4019 - val_acc: 0.6667\n",
      "Epoch 2527/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.0892 - acc: 0.9509 - val_loss: 1.3778 - val_acc: 0.7407\n",
      "Epoch 2528/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.0900 - acc: 0.9571 - val_loss: 1.4891 - val_acc: 0.6667\n",
      "Epoch 2529/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.0967 - acc: 0.9387 - val_loss: 1.3386 - val_acc: 0.7037\n",
      "Epoch 2530/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.1103 - acc: 0.9571 - val_loss: 1.5987 - val_acc: 0.6667\n",
      "Epoch 2531/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1210 - acc: 0.9448 - val_loss: 1.3703 - val_acc: 0.7778\n",
      "Epoch 2532/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1181 - acc: 0.9509 - val_loss: 1.5525 - val_acc: 0.6667\n",
      "Epoch 2533/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1086 - acc: 0.9387 - val_loss: 1.3515 - val_acc: 0.7407\n",
      "Epoch 2534/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.0941 - acc: 0.9509 - val_loss: 1.4627 - val_acc: 0.6667\n",
      "Epoch 2535/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.0919 - acc: 0.9571 - val_loss: 1.3646 - val_acc: 0.7037\n",
      "Epoch 2536/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.0908 - acc: 0.9571 - val_loss: 1.4505 - val_acc: 0.6667\n",
      "Epoch 2537/3000\n",
      "163/163 [==============================] - 0s 57us/step - loss: 0.0914 - acc: 0.9509 - val_loss: 1.3710 - val_acc: 0.7037\n",
      "Epoch 2538/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.0888 - acc: 0.9571 - val_loss: 1.4391 - val_acc: 0.6667\n",
      "Epoch 2539/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.0880 - acc: 0.9509 - val_loss: 1.3790 - val_acc: 0.7037\n",
      "Epoch 2540/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.0869 - acc: 0.9571 - val_loss: 1.4308 - val_acc: 0.6667\n",
      "Epoch 2541/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.0869 - acc: 0.9509 - val_loss: 1.3792 - val_acc: 0.7037\n",
      "Epoch 2542/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0867 - acc: 0.9571 - val_loss: 1.4317 - val_acc: 0.6667\n",
      "Epoch 2543/3000\n",
      "163/163 [==============================] - 0s 63us/step - loss: 0.0867 - acc: 0.9509 - val_loss: 1.3817 - val_acc: 0.7037\n",
      "Epoch 2544/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.0867 - acc: 0.9571 - val_loss: 1.4420 - val_acc: 0.6667\n",
      "Epoch 2545/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.0877 - acc: 0.9571 - val_loss: 1.3645 - val_acc: 0.7407\n",
      "Epoch 2546/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.0889 - acc: 0.9571 - val_loss: 1.4996 - val_acc: 0.6667\n",
      "Epoch 2547/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.0951 - acc: 0.9509 - val_loss: 1.3282 - val_acc: 0.7407\n",
      "Epoch 2548/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.1040 - acc: 0.9571 - val_loss: 1.5579 - val_acc: 0.6296\n",
      "Epoch 2549/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1090 - acc: 0.9387 - val_loss: 1.3324 - val_acc: 0.7407\n",
      "Epoch 2550/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.1009 - acc: 0.9571 - val_loss: 1.5263 - val_acc: 0.6296\n",
      "Epoch 2551/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1009 - acc: 0.9387 - val_loss: 1.3407 - val_acc: 0.7407\n",
      "Epoch 2552/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0952 - acc: 0.9509 - val_loss: 1.4905 - val_acc: 0.6667\n",
      "Epoch 2553/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.0928 - acc: 0.9571 - val_loss: 1.3660 - val_acc: 0.7407\n",
      "Epoch 2554/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.0891 - acc: 0.9571 - val_loss: 1.4671 - val_acc: 0.6667\n",
      "Epoch 2555/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.0892 - acc: 0.9632 - val_loss: 1.3808 - val_acc: 0.7407\n",
      "Epoch 2556/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.0871 - acc: 0.9571 - val_loss: 1.4545 - val_acc: 0.6667\n",
      "Epoch 2557/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.0869 - acc: 0.9632 - val_loss: 1.3763 - val_acc: 0.7407\n",
      "Epoch 2558/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.0866 - acc: 0.9571 - val_loss: 1.4501 - val_acc: 0.6667\n",
      "Epoch 2559/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.0869 - acc: 0.9571 - val_loss: 1.3627 - val_acc: 0.7037\n",
      "Epoch 2560/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.0872 - acc: 0.9571 - val_loss: 1.4596 - val_acc: 0.6667\n",
      "Epoch 2561/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.0876 - acc: 0.9632 - val_loss: 1.3592 - val_acc: 0.7407\n",
      "Epoch 2562/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0878 - acc: 0.9571 - val_loss: 1.4890 - val_acc: 0.6667\n",
      "Epoch 2563/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.0913 - acc: 0.9571 - val_loss: 1.3445 - val_acc: 0.7407\n",
      "Epoch 2564/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.1000 - acc: 0.9509 - val_loss: 1.5849 - val_acc: 0.6296\n",
      "Epoch 2565/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.1156 - acc: 0.9387 - val_loss: 1.3449 - val_acc: 0.7778\n",
      "Epoch 2566/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.1230 - acc: 0.9509 - val_loss: 1.5811 - val_acc: 0.6667\n",
      "Epoch 2567/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1223 - acc: 0.9325 - val_loss: 1.3325 - val_acc: 0.7407\n",
      "Epoch 2568/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.0930 - acc: 0.9509 - val_loss: 1.4374 - val_acc: 0.6667\n",
      "Epoch 2569/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.0876 - acc: 0.9632 - val_loss: 1.3845 - val_acc: 0.7037\n",
      "Epoch 2570/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.0857 - acc: 0.9571 - val_loss: 1.4140 - val_acc: 0.6667\n",
      "Epoch 2571/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.0852 - acc: 0.9509 - val_loss: 1.3968 - val_acc: 0.7037\n",
      "Epoch 2572/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.0852 - acc: 0.9509 - val_loss: 1.4043 - val_acc: 0.6667\n",
      "Epoch 2573/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.0854 - acc: 0.9509 - val_loss: 1.3982 - val_acc: 0.7037\n",
      "Epoch 2574/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.0851 - acc: 0.9509 - val_loss: 1.4175 - val_acc: 0.6667\n",
      "Epoch 2575/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.0850 - acc: 0.9509 - val_loss: 1.3948 - val_acc: 0.7037\n",
      "Epoch 2576/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0851 - acc: 0.9509 - val_loss: 1.4188 - val_acc: 0.6667\n",
      "Epoch 2577/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.0858 - acc: 0.9509 - val_loss: 1.3807 - val_acc: 0.7037\n",
      "Epoch 2578/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.0874 - acc: 0.9509 - val_loss: 1.4681 - val_acc: 0.6667\n",
      "Epoch 2579/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0894 - acc: 0.9571 - val_loss: 1.3409 - val_acc: 0.7407\n",
      "Epoch 2580/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.0953 - acc: 0.9571 - val_loss: 1.5562 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2581/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.1092 - acc: 0.9325 - val_loss: 1.3160 - val_acc: 0.7037\n",
      "Epoch 2582/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1049 - acc: 0.9571 - val_loss: 1.5502 - val_acc: 0.6296\n",
      "Epoch 2583/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.1032 - acc: 0.9387 - val_loss: 1.3570 - val_acc: 0.7407\n",
      "Epoch 2584/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.0969 - acc: 0.9509 - val_loss: 1.4860 - val_acc: 0.6667\n",
      "Epoch 2585/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0956 - acc: 0.9509 - val_loss: 1.3628 - val_acc: 0.7407\n",
      "Epoch 2586/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.0896 - acc: 0.9571 - val_loss: 1.4555 - val_acc: 0.6667\n",
      "Epoch 2587/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.0887 - acc: 0.9571 - val_loss: 1.3712 - val_acc: 0.7407\n",
      "Epoch 2588/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.0868 - acc: 0.9571 - val_loss: 1.4298 - val_acc: 0.6667\n",
      "Epoch 2589/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.0858 - acc: 0.9632 - val_loss: 1.3870 - val_acc: 0.7037\n",
      "Epoch 2590/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.0860 - acc: 0.9571 - val_loss: 1.4156 - val_acc: 0.6667\n",
      "Epoch 2591/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.0871 - acc: 0.9571 - val_loss: 1.3851 - val_acc: 0.7407\n",
      "Epoch 2592/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.0871 - acc: 0.9509 - val_loss: 1.4342 - val_acc: 0.6667\n",
      "Epoch 2593/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.0890 - acc: 0.9632 - val_loss: 1.3718 - val_acc: 0.7407\n",
      "Epoch 2594/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.0897 - acc: 0.9571 - val_loss: 1.4811 - val_acc: 0.6667\n",
      "Epoch 2595/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.0939 - acc: 0.9448 - val_loss: 1.3430 - val_acc: 0.7407\n",
      "Epoch 2596/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.0977 - acc: 0.9509 - val_loss: 1.5238 - val_acc: 0.6296\n",
      "Epoch 2597/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1032 - acc: 0.9387 - val_loss: 1.3584 - val_acc: 0.7407\n",
      "Epoch 2598/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1036 - acc: 0.9509 - val_loss: 1.5191 - val_acc: 0.6296\n",
      "Epoch 2599/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.1023 - acc: 0.9448 - val_loss: 1.3440 - val_acc: 0.7407\n",
      "Epoch 2600/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.0950 - acc: 0.9448 - val_loss: 1.4685 - val_acc: 0.6667\n",
      "Epoch 2601/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.0918 - acc: 0.9448 - val_loss: 1.3527 - val_acc: 0.7407\n",
      "Epoch 2602/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.0863 - acc: 0.9571 - val_loss: 1.4152 - val_acc: 0.6667\n",
      "Epoch 2603/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.0854 - acc: 0.9571 - val_loss: 1.3771 - val_acc: 0.7037\n",
      "Epoch 2604/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.0846 - acc: 0.9571 - val_loss: 1.4102 - val_acc: 0.6667\n",
      "Epoch 2605/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.0844 - acc: 0.9509 - val_loss: 1.3783 - val_acc: 0.7037\n",
      "Epoch 2606/3000\n",
      "163/163 [==============================] - 0s 26us/step - loss: 0.0847 - acc: 0.9571 - val_loss: 1.4056 - val_acc: 0.6667\n",
      "Epoch 2607/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.0862 - acc: 0.9509 - val_loss: 1.3654 - val_acc: 0.7037\n",
      "Epoch 2608/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.0890 - acc: 0.9571 - val_loss: 1.3947 - val_acc: 0.6667\n",
      "Epoch 2609/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.0962 - acc: 0.9509 - val_loss: 1.3652 - val_acc: 0.7037\n",
      "Epoch 2610/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.0966 - acc: 0.9509 - val_loss: 1.3760 - val_acc: 0.7037\n",
      "Epoch 2611/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.0862 - acc: 0.9509 - val_loss: 1.3756 - val_acc: 0.7037\n",
      "Epoch 2612/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.0844 - acc: 0.9509 - val_loss: 1.3822 - val_acc: 0.7037\n",
      "Epoch 2613/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.0840 - acc: 0.9509 - val_loss: 1.3725 - val_acc: 0.7037\n",
      "Epoch 2614/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.0838 - acc: 0.9509 - val_loss: 1.3986 - val_acc: 0.6667\n",
      "Epoch 2615/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0845 - acc: 0.9509 - val_loss: 1.3295 - val_acc: 0.7407\n",
      "Epoch 2616/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0862 - acc: 0.9571 - val_loss: 1.5102 - val_acc: 0.6667\n",
      "Epoch 2617/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.0992 - acc: 0.9387 - val_loss: 1.3543 - val_acc: 0.7407\n",
      "Epoch 2618/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1252 - acc: 0.9509 - val_loss: 1.6646 - val_acc: 0.6667\n",
      "Epoch 2619/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.1405 - acc: 0.9387 - val_loss: 1.3213 - val_acc: 0.7407\n",
      "Epoch 2620/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.0963 - acc: 0.9509 - val_loss: 1.4784 - val_acc: 0.6667\n",
      "Epoch 2621/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.0912 - acc: 0.9632 - val_loss: 1.3787 - val_acc: 0.7407\n",
      "Epoch 2622/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0870 - acc: 0.9571 - val_loss: 1.4540 - val_acc: 0.6667\n",
      "Epoch 2623/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.0856 - acc: 0.9509 - val_loss: 1.3999 - val_acc: 0.7037\n",
      "Epoch 2624/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.0844 - acc: 0.9571 - val_loss: 1.4399 - val_acc: 0.6667\n",
      "Epoch 2625/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.0841 - acc: 0.9509 - val_loss: 1.4112 - val_acc: 0.7037\n",
      "Epoch 2626/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.0841 - acc: 0.9571 - val_loss: 1.4447 - val_acc: 0.6667\n",
      "Epoch 2627/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.0843 - acc: 0.9509 - val_loss: 1.4066 - val_acc: 0.7037\n",
      "Epoch 2628/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.0843 - acc: 0.9571 - val_loss: 1.4725 - val_acc: 0.6667\n",
      "Epoch 2629/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.0854 - acc: 0.9571 - val_loss: 1.3912 - val_acc: 0.7037\n",
      "Epoch 2630/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.0861 - acc: 0.9571 - val_loss: 1.4981 - val_acc: 0.6667\n",
      "Epoch 2631/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.0876 - acc: 0.9632 - val_loss: 1.3606 - val_acc: 0.7407\n",
      "Epoch 2632/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.0912 - acc: 0.9571 - val_loss: 1.5557 - val_acc: 0.6667\n",
      "Epoch 2633/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.0985 - acc: 0.9325 - val_loss: 1.3504 - val_acc: 0.7407\n",
      "Epoch 2634/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.1054 - acc: 0.9571 - val_loss: 1.5915 - val_acc: 0.6296\n",
      "Epoch 2635/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.1119 - acc: 0.9387 - val_loss: 1.3757 - val_acc: 0.7778\n",
      "Epoch 2636/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.1104 - acc: 0.9509 - val_loss: 1.5694 - val_acc: 0.6296\n",
      "Epoch 2637/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.1102 - acc: 0.9387 - val_loss: 1.3792 - val_acc: 0.7407\n",
      "Epoch 2638/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.0898 - acc: 0.9509 - val_loss: 1.4756 - val_acc: 0.6667\n",
      "Epoch 2639/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.0854 - acc: 0.9632 - val_loss: 1.4268 - val_acc: 0.7037\n",
      "Epoch 2640/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.0838 - acc: 0.9571 - val_loss: 1.4533 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2641/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0834 - acc: 0.9509 - val_loss: 1.4407 - val_acc: 0.7037\n",
      "Epoch 2642/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.0834 - acc: 0.9509 - val_loss: 1.4554 - val_acc: 0.6667\n",
      "Epoch 2643/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.0834 - acc: 0.9509 - val_loss: 1.4392 - val_acc: 0.7037\n",
      "Epoch 2644/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0832 - acc: 0.9509 - val_loss: 1.4608 - val_acc: 0.6667\n",
      "Epoch 2645/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0831 - acc: 0.9509 - val_loss: 1.4397 - val_acc: 0.7037\n",
      "Epoch 2646/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.0835 - acc: 0.9509 - val_loss: 1.4703 - val_acc: 0.6667\n",
      "Epoch 2647/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.0848 - acc: 0.9509 - val_loss: 1.4070 - val_acc: 0.7037\n",
      "Epoch 2648/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.0865 - acc: 0.9571 - val_loss: 1.5287 - val_acc: 0.6667\n",
      "Epoch 2649/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.0917 - acc: 0.9571 - val_loss: 1.3469 - val_acc: 0.7407\n",
      "Epoch 2650/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.0959 - acc: 0.9571 - val_loss: 1.5989 - val_acc: 0.6667\n",
      "Epoch 2651/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.1032 - acc: 0.9325 - val_loss: 1.3547 - val_acc: 0.7407\n",
      "Epoch 2652/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.1025 - acc: 0.9571 - val_loss: 1.5885 - val_acc: 0.6296\n",
      "Epoch 2653/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1037 - acc: 0.9448 - val_loss: 1.3956 - val_acc: 0.7407\n",
      "Epoch 2654/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.0974 - acc: 0.9448 - val_loss: 1.5418 - val_acc: 0.6667\n",
      "Epoch 2655/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.0949 - acc: 0.9448 - val_loss: 1.4195 - val_acc: 0.7407\n",
      "Epoch 2656/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.0897 - acc: 0.9571 - val_loss: 1.4977 - val_acc: 0.6667\n",
      "Epoch 2657/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.0899 - acc: 0.9571 - val_loss: 1.4067 - val_acc: 0.7407\n",
      "Epoch 2658/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.0862 - acc: 0.9571 - val_loss: 1.4879 - val_acc: 0.6667\n",
      "Epoch 2659/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.0849 - acc: 0.9632 - val_loss: 1.4392 - val_acc: 0.7037\n",
      "Epoch 2660/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0840 - acc: 0.9571 - val_loss: 1.4719 - val_acc: 0.6667\n",
      "Epoch 2661/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.0835 - acc: 0.9509 - val_loss: 1.4389 - val_acc: 0.7037\n",
      "Epoch 2662/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.0834 - acc: 0.9571 - val_loss: 1.4692 - val_acc: 0.6667\n",
      "Epoch 2663/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0832 - acc: 0.9509 - val_loss: 1.4425 - val_acc: 0.7037\n",
      "Epoch 2664/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0835 - acc: 0.9571 - val_loss: 1.4738 - val_acc: 0.6667\n",
      "Epoch 2665/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.0854 - acc: 0.9632 - val_loss: 1.4309 - val_acc: 0.7407\n",
      "Epoch 2666/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0872 - acc: 0.9571 - val_loss: 1.5189 - val_acc: 0.6667\n",
      "Epoch 2667/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.0928 - acc: 0.9509 - val_loss: 1.4084 - val_acc: 0.7407\n",
      "Epoch 2668/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1003 - acc: 0.9509 - val_loss: 1.5762 - val_acc: 0.6296\n",
      "Epoch 2669/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.1077 - acc: 0.9448 - val_loss: 1.4323 - val_acc: 0.7778\n",
      "Epoch 2670/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1070 - acc: 0.9509 - val_loss: 1.5649 - val_acc: 0.6667\n",
      "Epoch 2671/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.0986 - acc: 0.9448 - val_loss: 1.4338 - val_acc: 0.7407\n",
      "Epoch 2672/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.0907 - acc: 0.9571 - val_loss: 1.4940 - val_acc: 0.6667\n",
      "Epoch 2673/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.0875 - acc: 0.9571 - val_loss: 1.4287 - val_acc: 0.7037\n",
      "Epoch 2674/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.0841 - acc: 0.9571 - val_loss: 1.4691 - val_acc: 0.6667\n",
      "Epoch 2675/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.0834 - acc: 0.9509 - val_loss: 1.4515 - val_acc: 0.7037\n",
      "Epoch 2676/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.0834 - acc: 0.9571 - val_loss: 1.4495 - val_acc: 0.6667\n",
      "Epoch 2677/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.0843 - acc: 0.9509 - val_loss: 1.4829 - val_acc: 0.7037\n",
      "Epoch 2678/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.0876 - acc: 0.9448 - val_loss: 1.4116 - val_acc: 0.7037\n",
      "Epoch 2679/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.0907 - acc: 0.9571 - val_loss: 1.5107 - val_acc: 0.6667\n",
      "Epoch 2680/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.0909 - acc: 0.9571 - val_loss: 1.3873 - val_acc: 0.7407\n",
      "Epoch 2681/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.0880 - acc: 0.9571 - val_loss: 1.5560 - val_acc: 0.6667\n",
      "Epoch 2682/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.0924 - acc: 0.9509 - val_loss: 1.3816 - val_acc: 0.7407\n",
      "Epoch 2683/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.0977 - acc: 0.9509 - val_loss: 1.5864 - val_acc: 0.6296\n",
      "Epoch 2684/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1009 - acc: 0.9448 - val_loss: 1.3978 - val_acc: 0.7778\n",
      "Epoch 2685/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1002 - acc: 0.9509 - val_loss: 1.5798 - val_acc: 0.6667\n",
      "Epoch 2686/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.1101 - acc: 0.9387 - val_loss: 1.3748 - val_acc: 0.7407\n",
      "Epoch 2687/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.0925 - acc: 0.9509 - val_loss: 1.5097 - val_acc: 0.6667\n",
      "Epoch 2688/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.0859 - acc: 0.9632 - val_loss: 1.4286 - val_acc: 0.7037\n",
      "Epoch 2689/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.0835 - acc: 0.9571 - val_loss: 1.4823 - val_acc: 0.6667\n",
      "Epoch 2690/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.0830 - acc: 0.9509 - val_loss: 1.4466 - val_acc: 0.7037\n",
      "Epoch 2691/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.0825 - acc: 0.9571 - val_loss: 1.4775 - val_acc: 0.6667\n",
      "Epoch 2692/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.0823 - acc: 0.9509 - val_loss: 1.4499 - val_acc: 0.7037\n",
      "Epoch 2693/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0824 - acc: 0.9571 - val_loss: 1.4817 - val_acc: 0.6667\n",
      "Epoch 2694/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0828 - acc: 0.9509 - val_loss: 1.4357 - val_acc: 0.7037\n",
      "Epoch 2695/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.0846 - acc: 0.9571 - val_loss: 1.5282 - val_acc: 0.6667\n",
      "Epoch 2696/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0870 - acc: 0.9632 - val_loss: 1.3850 - val_acc: 0.7407\n",
      "Epoch 2697/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0927 - acc: 0.9571 - val_loss: 1.5833 - val_acc: 0.6667\n",
      "Epoch 2698/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.0997 - acc: 0.9448 - val_loss: 1.3575 - val_acc: 0.7407\n",
      "Epoch 2699/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1005 - acc: 0.9571 - val_loss: 1.6025 - val_acc: 0.6667\n",
      "Epoch 2700/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.1064 - acc: 0.9387 - val_loss: 1.4048 - val_acc: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2701/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.1053 - acc: 0.9509 - val_loss: 1.5635 - val_acc: 0.6296\n",
      "Epoch 2702/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.1068 - acc: 0.9387 - val_loss: 1.3947 - val_acc: 0.7407\n",
      "Epoch 2703/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.0887 - acc: 0.9509 - val_loss: 1.4904 - val_acc: 0.6667\n",
      "Epoch 2704/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.0842 - acc: 0.9632 - val_loss: 1.4457 - val_acc: 0.7037\n",
      "Epoch 2705/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.0828 - acc: 0.9571 - val_loss: 1.4678 - val_acc: 0.6667\n",
      "Epoch 2706/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.0823 - acc: 0.9509 - val_loss: 1.4576 - val_acc: 0.7037\n",
      "Epoch 2707/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.0821 - acc: 0.9509 - val_loss: 1.4639 - val_acc: 0.6667\n",
      "Epoch 2708/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.0820 - acc: 0.9509 - val_loss: 1.4625 - val_acc: 0.7037\n",
      "Epoch 2709/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.0818 - acc: 0.9509 - val_loss: 1.4650 - val_acc: 0.6667\n",
      "Epoch 2710/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.0822 - acc: 0.9509 - val_loss: 1.4627 - val_acc: 0.7037\n",
      "Epoch 2711/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.0821 - acc: 0.9509 - val_loss: 1.4662 - val_acc: 0.6667\n",
      "Epoch 2712/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.0828 - acc: 0.9509 - val_loss: 1.4581 - val_acc: 0.7037\n",
      "Epoch 2713/3000\n",
      "163/163 [==============================] - 0s 30us/step - loss: 0.0843 - acc: 0.9571 - val_loss: 1.4780 - val_acc: 0.6667\n",
      "Epoch 2714/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.0888 - acc: 0.9632 - val_loss: 1.4322 - val_acc: 0.7407\n",
      "Epoch 2715/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.0931 - acc: 0.9571 - val_loss: 1.5480 - val_acc: 0.6667\n",
      "Epoch 2716/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.0985 - acc: 0.9387 - val_loss: 1.4061 - val_acc: 0.7778\n",
      "Epoch 2717/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1004 - acc: 0.9571 - val_loss: 1.5828 - val_acc: 0.6667\n",
      "Epoch 2718/3000\n",
      "163/163 [==============================] - 0s 28us/step - loss: 0.0991 - acc: 0.9448 - val_loss: 1.4215 - val_acc: 0.7407\n",
      "Epoch 2719/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.0957 - acc: 0.9448 - val_loss: 1.5578 - val_acc: 0.6667\n",
      "Epoch 2720/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.0940 - acc: 0.9448 - val_loss: 1.4042 - val_acc: 0.7407\n",
      "Epoch 2721/3000\n",
      "163/163 [==============================] - 0s 32us/step - loss: 0.0898 - acc: 0.9571 - val_loss: 1.5291 - val_acc: 0.6667\n",
      "Epoch 2722/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.0896 - acc: 0.9571 - val_loss: 1.4013 - val_acc: 0.7407\n",
      "Epoch 2723/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0886 - acc: 0.9571 - val_loss: 1.5241 - val_acc: 0.6667\n",
      "Epoch 2724/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.0886 - acc: 0.9571 - val_loss: 1.4091 - val_acc: 0.7037\n",
      "Epoch 2725/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.0863 - acc: 0.9571 - val_loss: 1.5256 - val_acc: 0.6667\n",
      "Epoch 2726/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.0860 - acc: 0.9632 - val_loss: 1.4160 - val_acc: 0.7407\n",
      "Epoch 2727/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.0852 - acc: 0.9571 - val_loss: 1.5121 - val_acc: 0.6667\n",
      "Epoch 2728/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.0849 - acc: 0.9632 - val_loss: 1.4248 - val_acc: 0.7037\n",
      "Epoch 2729/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.0846 - acc: 0.9571 - val_loss: 1.5202 - val_acc: 0.6667\n",
      "Epoch 2730/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.0863 - acc: 0.9571 - val_loss: 1.4152 - val_acc: 0.7407\n",
      "Epoch 2731/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.0888 - acc: 0.9509 - val_loss: 1.5528 - val_acc: 0.6667\n",
      "Epoch 2732/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.0894 - acc: 0.9509 - val_loss: 1.4112 - val_acc: 0.7407\n",
      "Epoch 2733/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.0909 - acc: 0.9509 - val_loss: 1.5609 - val_acc: 0.6296\n",
      "Epoch 2734/3000\n",
      "163/163 [==============================] - 0s 29us/step - loss: 0.1009 - acc: 0.9387 - val_loss: 1.4084 - val_acc: 0.7778\n",
      "Epoch 2735/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.1138 - acc: 0.9509 - val_loss: 1.6145 - val_acc: 0.6296\n",
      "Epoch 2736/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1144 - acc: 0.9325 - val_loss: 1.3682 - val_acc: 0.7407\n",
      "Epoch 2737/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.0935 - acc: 0.9509 - val_loss: 1.5205 - val_acc: 0.6667\n",
      "Epoch 2738/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.0896 - acc: 0.9571 - val_loss: 1.4147 - val_acc: 0.7037\n",
      "Epoch 2739/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.0844 - acc: 0.9571 - val_loss: 1.4848 - val_acc: 0.6667\n",
      "Epoch 2740/3000\n",
      "163/163 [==============================] - 0s 33us/step - loss: 0.0824 - acc: 0.9509 - val_loss: 1.4432 - val_acc: 0.7037\n",
      "Epoch 2741/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.0818 - acc: 0.9571 - val_loss: 1.4709 - val_acc: 0.7037\n",
      "Epoch 2742/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.0817 - acc: 0.9509 - val_loss: 1.4574 - val_acc: 0.7037\n",
      "Epoch 2743/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.0817 - acc: 0.9509 - val_loss: 1.4653 - val_acc: 0.7037\n",
      "Epoch 2744/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.0816 - acc: 0.9509 - val_loss: 1.4658 - val_acc: 0.7037\n",
      "Epoch 2745/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.0813 - acc: 0.9509 - val_loss: 1.4663 - val_acc: 0.7037\n",
      "Epoch 2746/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.0814 - acc: 0.9509 - val_loss: 1.4580 - val_acc: 0.7037\n",
      "Epoch 2747/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.0820 - acc: 0.9509 - val_loss: 1.4682 - val_acc: 0.7037\n",
      "Epoch 2748/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.0818 - acc: 0.9509 - val_loss: 1.4769 - val_acc: 0.6667\n",
      "Epoch 2749/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.0822 - acc: 0.9509 - val_loss: 1.4524 - val_acc: 0.7037\n",
      "Epoch 2750/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.0841 - acc: 0.9509 - val_loss: 1.5082 - val_acc: 0.6667\n",
      "Epoch 2751/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.0912 - acc: 0.9509 - val_loss: 1.3905 - val_acc: 0.7778\n",
      "Epoch 2752/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.1026 - acc: 0.9571 - val_loss: 1.6041 - val_acc: 0.6667\n",
      "Epoch 2753/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.1043 - acc: 0.9509 - val_loss: 1.4073 - val_acc: 0.7778\n",
      "Epoch 2754/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.0984 - acc: 0.9571 - val_loss: 1.5592 - val_acc: 0.6667\n",
      "Epoch 2755/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.0988 - acc: 0.9448 - val_loss: 1.4166 - val_acc: 0.7778\n",
      "Epoch 2756/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.0924 - acc: 0.9509 - val_loss: 1.5397 - val_acc: 0.6667\n",
      "Epoch 2757/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0883 - acc: 0.9448 - val_loss: 1.4231 - val_acc: 0.7407\n",
      "Epoch 2758/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.0838 - acc: 0.9571 - val_loss: 1.4951 - val_acc: 0.6667\n",
      "Epoch 2759/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.0857 - acc: 0.9632 - val_loss: 1.4069 - val_acc: 0.7037\n",
      "Epoch 2760/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0899 - acc: 0.9571 - val_loss: 1.5107 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2761/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.0930 - acc: 0.9571 - val_loss: 1.3884 - val_acc: 0.7037\n",
      "Epoch 2762/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.0868 - acc: 0.9571 - val_loss: 1.5221 - val_acc: 0.6667\n",
      "Epoch 2763/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.0864 - acc: 0.9571 - val_loss: 1.4070 - val_acc: 0.7407\n",
      "Epoch 2764/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.0872 - acc: 0.9509 - val_loss: 1.5270 - val_acc: 0.6667\n",
      "Epoch 2765/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.0859 - acc: 0.9509 - val_loss: 1.4164 - val_acc: 0.7407\n",
      "Epoch 2766/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.0848 - acc: 0.9571 - val_loss: 1.5150 - val_acc: 0.6667\n",
      "Epoch 2767/3000\n",
      "163/163 [==============================] - 0s 31us/step - loss: 0.0851 - acc: 0.9571 - val_loss: 1.4079 - val_acc: 0.7037\n",
      "Epoch 2768/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.0853 - acc: 0.9571 - val_loss: 1.5283 - val_acc: 0.6667\n",
      "Epoch 2769/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0889 - acc: 0.9509 - val_loss: 1.3992 - val_acc: 0.7407\n",
      "Epoch 2770/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.0889 - acc: 0.9509 - val_loss: 1.5402 - val_acc: 0.6667\n",
      "Epoch 2771/3000\n",
      "163/163 [==============================] - 0s 53us/step - loss: 0.0921 - acc: 0.9448 - val_loss: 1.3974 - val_acc: 0.7778\n",
      "Epoch 2772/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.0929 - acc: 0.9509 - val_loss: 1.5498 - val_acc: 0.6667\n",
      "Epoch 2773/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.0928 - acc: 0.9448 - val_loss: 1.4137 - val_acc: 0.7407\n",
      "Epoch 2774/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.0904 - acc: 0.9509 - val_loss: 1.5261 - val_acc: 0.6667\n",
      "Epoch 2775/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0889 - acc: 0.9509 - val_loss: 1.4166 - val_acc: 0.7037\n",
      "Epoch 2776/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.0864 - acc: 0.9571 - val_loss: 1.5172 - val_acc: 0.6667\n",
      "Epoch 2777/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.0885 - acc: 0.9571 - val_loss: 1.4019 - val_acc: 0.7037\n",
      "Epoch 2778/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.0901 - acc: 0.9509 - val_loss: 1.5140 - val_acc: 0.6667\n",
      "Epoch 2779/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0900 - acc: 0.9571 - val_loss: 1.3961 - val_acc: 0.7037\n",
      "Epoch 2780/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.0863 - acc: 0.9571 - val_loss: 1.5272 - val_acc: 0.6667\n",
      "Epoch 2781/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.0866 - acc: 0.9571 - val_loss: 1.4100 - val_acc: 0.7407\n",
      "Epoch 2782/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.0858 - acc: 0.9571 - val_loss: 1.5131 - val_acc: 0.6667\n",
      "Epoch 2783/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.0882 - acc: 0.9448 - val_loss: 1.3962 - val_acc: 0.7778\n",
      "Epoch 2784/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.0898 - acc: 0.9571 - val_loss: 1.5433 - val_acc: 0.6667\n",
      "Epoch 2785/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.0932 - acc: 0.9448 - val_loss: 1.4028 - val_acc: 0.7778\n",
      "Epoch 2786/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.0932 - acc: 0.9509 - val_loss: 1.5419 - val_acc: 0.6667\n",
      "Epoch 2787/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0915 - acc: 0.9448 - val_loss: 1.4058 - val_acc: 0.7778\n",
      "Epoch 2788/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0885 - acc: 0.9571 - val_loss: 1.5058 - val_acc: 0.6667\n",
      "Epoch 2789/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.0850 - acc: 0.9571 - val_loss: 1.4155 - val_acc: 0.7037\n",
      "Epoch 2790/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.0828 - acc: 0.9509 - val_loss: 1.4777 - val_acc: 0.6667\n",
      "Epoch 2791/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.0826 - acc: 0.9632 - val_loss: 1.4153 - val_acc: 0.7037\n",
      "Epoch 2792/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0819 - acc: 0.9571 - val_loss: 1.4744 - val_acc: 0.6667\n",
      "Epoch 2793/3000\n",
      "163/163 [==============================] - 0s 53us/step - loss: 0.0818 - acc: 0.9571 - val_loss: 1.4627 - val_acc: 0.7037\n",
      "Epoch 2794/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.0820 - acc: 0.9509 - val_loss: 1.5254 - val_acc: 0.6667\n",
      "Epoch 2795/3000\n",
      "163/163 [==============================] - 0s 53us/step - loss: 0.0829 - acc: 0.9632 - val_loss: 1.4236 - val_acc: 0.7407\n",
      "Epoch 2796/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.0874 - acc: 0.9571 - val_loss: 1.5991 - val_acc: 0.6667\n",
      "Epoch 2797/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.1019 - acc: 0.9448 - val_loss: 1.3810 - val_acc: 0.7778\n",
      "Epoch 2798/3000\n",
      "163/163 [==============================] - 0s 58us/step - loss: 0.1064 - acc: 0.9509 - val_loss: 1.6172 - val_acc: 0.6667\n",
      "Epoch 2799/3000\n",
      "163/163 [==============================] - 0s 53us/step - loss: 0.1037 - acc: 0.9387 - val_loss: 1.4284 - val_acc: 0.7778\n",
      "Epoch 2800/3000\n",
      "163/163 [==============================] - 0s 53us/step - loss: 0.0952 - acc: 0.9448 - val_loss: 1.5700 - val_acc: 0.6296\n",
      "Epoch 2801/3000\n",
      "163/163 [==============================] - 0s 53us/step - loss: 0.1078 - acc: 0.9387 - val_loss: 1.4174 - val_acc: 0.7778\n",
      "Epoch 2802/3000\n",
      "163/163 [==============================] - 0s 54us/step - loss: 0.0907 - acc: 0.9509 - val_loss: 1.5162 - val_acc: 0.6667\n",
      "Epoch 2803/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.0855 - acc: 0.9571 - val_loss: 1.4338 - val_acc: 0.7037\n",
      "Epoch 2804/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.0820 - acc: 0.9509 - val_loss: 1.4828 - val_acc: 0.6667\n",
      "Epoch 2805/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.0809 - acc: 0.9509 - val_loss: 1.4564 - val_acc: 0.7037\n",
      "Epoch 2806/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0806 - acc: 0.9571 - val_loss: 1.4764 - val_acc: 0.6667\n",
      "Epoch 2807/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.0803 - acc: 0.9509 - val_loss: 1.4680 - val_acc: 0.7037\n",
      "Epoch 2808/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0803 - acc: 0.9509 - val_loss: 1.4700 - val_acc: 0.6667\n",
      "Epoch 2809/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.0811 - acc: 0.9509 - val_loss: 1.4613 - val_acc: 0.7037\n",
      "Epoch 2810/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.0810 - acc: 0.9571 - val_loss: 1.4891 - val_acc: 0.6667\n",
      "Epoch 2811/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.0809 - acc: 0.9571 - val_loss: 1.4534 - val_acc: 0.7037\n",
      "Epoch 2812/3000\n",
      "163/163 [==============================] - 0s 55us/step - loss: 0.0821 - acc: 0.9509 - val_loss: 1.5125 - val_acc: 0.6667\n",
      "Epoch 2813/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.0854 - acc: 0.9571 - val_loss: 1.4212 - val_acc: 0.7407\n",
      "Epoch 2814/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.0914 - acc: 0.9509 - val_loss: 1.5809 - val_acc: 0.6667\n",
      "Epoch 2815/3000\n",
      "163/163 [==============================] - 0s 57us/step - loss: 0.0953 - acc: 0.9448 - val_loss: 1.4085 - val_acc: 0.7778\n",
      "Epoch 2816/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.0958 - acc: 0.9571 - val_loss: 1.5826 - val_acc: 0.6667\n",
      "Epoch 2817/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1006 - acc: 0.9448 - val_loss: 1.4030 - val_acc: 0.7778\n",
      "Epoch 2818/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.0974 - acc: 0.9509 - val_loss: 1.5563 - val_acc: 0.6667\n",
      "Epoch 2819/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.0927 - acc: 0.9448 - val_loss: 1.4292 - val_acc: 0.7407\n",
      "Epoch 2820/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0857 - acc: 0.9571 - val_loss: 1.5123 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2821/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.0841 - acc: 0.9632 - val_loss: 1.4249 - val_acc: 0.7037\n",
      "Epoch 2822/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.0840 - acc: 0.9509 - val_loss: 1.5018 - val_acc: 0.6667\n",
      "Epoch 2823/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.0901 - acc: 0.9571 - val_loss: 1.3987 - val_acc: 0.7037\n",
      "Epoch 2824/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0915 - acc: 0.9448 - val_loss: 1.5140 - val_acc: 0.6667\n",
      "Epoch 2825/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.0892 - acc: 0.9571 - val_loss: 1.4012 - val_acc: 0.7037\n",
      "Epoch 2826/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.0862 - acc: 0.9509 - val_loss: 1.5338 - val_acc: 0.6667\n",
      "Epoch 2827/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.0854 - acc: 0.9509 - val_loss: 1.4148 - val_acc: 0.7407\n",
      "Epoch 2828/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0845 - acc: 0.9571 - val_loss: 1.5198 - val_acc: 0.6667\n",
      "Epoch 2829/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.0845 - acc: 0.9571 - val_loss: 1.4145 - val_acc: 0.7407\n",
      "Epoch 2830/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.0835 - acc: 0.9571 - val_loss: 1.5130 - val_acc: 0.6667\n",
      "Epoch 2831/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0839 - acc: 0.9571 - val_loss: 1.4060 - val_acc: 0.7037\n",
      "Epoch 2832/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.0844 - acc: 0.9571 - val_loss: 1.5300 - val_acc: 0.6667\n",
      "Epoch 2833/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0890 - acc: 0.9509 - val_loss: 1.4292 - val_acc: 0.7778\n",
      "Epoch 2834/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.0913 - acc: 0.9509 - val_loss: 1.5836 - val_acc: 0.6667\n",
      "Epoch 2835/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.0924 - acc: 0.9448 - val_loss: 1.4387 - val_acc: 0.7778\n",
      "Epoch 2836/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.0916 - acc: 0.9509 - val_loss: 1.5823 - val_acc: 0.6667\n",
      "Epoch 2837/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.0891 - acc: 0.9448 - val_loss: 1.4530 - val_acc: 0.7407\n",
      "Epoch 2838/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0848 - acc: 0.9571 - val_loss: 1.5429 - val_acc: 0.6667\n",
      "Epoch 2839/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.0867 - acc: 0.9571 - val_loss: 1.4296 - val_acc: 0.7778\n",
      "Epoch 2840/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.0861 - acc: 0.9571 - val_loss: 1.5691 - val_acc: 0.6667\n",
      "Epoch 2841/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.0873 - acc: 0.9509 - val_loss: 1.4350 - val_acc: 0.7037\n",
      "Epoch 2842/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.0873 - acc: 0.9571 - val_loss: 1.5651 - val_acc: 0.6667\n",
      "Epoch 2843/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.0877 - acc: 0.9571 - val_loss: 1.4243 - val_acc: 0.7037\n",
      "Epoch 2844/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.0864 - acc: 0.9571 - val_loss: 1.5749 - val_acc: 0.6667\n",
      "Epoch 2845/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.0872 - acc: 0.9509 - val_loss: 1.4430 - val_acc: 0.7778\n",
      "Epoch 2846/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0878 - acc: 0.9509 - val_loss: 1.5613 - val_acc: 0.6667\n",
      "Epoch 2847/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.0865 - acc: 0.9509 - val_loss: 1.4610 - val_acc: 0.7778\n",
      "Epoch 2848/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0857 - acc: 0.9571 - val_loss: 1.5481 - val_acc: 0.6667\n",
      "Epoch 2849/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0903 - acc: 0.9448 - val_loss: 1.4444 - val_acc: 0.7778\n",
      "Epoch 2850/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.0930 - acc: 0.9509 - val_loss: 1.5893 - val_acc: 0.6667\n",
      "Epoch 2851/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0947 - acc: 0.9448 - val_loss: 1.4746 - val_acc: 0.7778\n",
      "Epoch 2852/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.0956 - acc: 0.9509 - val_loss: 1.5844 - val_acc: 0.6667\n",
      "Epoch 2853/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.0975 - acc: 0.9448 - val_loss: 1.4272 - val_acc: 0.7778\n",
      "Epoch 2854/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.0877 - acc: 0.9509 - val_loss: 1.5393 - val_acc: 0.6667\n",
      "Epoch 2855/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.0825 - acc: 0.9632 - val_loss: 1.4686 - val_acc: 0.7037\n",
      "Epoch 2856/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.0806 - acc: 0.9571 - val_loss: 1.5180 - val_acc: 0.6667\n",
      "Epoch 2857/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.0801 - acc: 0.9509 - val_loss: 1.4881 - val_acc: 0.7037\n",
      "Epoch 2858/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.0798 - acc: 0.9571 - val_loss: 1.5153 - val_acc: 0.6667\n",
      "Epoch 2859/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.0800 - acc: 0.9509 - val_loss: 1.4760 - val_acc: 0.7037\n",
      "Epoch 2860/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0808 - acc: 0.9571 - val_loss: 1.5493 - val_acc: 0.6667\n",
      "Epoch 2861/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0845 - acc: 0.9509 - val_loss: 1.4301 - val_acc: 0.7037\n",
      "Epoch 2862/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.0923 - acc: 0.9509 - val_loss: 1.5854 - val_acc: 0.6667\n",
      "Epoch 2863/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.0938 - acc: 0.9571 - val_loss: 1.4040 - val_acc: 0.7778\n",
      "Epoch 2864/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.0884 - acc: 0.9571 - val_loss: 1.6136 - val_acc: 0.6667\n",
      "Epoch 2865/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.0937 - acc: 0.9387 - val_loss: 1.4208 - val_acc: 0.7778\n",
      "Epoch 2866/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.0945 - acc: 0.9509 - val_loss: 1.5935 - val_acc: 0.6667\n",
      "Epoch 2867/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0923 - acc: 0.9448 - val_loss: 1.4468 - val_acc: 0.7778\n",
      "Epoch 2868/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0877 - acc: 0.9509 - val_loss: 1.5576 - val_acc: 0.6667\n",
      "Epoch 2869/3000\n",
      "163/163 [==============================] - 0s 53us/step - loss: 0.0852 - acc: 0.9509 - val_loss: 1.4666 - val_acc: 0.7037\n",
      "Epoch 2870/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.0822 - acc: 0.9571 - val_loss: 1.5334 - val_acc: 0.6667\n",
      "Epoch 2871/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.0811 - acc: 0.9632 - val_loss: 1.4751 - val_acc: 0.7037\n",
      "Epoch 2872/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.0805 - acc: 0.9509 - val_loss: 1.5276 - val_acc: 0.6667\n",
      "Epoch 2873/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0811 - acc: 0.9632 - val_loss: 1.4668 - val_acc: 0.7037\n",
      "Epoch 2874/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.0815 - acc: 0.9571 - val_loss: 1.5494 - val_acc: 0.6667\n",
      "Epoch 2875/3000\n",
      "163/163 [==============================] - 0s 53us/step - loss: 0.0823 - acc: 0.9632 - val_loss: 1.4529 - val_acc: 0.7407\n",
      "Epoch 2876/3000\n",
      "163/163 [==============================] - 0s 59us/step - loss: 0.0844 - acc: 0.9571 - val_loss: 1.5801 - val_acc: 0.6667\n",
      "Epoch 2877/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.0928 - acc: 0.9448 - val_loss: 1.4227 - val_acc: 0.7778\n",
      "Epoch 2878/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.0992 - acc: 0.9571 - val_loss: 1.6164 - val_acc: 0.6667\n",
      "Epoch 2879/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.0949 - acc: 0.9448 - val_loss: 1.4629 - val_acc: 0.7778\n",
      "Epoch 2880/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.0907 - acc: 0.9509 - val_loss: 1.5741 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2881/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.0900 - acc: 0.9509 - val_loss: 1.4331 - val_acc: 0.7407\n",
      "Epoch 2882/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.0886 - acc: 0.9571 - val_loss: 1.5703 - val_acc: 0.6667\n",
      "Epoch 2883/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.0904 - acc: 0.9571 - val_loss: 1.4269 - val_acc: 0.7037\n",
      "Epoch 2884/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.0860 - acc: 0.9571 - val_loss: 1.5448 - val_acc: 0.6667\n",
      "Epoch 2885/3000\n",
      "163/163 [==============================] - 0s 65us/step - loss: 0.0825 - acc: 0.9632 - val_loss: 1.4580 - val_acc: 0.7037\n",
      "Epoch 2886/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.0808 - acc: 0.9509 - val_loss: 1.5283 - val_acc: 0.6667\n",
      "Epoch 2887/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.0802 - acc: 0.9571 - val_loss: 1.4728 - val_acc: 0.7037\n",
      "Epoch 2888/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.0801 - acc: 0.9571 - val_loss: 1.5259 - val_acc: 0.6667\n",
      "Epoch 2889/3000\n",
      "163/163 [==============================] - 0s 57us/step - loss: 0.0809 - acc: 0.9632 - val_loss: 1.4626 - val_acc: 0.7037\n",
      "Epoch 2890/3000\n",
      "163/163 [==============================] - 0s 53us/step - loss: 0.0820 - acc: 0.9571 - val_loss: 1.5620 - val_acc: 0.6667\n",
      "Epoch 2891/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.0837 - acc: 0.9509 - val_loss: 1.4528 - val_acc: 0.7407\n",
      "Epoch 2892/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.0895 - acc: 0.9509 - val_loss: 1.6180 - val_acc: 0.6667\n",
      "Epoch 2893/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.1000 - acc: 0.9448 - val_loss: 1.4542 - val_acc: 0.7778\n",
      "Epoch 2894/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.1102 - acc: 0.9509 - val_loss: 1.6537 - val_acc: 0.6667\n",
      "Epoch 2895/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.1168 - acc: 0.9448 - val_loss: 1.4009 - val_acc: 0.7778\n",
      "Epoch 2896/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.0865 - acc: 0.9509 - val_loss: 1.5061 - val_acc: 0.6667\n",
      "Epoch 2897/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.0817 - acc: 0.9571 - val_loss: 1.4579 - val_acc: 0.7037\n",
      "Epoch 2898/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.0802 - acc: 0.9571 - val_loss: 1.4929 - val_acc: 0.6667\n",
      "Epoch 2899/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.0795 - acc: 0.9509 - val_loss: 1.4777 - val_acc: 0.7037\n",
      "Epoch 2900/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.0793 - acc: 0.9571 - val_loss: 1.4909 - val_acc: 0.7037\n",
      "Epoch 2901/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0792 - acc: 0.9509 - val_loss: 1.4840 - val_acc: 0.7037\n",
      "Epoch 2902/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.0792 - acc: 0.9571 - val_loss: 1.4795 - val_acc: 0.7037\n",
      "Epoch 2903/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.0800 - acc: 0.9509 - val_loss: 1.5031 - val_acc: 0.7037\n",
      "Epoch 2904/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.0829 - acc: 0.9571 - val_loss: 1.4558 - val_acc: 0.7037\n",
      "Epoch 2905/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.0912 - acc: 0.9448 - val_loss: 1.5332 - val_acc: 0.6667\n",
      "Epoch 2906/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.0918 - acc: 0.9571 - val_loss: 1.4239 - val_acc: 0.7037\n",
      "Epoch 2907/3000\n",
      "163/163 [==============================] - 0s 34us/step - loss: 0.0827 - acc: 0.9509 - val_loss: 1.5628 - val_acc: 0.6667\n",
      "Epoch 2908/3000\n",
      "163/163 [==============================] - 0s 58us/step - loss: 0.0845 - acc: 0.9509 - val_loss: 1.3996 - val_acc: 0.7778\n",
      "Epoch 2909/3000\n",
      "163/163 [==============================] - 0s 38us/step - loss: 0.0927 - acc: 0.9509 - val_loss: 1.6330 - val_acc: 0.6667\n",
      "Epoch 2910/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.0987 - acc: 0.9448 - val_loss: 1.4151 - val_acc: 0.7778\n",
      "Epoch 2911/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.0941 - acc: 0.9571 - val_loss: 1.5949 - val_acc: 0.6667\n",
      "Epoch 2912/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.0900 - acc: 0.9448 - val_loss: 1.4375 - val_acc: 0.7778\n",
      "Epoch 2913/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.0851 - acc: 0.9571 - val_loss: 1.5666 - val_acc: 0.6667\n",
      "Epoch 2914/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.0848 - acc: 0.9571 - val_loss: 1.4776 - val_acc: 0.7407\n",
      "Epoch 2915/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0820 - acc: 0.9571 - val_loss: 1.5602 - val_acc: 0.6667\n",
      "Epoch 2916/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0808 - acc: 0.9632 - val_loss: 1.4930 - val_acc: 0.7037\n",
      "Epoch 2917/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.0799 - acc: 0.9509 - val_loss: 1.5544 - val_acc: 0.6667\n",
      "Epoch 2918/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.0798 - acc: 0.9571 - val_loss: 1.4942 - val_acc: 0.7037\n",
      "Epoch 2919/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0798 - acc: 0.9509 - val_loss: 1.5648 - val_acc: 0.6667\n",
      "Epoch 2920/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.0804 - acc: 0.9632 - val_loss: 1.4837 - val_acc: 0.7407\n",
      "Epoch 2921/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.0819 - acc: 0.9571 - val_loss: 1.5832 - val_acc: 0.6667\n",
      "Epoch 2922/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.0866 - acc: 0.9509 - val_loss: 1.4471 - val_acc: 0.7778\n",
      "Epoch 2923/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.0925 - acc: 0.9509 - val_loss: 1.6480 - val_acc: 0.6667\n",
      "Epoch 2924/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.0957 - acc: 0.9448 - val_loss: 1.4403 - val_acc: 0.7778\n",
      "Epoch 2925/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.0990 - acc: 0.9509 - val_loss: 1.6520 - val_acc: 0.6667\n",
      "Epoch 2926/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.1058 - acc: 0.9387 - val_loss: 1.4552 - val_acc: 0.7778\n",
      "Epoch 2927/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.0931 - acc: 0.9448 - val_loss: 1.6013 - val_acc: 0.6667\n",
      "Epoch 2928/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.0943 - acc: 0.9448 - val_loss: 1.4801 - val_acc: 0.7778\n",
      "Epoch 2929/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0921 - acc: 0.9509 - val_loss: 1.5779 - val_acc: 0.6667\n",
      "Epoch 2930/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.0867 - acc: 0.9448 - val_loss: 1.4743 - val_acc: 0.7037\n",
      "Epoch 2931/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0822 - acc: 0.9448 - val_loss: 1.5468 - val_acc: 0.6667\n",
      "Epoch 2932/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.0795 - acc: 0.9571 - val_loss: 1.5139 - val_acc: 0.7037\n",
      "Epoch 2933/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.0789 - acc: 0.9571 - val_loss: 1.5406 - val_acc: 0.6667\n",
      "Epoch 2934/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.0786 - acc: 0.9509 - val_loss: 1.5245 - val_acc: 0.7037\n",
      "Epoch 2935/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.0786 - acc: 0.9571 - val_loss: 1.5265 - val_acc: 0.6667\n",
      "Epoch 2936/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.0793 - acc: 0.9509 - val_loss: 1.5226 - val_acc: 0.7037\n",
      "Epoch 2937/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.0790 - acc: 0.9571 - val_loss: 1.5434 - val_acc: 0.6667\n",
      "Epoch 2938/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.0790 - acc: 0.9571 - val_loss: 1.5123 - val_acc: 0.7037\n",
      "Epoch 2939/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.0799 - acc: 0.9571 - val_loss: 1.5520 - val_acc: 0.6667\n",
      "Epoch 2940/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.0823 - acc: 0.9632 - val_loss: 1.4698 - val_acc: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2941/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.0851 - acc: 0.9571 - val_loss: 1.6228 - val_acc: 0.6667\n",
      "Epoch 2942/3000\n",
      "163/163 [==============================] - 0s 53us/step - loss: 0.0910 - acc: 0.9387 - val_loss: 1.4516 - val_acc: 0.7778\n",
      "Epoch 2943/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.0974 - acc: 0.9571 - val_loss: 1.6478 - val_acc: 0.6296\n",
      "Epoch 2944/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.1012 - acc: 0.9509 - val_loss: 1.4711 - val_acc: 0.7778\n",
      "Epoch 2945/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.0978 - acc: 0.9509 - val_loss: 1.6353 - val_acc: 0.6667\n",
      "Epoch 2946/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.0917 - acc: 0.9448 - val_loss: 1.4794 - val_acc: 0.7037\n",
      "Epoch 2947/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.0841 - acc: 0.9571 - val_loss: 1.5710 - val_acc: 0.6667\n",
      "Epoch 2948/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.0860 - acc: 0.9571 - val_loss: 1.4570 - val_acc: 0.7037\n",
      "Epoch 2949/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.0909 - acc: 0.9448 - val_loss: 1.6053 - val_acc: 0.6667\n",
      "Epoch 2950/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.0909 - acc: 0.9571 - val_loss: 1.4638 - val_acc: 0.7407\n",
      "Epoch 2951/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.0821 - acc: 0.9509 - val_loss: 1.5666 - val_acc: 0.6667\n",
      "Epoch 2952/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.0798 - acc: 0.9632 - val_loss: 1.5023 - val_acc: 0.7037\n",
      "Epoch 2953/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.0793 - acc: 0.9571 - val_loss: 1.5455 - val_acc: 0.6667\n",
      "Epoch 2954/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.0797 - acc: 0.9632 - val_loss: 1.4934 - val_acc: 0.7037\n",
      "Epoch 2955/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.0796 - acc: 0.9509 - val_loss: 1.5696 - val_acc: 0.6667\n",
      "Epoch 2956/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.0801 - acc: 0.9632 - val_loss: 1.4821 - val_acc: 0.7407\n",
      "Epoch 2957/3000\n",
      "163/163 [==============================] - 0s 47us/step - loss: 0.0809 - acc: 0.9571 - val_loss: 1.5902 - val_acc: 0.6667\n",
      "Epoch 2958/3000\n",
      "163/163 [==============================] - 0s 42us/step - loss: 0.0843 - acc: 0.9509 - val_loss: 1.4548 - val_acc: 0.7407\n",
      "Epoch 2959/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.0897 - acc: 0.9509 - val_loss: 1.6420 - val_acc: 0.6667\n",
      "Epoch 2960/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.0915 - acc: 0.9448 - val_loss: 1.4677 - val_acc: 0.7778\n",
      "Epoch 2961/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.0909 - acc: 0.9509 - val_loss: 1.6256 - val_acc: 0.6667\n",
      "Epoch 2962/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.0966 - acc: 0.9448 - val_loss: 1.4563 - val_acc: 0.7778\n",
      "Epoch 2963/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.0976 - acc: 0.9509 - val_loss: 1.6296 - val_acc: 0.6667\n",
      "Epoch 2964/3000\n",
      "163/163 [==============================] - 0s 44us/step - loss: 0.0927 - acc: 0.9448 - val_loss: 1.4761 - val_acc: 0.7778\n",
      "Epoch 2965/3000\n",
      "163/163 [==============================] - 0s 41us/step - loss: 0.0845 - acc: 0.9571 - val_loss: 1.5628 - val_acc: 0.6667\n",
      "Epoch 2966/3000\n",
      "163/163 [==============================] - 0s 39us/step - loss: 0.0829 - acc: 0.9632 - val_loss: 1.4832 - val_acc: 0.7037\n",
      "Epoch 2967/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.0801 - acc: 0.9509 - val_loss: 1.5650 - val_acc: 0.6667\n",
      "Epoch 2968/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.0800 - acc: 0.9571 - val_loss: 1.5053 - val_acc: 0.7037\n",
      "Epoch 2969/3000\n",
      "163/163 [==============================] - 0s 53us/step - loss: 0.0793 - acc: 0.9571 - val_loss: 1.5658 - val_acc: 0.6667\n",
      "Epoch 2970/3000\n",
      "163/163 [==============================] - 0s 36us/step - loss: 0.0798 - acc: 0.9571 - val_loss: 1.4896 - val_acc: 0.7037\n",
      "Epoch 2971/3000\n",
      "163/163 [==============================] - 0s 37us/step - loss: 0.0799 - acc: 0.9571 - val_loss: 1.5698 - val_acc: 0.6667\n",
      "Epoch 2972/3000\n",
      "163/163 [==============================] - 0s 35us/step - loss: 0.0806 - acc: 0.9571 - val_loss: 1.4811 - val_acc: 0.7407\n",
      "Epoch 2973/3000\n",
      "163/163 [==============================] - 0s 58us/step - loss: 0.0827 - acc: 0.9509 - val_loss: 1.5997 - val_acc: 0.6667\n",
      "Epoch 2974/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.0838 - acc: 0.9571 - val_loss: 1.4514 - val_acc: 0.7778\n",
      "Epoch 2975/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.0870 - acc: 0.9571 - val_loss: 1.6424 - val_acc: 0.6667\n",
      "Epoch 2976/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.0954 - acc: 0.9387 - val_loss: 1.4284 - val_acc: 0.7778\n",
      "Epoch 2977/3000\n",
      "163/163 [==============================] - 0s 57us/step - loss: 0.0991 - acc: 0.9571 - val_loss: 1.6236 - val_acc: 0.6667\n",
      "Epoch 2978/3000\n",
      "163/163 [==============================] - 0s 56us/step - loss: 0.0985 - acc: 0.9448 - val_loss: 1.4637 - val_acc: 0.7778\n",
      "Epoch 2979/3000\n",
      "163/163 [==============================] - 0s 54us/step - loss: 0.0942 - acc: 0.9448 - val_loss: 1.6029 - val_acc: 0.6667\n",
      "Epoch 2980/3000\n",
      "163/163 [==============================] - 0s 55us/step - loss: 0.0915 - acc: 0.9448 - val_loss: 1.4679 - val_acc: 0.7778\n",
      "Epoch 2981/3000\n",
      "163/163 [==============================] - 0s 63us/step - loss: 0.0835 - acc: 0.9571 - val_loss: 1.5487 - val_acc: 0.6667\n",
      "Epoch 2982/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.0809 - acc: 0.9632 - val_loss: 1.4912 - val_acc: 0.7407\n",
      "Epoch 2983/3000\n",
      "163/163 [==============================] - 0s 52us/step - loss: 0.0790 - acc: 0.9571 - val_loss: 1.5347 - val_acc: 0.6667\n",
      "Epoch 2984/3000\n",
      "163/163 [==============================] - 0s 55us/step - loss: 0.0784 - acc: 0.9571 - val_loss: 1.5076 - val_acc: 0.7037\n",
      "Epoch 2985/3000\n",
      "163/163 [==============================] - 0s 54us/step - loss: 0.0781 - acc: 0.9571 - val_loss: 1.5350 - val_acc: 0.6667\n",
      "Epoch 2986/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.0780 - acc: 0.9509 - val_loss: 1.5163 - val_acc: 0.7037\n",
      "Epoch 2987/3000\n",
      "163/163 [==============================] - 0s 50us/step - loss: 0.0779 - acc: 0.9571 - val_loss: 1.5351 - val_acc: 0.6667\n",
      "Epoch 2988/3000\n",
      "163/163 [==============================] - 0s 49us/step - loss: 0.0786 - acc: 0.9509 - val_loss: 1.4969 - val_acc: 0.7407\n",
      "Epoch 2989/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.0787 - acc: 0.9571 - val_loss: 1.5592 - val_acc: 0.6667\n",
      "Epoch 2990/3000\n",
      "163/163 [==============================] - 0s 51us/step - loss: 0.0790 - acc: 0.9571 - val_loss: 1.4847 - val_acc: 0.7407\n",
      "Epoch 2991/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.0808 - acc: 0.9571 - val_loss: 1.5835 - val_acc: 0.6667\n",
      "Epoch 2992/3000\n",
      "163/163 [==============================] - 0s 55us/step - loss: 0.0859 - acc: 0.9509 - val_loss: 1.4401 - val_acc: 0.7778\n",
      "Epoch 2993/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.0948 - acc: 0.9571 - val_loss: 1.6387 - val_acc: 0.6667\n",
      "Epoch 2994/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.1028 - acc: 0.9509 - val_loss: 1.4679 - val_acc: 0.7778\n",
      "Epoch 2995/3000\n",
      "163/163 [==============================] - 0s 54us/step - loss: 0.1083 - acc: 0.9509 - val_loss: 1.6376 - val_acc: 0.6296\n",
      "Epoch 2996/3000\n",
      "163/163 [==============================] - 0s 46us/step - loss: 0.1138 - acc: 0.9448 - val_loss: 1.4287 - val_acc: 0.7778\n",
      "Epoch 2997/3000\n",
      "163/163 [==============================] - 0s 43us/step - loss: 0.0866 - acc: 0.9509 - val_loss: 1.5412 - val_acc: 0.6667\n",
      "Epoch 2998/3000\n",
      "163/163 [==============================] - 0s 45us/step - loss: 0.0799 - acc: 0.9632 - val_loss: 1.4895 - val_acc: 0.7407\n",
      "Epoch 2999/3000\n",
      "163/163 [==============================] - 0s 48us/step - loss: 0.0783 - acc: 0.9571 - val_loss: 1.5118 - val_acc: 0.6667\n",
      "Epoch 3000/3000\n",
      "163/163 [==============================] - 0s 40us/step - loss: 0.0780 - acc: 0.9509 - val_loss: 1.5060 - val_acc: 0.7037\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "hidden_layer = 10\n",
    "model.add(layers.Dense(hidden_layer, activation='relu', input_dim=3))\n",
    "model.add(layers.Dense(hidden_layer, activation='relu'))\n",
    "model.add(layers.Dense(hidden_layer, activation='relu'))\n",
    "model.add(layers.Dense(hidden_layer, activation='relu'))\n",
    "model.add(layers.Dense(hidden_layer, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['acc'])\n",
    "#model.compile(optimizer=RMSprop(lr=0.00001), loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(clinical_train, y_train, validation_data=(clinical_validation, y_validation), epochs=3000, batch_size=256, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "3/3 [==============================] - 0s 836us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14412416517734528, 1.0]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(clinical_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.7315575 ,  0.        , -0.14323373], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinical_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(clinical_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04985923] 0\n",
      "[1.6053207e-08] 0\n",
      "[1.] 1\n"
     ]
    }
   ],
   "source": [
    "for a, b in zip(prediction, y_test):\n",
    "    print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_smoothly(history):\n",
    "    def smooth_curve(points, factor=0.8):\n",
    "      smoothed_points = []\n",
    "      for point in points:\n",
    "        if smoothed_points:\n",
    "          previous = smoothed_points[-1]\n",
    "          smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "          smoothed_points.append(point)\n",
    "      return smoothed_points\n",
    "\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(len(acc))\n",
    "    \n",
    "    plt.plot(epochs,\n",
    "             smooth_curve(acc), 'bo', label='Smoothed training acc')\n",
    "    plt.plot(epochs,\n",
    "             smooth_curve(val_acc), 'b', label='Smoothed validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs,\n",
    "             smooth_curve(loss), 'bo', label='Smoothed training loss')\n",
    "    plt.plot(epochs,\n",
    "             smooth_curve(val_loss), 'b', label='Smoothed validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJztnXt4FEX297+HcAnhIppEBQIBXRTBBISIXLygQURUXF1QWEDxhoK4+vOKooi+srKsK4sCKqsCQhRcdBVdFEVxVRQ1aEQIErlqACEEAyQEIXDeP6o73dPTPdMzmclMT87nefqZ7qqa6lPd1aerT1WdImaGIAiCkFjUi7UAgiAIQuQR5S4IgpCAiHIXBEFIQES5C4IgJCCi3AVBEBIQUe6CIAgJiCj3BIaIkoionIjaRjJtLCGiPxBRxMfvElE/ItpqOt5AROe5SRvGuV4koofC/b8guKF+rAUQDIio3HSYAuB3AEe141uZOS+U/Jj5KICmkU5bF2Dm0yORDxHdDGAEM/c15X1zJPIWhECIco8jmLlauWotw5uZeblTeiKqz8xVtSGbIARD6mN8IWYZD0FETxDRIiJ6jYgOABhBRL2IaBURlRHRTiJ6hogaaOnrExETUTvteIEW/x4RHSCiL4mofahptfhLiaiIiPYR0bNEtJKIRjnI7UbGW4loIxH9RkTPmP6bRETTiKiUiDYBGBDg+jxMRAstYTOJ6Glt/2YiWq+VZ5PWqnbKq5iI+mr7KUQ0X5NtHYDuNufdrOW7jogGaeFZAGYAOE8zee0xXdtJpv/fppW9lIjeIqKWbq5NKNdZl4eIlhPRXiL6lYjuN53nEe2a7CeifCJqZWcCI6LP9fusXc9PtfPsBfAwEXUgohVaWfZo1+040/8ztTKWaPHTiShZk/kMU7qWRHSQiFKdyisEgZlli8MNwFYA/SxhTwA4DOAKqBdzYwBnAzgH6ivsFABFAMZp6esDYADttOMFAPYAyAHQAMAiAAvCSHsigAMArtTi7gZwBMAoh7K4kfFtAMcBaAdgr152AOMArAOQASAVwKeq2tqe5xQA5QCamPLeDSBHO75CS0MALgJQCSBbi+sHYKspr2IAfbX9pwB8AuB4AJkACi1prwHQUrsnf9ZkOEmLuxnAJxY5FwCYpO3312TsCiAZwCwAH7u5NiFe5+MA7AJwJ4BGAJoD6KHFPQjgewAdtDJ0BXACgD9YrzWAz/X7rJWtCsAYAElQ9fE0ALkAGmr1ZCWAp0zlWatdzyZa+j5a3GwAk03nuQfAf2L9HHp5i7kAsjncGGfl/nGQ/90L4N/avp3Cft6UdhCAtWGkvRHAZ6Y4ArATDsrdpYw9TfFvArhX2/8Uyjylxw20KhxL3qsA/FnbvxRAUYC07wK4XdsPpNx/Nt8LAGPNaW3yXQvgMm0/mHKfB+CvprjmUP0sGcGuTYjXeSSAfId0m3R5LeFulPvmIDIMBvCNtn8egF8BJNmk6wNgCwDSjgsAXB3p56oubWKW8R6/mA+IqCMR/Vf7zN4P4HEAaQH+/6tp/yACd6I6pW1lloPV01jslIlLGV2dC8C2APICwKsAhmn7fwZQ3QlNRJcT0VeaWaIMqtUc6FrptAwkAxGNIqLvNdNCGYCOLvMFVPmq82Pm/QB+A9DalMbVPQtyndsA2OggQxsoBR8O1vp4MhG9TkTbNRnmWmTYyqrz3gdmXgn1FXAuEZ0JoC2A/4YpkwCxuXsR6zDAF6Bain9g5uYAJkK1pKPJTqiWJQCAiAi+yshKTWTcCaUUdIIN1VwEoB8RZUCZjV7VZGwMYDGAJ6FMJi0AfOBSjl+dZCCiUwA8B2WaSNXy/dGUb7BhmzugTD16fs2gzD/bXchlJdB1/gXAqQ7/c4qr0GRKMYWdbEljLd/foEZ5ZWkyjLLIkElESQ5yvAJgBNRXxuvM/LtDOsEFoty9TzMA+wBUaB1St9bCOd8F0I2IriCi+lB23PQoyfg6gLuIqLXWufZAoMTMvAvKdDAHwAZm/kmLagRlBy4BcJSILoeyDbuV4SEiakFqHsA4U1xTKAVXAvWeuxmq5a6zC0CGuWPTwmsAbiKibCJqBPXy+YyZHb+EAhDoOi8B0JaIxhFRQyJqTkQ9tLgXATxBRKeSoisRnQD1UvsVquM+iYhGw/QiCiBDBYB9RNQGyjSk8yWAUgB/JdVJ3ZiI+pji50OZcf4MpeiFGiDK3fvcA+B6qA7OF6BarlFFU6DXAnga6mE9FcB3UC22SMv4HICPAPwA4Buo1ncwXoWyob9qkrkMwP8B+A9Up+RgqJeUGx6F+oLYCuA9mBQPM68B8AyAr7U0HQF8ZfrvhwB+ArCLiMzmFf3/70OZT/6j/b8tgOEu5bLieJ2ZeR+AiwH8CaoDtwjABVr03wG8BXWd90N1biZr5rZbADwE1bn+B0vZ7HgUQA+ol8wSAG+YZKgCcDmAM6Ba8T9D3Qc9fivUfT7MzF+EWHbBgt55IQhho31m7wAwmJk/i7U8gncholegOmknxVoWryOTmISwIKIBUJ/Zh6CG0lVBtV4FISy0/osrAWTFWpZEQMwyQricC2Az1Of6AAB/lA4wIVyI6EmosfZ/ZeafYy1PIiBmGUEQhAREWu6CIAgJSMxs7mlpadyuXbtYnV4QBMGTrF69eg8zBxp6DCCGyr1du3bIz8+P1ekFQRA8CREFm6UNQMwygiAICYkod0EQhARElLsgCEICIspdEAQhARHlLgiCkIAEVe5E9DIR7SaitQ7xpC2ztZGI1hBRt8iLKQhCtOncGSCK3VavXmzPH4tt7Njo3U83Lfe5CLBuJdRqNx20bTSUFz9BEEIkJcX3wU8xeVHv1883rl8/I65168gomsLC2i+zmbo4Wf6556Kn4IMqd2b+FMpFqhNXAniFFasAtCBtgV9BEBR5eUC7dqp12q6dOjZDBFRW+oZVVqrw1q2Bjz7yjfvoI0Mp79gRTcmFaDN7dnTyjcQkptbwXWqrWAvbaU2oOfsfDQBt2wZbUEcQEoO8PGDECON42zbjePhw31a4HaK8E5ujfosORoZIdKjaLVNm+4HFzLOZOYeZc9LTg86eFYSoEawlHSweCGwqMcebFbuZ669Xv9ZWuVC3SHJadLCGREK5F8N3fckMqIUbBCEu0VvS27YpO6/ektYVeF4eMHKkf7xuGx07ViltO1NJv37q/40aBVfa0WqxCd5i9Ojo5OvK5S8RtQPwLjOfaRN3GdSakgMBnAPgGWbuYU1nJScnh8W3jBAL6te3V6xEwLFjQHIy8LuDZ/rc3Mi2tCOdn+AtOnUC1q0L7T9EtJqZc4KlczMU8jWoFXdOJ6JiIrqJiG4jotu0JEuhFm3YCOBfAKI4uEeoaziZPpzMJnqr2mlr3Ni5xcys/u+k2IHIK2JR7HWbUBV7KMRssQ5puQt29OsXvsKTVrDgJZo0AcrLQ/9fxFruglBb1ESxA6LYBW/xwgvRzV+UuxAVgplH7DZRzkJdYvjw6OYfs8U6BG8xdqyabGG2VzdpoibaHDsWO7kEQbBHlLsQkLFj1RRpOyoqalcWQRDcI2YZwQ99JAqRs2IXBCEwycmxPb8od8HPPq5P8BEEr0B28+Qt6DNBg80ITU313V+wQG0NGvimq1fPP68GDVRaZmWydDpXtGal+sgX/VMIsSQvD0hLMxR306Zq9qRZmUvrvO7hRhlGE7Oi7dTJPk2rVu4Usj75LDMz8DmrqpTSraoKnG7PHpWOWe0PH662OXPUOYjU7yuvAPPm+YbNmePbUeo0+zRas1J9YOaYbN27d2chuowZo1dR2WQztlDrR6dOzElJal//rcmWmmpfV83nGDPGfX3W0y5YwExknyYz0zev1FT3stUUN2ULBQD5zMF1bNAE0dpEuYfGggXOFVLfnCq2bN7biNQ9j3S+9er516vMTHW+zEzm3NzgiihYPTSfy/oyaNBAnTNcginKMWP8n4OUFP9zLljA3LChb7qGDWsmW20hyj1BWLCAuUmT2Csb2dxvSUm+SkJXoNZ0ubmB82F2vvdNmihFaQ3XFVSwVm5N66T13A0aqLzNL4oFC/xfHrWhPN2eMxayRQJR7glANFpustVsczJP1K8fnpJo2tT+PE2bGnXATpHqitPcik5N9T13pM0B1rrpRcWYCLhV7uJbJo5p1Ag4fDjWUtQdkpLsnYolJamOs2jMKKxXT6lmK3onIaA6xSdMAH7+GWjbFpg8OfqzG4X4RXzLeBh9nLko9tpFH02xYIHvCIhoKXbAXrFbw4cPB7ZuVcp+61ZR7II7ZIZqnFFT51mCM0lJamKJ3cxa89hmfehbbcnk9LUgCDVBWu5xQl6e+kQXxR4+dmO3mzb1bYG/8IL/ZJQGDYDp02tHRisxHQctJDSi3GOMviTbiBHOn+iComFDY7ag2WyizwicP98//MABX3OG3WQU68ST2mTWLGDMGN/JOmPGqHBBqAnSoRoj9HU8BQMi5WmyokJ1HA4cCCxdKh2JgmDGbYeq2NxrmUBeFusimZmitAUhGohZJspYfbvUBcWelKSWvLP6D7GaHphl9IcgRAtpuUeRRBj5Uq8ecOuthnkkJcVYoCMpCejbFygoAEpLVfrUVNU5KQpbEGKLKPcokCiml6ZNgeefF0UtCF5ElHuE6NwZKCyMtRTuSEoCTj8d2LBBjbFOSlJD72SEhiAkDqLcI0Dr1sCOHbGWwp5oTp0XBCF+kQ7VGpKXF7+KPSVFFLsg1FVcKXciGkBEG4hoIxGNt4nPJKKPiGgNEX1CRBmRFzX+iOVY9dxcf1+C1sk9s2eLYheEukpQ5U5ESQBmArgUQCcAw4jIujDWUwBeYeZsAI8DeDLSgsYbkVbs+tBA82aeuaijz7xcvtw/D3EwJQiCTtAZqkTUC8AkZr5EO34QAJj5SVOadQAuYeZiIiIA+5i5eaB8vT5D1clVa6jIJB5BEEIhki5/WwP4xXRcrIWZ+R7An7T9qwA0I6JUSxoQ0Wgiyiei/JKSEhenjk9atw5fsZt9ocgkHkEQooUb5W63TrpVtd0L4AIi+g7ABQC2A/BbY5yZZzNzDjPnpKenhyxsPNCvn/sOVCJ/c4soc0EQagM3QyGLAbQxHWcA8FFvzLwDwNUAQERNAfyJmfdFSsh4YexY9zNOO3UC1q2LrjyCIAhOuGm5fwOgAxG1J6KGAIYCWGJOQERpRKTn9SCAlyMrZnzgdtZpvXqi2AVBiC1BlTszVwEYB2AZgPUAXmfmdUT0OBEN0pL1BbCBiIoAnARgcpTkjRl5ee7T2q2sIwiCUJu4mqHKzEsBLLWETTTtLwawOLKixRcjR7pLN2ZMdOUQBEFwg8xQdUHnzu5Gx+Tmin8WQRDiA1HuQRg71p1DsNxc+4lFgiAIsUAchzkQygzUhg1FsQuCEF+IcjcR7uIaLyfk2CBBELyMKHfU3Be7TEoSBCHeqLM297FjjXVNa6LYFyyInEyCIAiRok603KO5SpK02gVBiEcSvuUeTcUurXZBEOKVhFfu0VDs9esrxS6tdkEQ4pWENsuMHRvZ/GQ9UkEQvEJCt9zdOvoKRr16yq1AVZUodkEQvEHCttwj0WqvXx+YO1cUuiAI3iNhW+4vvBDe/5KTjZWSjhwRxS4IgjdJ2Jb7sWPB08iCGoIgJCoJ2XJ343t9wQJR7IIgJC4JqdzvvDNwfNOmYm4RBCGxSUjlXloaOP7552tHDkEQhFiRkMo9GNJqFwQh0Uk45R7piUuCIAheJKGUe15e8IlLTZrUjiyCIAixJKGU+6hRwdOEO/5dEATBSySUcq+qCp5G7O2CINQFEka59+sXawkEQRDih4RR7m7WPh0zJvpyCIIgxAOulDsRDSCiDUS0kYjG28S3JaIVRPQdEa0hooGRF7VmNG4MzJoVaykEQRBqh6DKnYiSAMwEcCmATgCGEVEnS7KHAbzOzGcBGAqgVtWoG5PMwYPRl0MQBCFecNNy7wFgIzNvZubDABYCuNKShgE01/aPA7AjciIGJ5hJRpbDEwShruHGK2RrAL+YjosBnGNJMwnAB0R0B4AmAOKqe1NGyAiCUNdw03InmzC2HA8DMJeZMwAMBDCfiPzyJqLRRJRPRPklJSWhS2tDsBmp0okqCEJdxI1yLwbQxnScAX+zy00AXgcAZv4SQDKANGtGzDybmXOYOSc9PT08iS0EcwImnaiCINRF3Cj3bwB0IKL2RNQQqsN0iSXNzwByAYCIzoBS7pFpmgeBrd8QgiAIQnDlzsxVAMYBWAZgPdSomHVE9DgRDdKS3QPgFiL6HsBrAEYxR1/tulmUQxAEoS7iapk9Zl4KYKklbKJpvxBAn8iKFpxgvmRyc2tFDEEQhLjDszNU8/KC+5JZvrx2ZBEEQYg3PKvcR4yItQSCIAjxiyeVu5sZqUlJ0ZdDEAQhXvGkcnfjJGzevOjLIQiCEK94Urm7QWalCoJQl0lI5S6zUgVBqOt4TrkHG9veooXMShUEQfCccr/ttsDxv/1WO3IIgiDEM55T7uXlznGpqbUnhyAIQjzjOeUeiOnTYy2BIAhCfJBQyl1GyAiCICgSSrkLgiAIClHugiAICYgod0EQhARElLsgCEIC4jnlTnYrugYIFwRBqIt4Trk7re8ky+0JgiAYeE65O7nyFRe/giAIBp5T7kePhhYuCIJQF/GUcs/Lc7atZ2bWriyCIAjxjKeU+4QJ9rZ1ImDy5NqXRxAEIV7xlHL/+Wf7cGZxPSAIgmDGU8r9hBPsw8UbpCAIgi+eUu6CIAiCOzyl3PfuDS1cEAShruJKuRPRACLaQEQbiWi8Tfw0IirQtiIiKou8qM5mGadwQRCEukr9YAmIKAnATAAXAygG8A0RLWHmQj0NM/+fKf0dAM6KgqyCIAiCS9y03HsA2MjMm5n5MICFAK4MkH4YgNciIZwVMcsIgiC4w41ybw3gF9NxsRbmBxFlAmgP4GOH+NFElE9E+SUlJaHKirZtQwsXBEGoq7hR7nZzQp3cdA0FsJiZbZ0BMPNsZs5h5pz09HS3MlYzcGBo4YIgCHUVN8q9GEAb03EGgB0OaYciSiYZAFi61D78jTfULNWdO42wOXNUGBGweXO0JBIEQYhP3Cj3bwB0IKL2RNQQSoEvsSYiotMBHA/gy8iKaOA0Q3X3bvXbqpURduONxr7TS0EQBCFRCarcmbkKwDgAywCsB/A6M68joseJaJAp6TAAC5mj51ndybZudib28MPAu+/6xs+ZEy2JBEEQ4hOKoi4OSE5ODufn54f0n7w8YPRo4OBBIywlxffYCVnMQxCERICIVjNzTrB0npqhOnw4cP31xsIcSUnAddfFViZBEIR4xFPKPS8PmDfPWJjj6FF17AYi4I47oiebIAhCPOEp5T5hgr8JprLS/f9nzIisPIIgCPGKp5S702gZAGjXzj/srbf8w76M2lgeQRCE+MFTyj3QTNTJk4Hbb/cNGzTIP13v3pGVSRAEIR7xlHKfPFmNjjGTnKx+GzUCpk0DnnnGiHNab/XYsejIJwiCEC94SrkPHw7Mnq0WwyZSvw8+qOIaNQIaNFCdphUVwJ49zvls2FA78gqCG6ZMAQoLg6cThFDwlHK348gR9duokRGWkmIsvffhh/7/6dQp+nIJghsOH1YNlM6dYy2JkGh4Srnrk5i2bVOTkrZtA/7+dxWnm2es9Otn3yr62NZvpSDULkdtXewJQs3xlHK3Gwr5++/q19xyt3LGGf6t9dxc1WoShFiycaOxf+hQ7OQQEg9PKfdAQyEDKXdA2TXt/vPrrzWTSRBqwn/+Y+xfc03s5BASD08p90BDIYMpdyef799+G748glBTzD6P3nnHPs077wAPPFA78giJg6eUu91QyIYN1a+TzV0nKQlYscI//LLLAn8RCEKoMAPl5e7Suql7gwYBU6cax3PmAO+/H55sQt3BU8rdbijk8OEqLljLHQD69rUPz8yMmIhCHaa0FOjeHbjvPqBZMzUC5vnnVV11Wuf35ZdDP8+NNwKXXlozWYXEx1PK3Q67oZDhIC6B6y5HjgAvvug8cuXAAeC554LXkUWLlJnvH/9Qx4WFwJgxaj811XlSnR1ffAHs3w8UFbn/jxuqqpSdX+p74uMp5W43FHLRIhXnVrmbZ7CamT078P8OHlQjc1asMIZfCvHN0aOAeR323bvtJ7c98QRwyy1qs05wy80FTj4ZGDsW+OQT53Nt2ODv/sJJpsOHgaeeUnnbsW8f0KeP6mA9/XTfuB9/9D2urPR9ATADy5Y5z8KeMgW4+mpgid9aakLCwcwx2bp3786hkpnJrKqv/3bkiPt8LrjAPo9jx+zTv/WWim/f3kgr2FNaynzoUO2ec/585pkz/cMffFDdq9271bF+71as8E1nrQc669f7hv/9784yONVL69akCfOTTzrHMzPv3Gkf9+mn/mn79vWt/2+8oY6fekr93nwzc3m5Ieett6rwWbPU8YYN6njdOteXu86wcSPzwoXOeiFWAMhnFzrWU8qdKPBD4Zb33nPOZ9s25m++YZ42jfmTT5h/+y3w+Q4dYj58OOSiJCwAc25u5PM9coR5yhTmigrmykrmt99W4eXlznVAD1+wwPcYYJ4921CITvf2mmvs7/3o0b7nOXbMvXIHmDMyAtfj7dvt4+691z+tvq+/UB9+WB2npNiXacwYdXzrrer4ppvU8f33h39v4oXKSuYvv3SffsYMtdnx7bfGtfv228jIFykSUrk7tdyTkkLOio8eDe2BdFIA4bxcEhm76zFhAvNrrzHv3x9+vnPmqHwfeID5qqvUflGRalnp59y82V6Wiy/2Pda38ePtw08+mfmzzwLf/99/Z37hBVWP5s6tWV2y1qtHHrGP69HDXwZ9/+BB+7Lo2/79zM8+y/zQQ+p48GDf9H/6U/j3Jl7Qv0rmzg2e9tChwM/uyJFG/PLlkZWzpiSkcl+wwL9FkpSkHsZwqKoK/yHMzvZtsR07ph50c961SUGB7+d3rLA+MCUl/sorGAcPqrTvvKMUGLNSTABzly6++bVta+y/8IK9LD16qE9s6z288ELfdKFsugK+/fbw65DdVlzsPu0XXxj7//ufKo9TWr2FPnCgffyAATW/97EmlHpmNnHZmV0yMpjPOEPFv/lm+DKNHs28bBnzJZcw9+4dfj5mElK5MysFn5mpTDSZmcwnncRcr15YWTGz86d3qFurVkZF+fvf1f5jj9WO/Xn/fnW+QYOif65gWB8uq1J1g1lhA8pM1qFD8HuQm6ta6e3aMZ97rrv7ZpY5Vtu+fcb+P/4RXh433BA4Xlfq3bvbx593XuTrQrTQ+8ysStlcnmDPnf4lCDC//75vXEWF7zWdM8e9bFVVyny2bZuvyTCU+h+MhFXu/gWt2UVbvDiyD6qducfNZ2JN2LVLnSctzT5+yRJljzRTWWkok0hQUcE8aZLv/Rg6lDk11fdaVFQY/1m+nHniRN98ysoiez+Cbcy1e75oydC/v7t0TqbNs86KTD2oDXSZrXXaWqZ33nHOY+JEI938+b5x33+vwmfONNLonfLB0M15/fszFxb6yxSJxp5b5e6poZDR4OyzI5vfgQP+YaNGqeX9nCayRIo9e4yJWl9/DVxxhRpbPWgQcPfdvml1WfRhncuWqRnAVsrL1VDBqir/OGZjbPgFFwCTJhlxRMDChWpij5myMmO/Xz/g8ceBtWuB5cvVf1q0cFvayBDK2PN45oMP3KXbts0+XHfAZ6aoCJg4Ud3nSDNxIjBuXM3ysDr+u/BC3+O5c53/a74Ozz/vG6c/Gx06GGGvvgrMnw/Ur29/rXTMz39xsfo1z6oPtM5ExHHzBojGFimzjLn1Ew76J1iktosvdo7Lzg5fzkDoLfdALcH27Y30O3cyjxtnn97KXXep8MGD/T+D9U99u/M5bTt2GP+PRSs5Hrd4uBajRhn35cUX1RBJfejv9u1q0/s/IoFTfQuG2dRhbU1bTaxXXeWcz6BB/vdA5/33VdjKlUb8k0+qvj39ejjx738b59b3k5ONfAoKQi+zFUSy5U5EA4hoAxFtJKLxDmmuIaJCIlpHRK9G9A2kYTeJCbBfHNstKSkqr0hhtziIzpo1kTuPGeuEFH2hEjNbthj7LVsCM2a4y/uf/1S/ixcDV16p9ocNUy3epUvV8fr17mUtLVUTwmq1BeNxTj7Z93jevMifY/lyw0PlzTeryVN6nXnxRaB1azWxKtY0bWrsW10kW78uKyqc87H7wtaxcyNeWWl85QXSF7pPoSZNjHPos+iB2q33QZU7ESUBmAngUgCdAAwjok6WNB0APAigDzN3BnBXFGS19ecOAFu31jxvL6/OVFDgexzI/HPttf5hv/zie3zppcC99yqzihnda6E1PJRrl5WlKn56uvv/eAmzn6I9e5TC0e+Pk2+jYFjdIkTDNXBxsZq5umqVf9zy5eo3Pz+0PP/yF+DNN2sm1//+p5bP3LNHzTA2YzWPWM/16afO+QZS7rq5x6zcDx70NeExK1cTR48CN9wAfPedCtdNTSkpyn0E4Hv/zDOmo06wpj2AXgCWmY4fBPCgJc1UADe7+VTQt1hOYnKiNj5/d+0KXa7Dh5lXrVITUJYs8Y175x335968OXiaI0dq5zok4nbWWczffaf2naq3Of077zBv2qTCFyzwjZs2TQ11bN+e+Z57fONCqat33hlaGRo39g9r0cL33E78/rsa1fTf//rKGOg6mIcP23H55Srd228z//CDr1w//GA8H3ff7S/3ddc553v66f7XVEe/F0VFRrx5yOubbzI/95zanz1b/bZp41uuceOMoZTm7fHHA5fXDYigWaY1AHPbrlgLM3MagNOIaCURrSKiAXYZEdFoIsonovySMF5hgfy5R5r77otOviedFPp/JkwAevZUzqsGDQJWrlStgk2bVKepW9y4iW3QIHT5EoHeve3DR41yn8cJJwBdu6rHOFgrt7QUuPxy4JRT1PHw4cBppxnxF10E9OoFbN4MPPmkMkfa0b+/v/8ZM1OnAuee674MlZX+YeZOcGZnB2vFxcBPPykfO/v2GeEPPAAcf7z9f4ItltO4sfo9eNDf7KLL+txzwNNP+/83UGf5/v3AVVcZx+bVwWXmAAAgAElEQVSWvJNZRufNNw0fRLqvH90ENGCAkYedubI2149wo9ztLhFbjusD6ACgL4BhAF4kIr9xD8w8m5lzmDknPYzv8smTjZsdDcw2RfMDc9xxQJcu0TsvoD45dXvd0aPAs88Cf/0rsG6dv6Oyc88FWrUC/vCH0M4xdmxkZI1H6td3l+6mm+x9qH/wgepfaNPGN3zWLKXQdAJ96r/4ojsZAPUisNK/v7GfnW3sN2jg7/CutFTVkWXLgGnTfOPOPNPYT0oCLr7YN16vN+GYIufOVdfaasozs3Wrrwll6lTfF4QZs9/7774DRo70Nbfoz/vmzf4m2dmzlYO07dvt8w60jOaBA8qEtnKlOv5//0+ZTPbu9VXurbVmrPncR44Yylx/qeimUP2F4rRk4vvvq74qtmrQaBCsaQ93ZpnnAYwyHX8E4OxA+YY7WmboUOMT57jj3H0uuuXIESP/jRtVr3h+vppl6eRjJpztoYfUiJV584xzm8vx4ouRO1dd2dy6AHj4Yd/rba0/u3Yxf/65Ea6PEDnxROYrr/T974knGvuBRlCYufpq5htvtI/bulXlNXKkfbxTXTfPrfjHP5i3bGF+/XXlOI3ZmCV88snKtPfVV8op2oEDoV/niy5Sv7rpxYx5wprZpKFvZhOMHrZ6tRE2YoQKMzt208ej9+zJ/NJL/nmuWOEsq5NLBf16TJyoRoBZR7hNm6Z+9+5V1xFQbi/0eH22tHUzz1gfPNg/vnt3Y4b9hx/ay+YGRGoSE1SrfDOA9gAaAvgeQGdLmgEA5mn7aVBmnNRA+Yar3KdPV1Lv2WPYze68M6ysbDl4UE3ltiNaimnGDGN/1KjonSeWW3p6aOmdJpdt26ZsntZwu/szdaqyfeqTUgDlNoBZ+bsZMsT3/3b32s4m/NVXzGvX+vp2iRRHjji7rqioUI0MO8KVw3rNOnUy9v/3PzV09cMPjTDdC+Ubb/jn9dNPRjqrR01AzaSeMUMpdPM5dAYMUGHvvmuEPfGEv1zm7Y47nOvQFVf4yrd6NfOwYUb8tGkq3Cqr7lemosJQ2GZ/P888Y38+80zjyy6zT6OX/dVXQ79Xxj2LkM2dmasAjAOwDMB6AK8z8zoiepyIBmnJlgEoJaJCACsA3MfMpfY51gx9Ob1Dhwy7V8eOkcu/cWPg/PPt4/bsUTZYfQEGnbIy/9WcAg2JtGKezBFo4oWX6dUrtPR/+pN/WM+eqt/FbCs1Y/Zh/u9/q36TZ5/1NXHok9aeeMJYC8COp55Sv/VsnpAePdQqS/oSj5Gkfn1lSrEjJcV5kteyZcA994R+vlWrgK++MsyO+kSgLl3Uc9Cypa8pVLe329nmgw35O3BA1fXu3Y0ws1mmSRP1ax7CqJtIrCaZfv3U77PP+obfeKMyowJKR3TvroaSVlaq/ddeM9LqJhfrEp3z56vfRo2UmSU5Wf1fv/ZOSyiazUD6MGEraWn25YkGrsa5M/NSZj6NmU9l5sla2ERmXqLtMzPfzcydmDmLmRcGzjF8zMpdxzz2NZqkpqr1K++/3whr2VJVJvM4ckBVvr/9rXbkinfCHf713nvqd/Nm9cB/+aV9Or3jy9yBZl1rV+eii4x9Pb1d988996i2VjDGjAHeeCN4umjTv7/xQgqFc85RL6uzzlLHXbqozluzEjT3Q3z2mfqtrAT+9S/fBUzMyu0um8HQdqtKBVPuep7mDs8ff/Qf6795s3rxvPSScd8OHVIdmLt2qSG4VvSXltNADf0l27ixKq/+YisvV30DgLLV65hldKo7zZurOnjiifbxkcRz7gfMyv2xx9T+1VfXrgyZmca59Sn3dj3z99+vWkV1nbQ0e9cGQODW5oAB6iFp395fWU+eDAwdqsbe23XuWTssdcVhvU9VVcDOnYHlD8SsWbVf/6KB/oJMSQFeeAE44wwjrm1b/5XKKivVS+DCC4GNG4HbbvNtcNkpcrvO6PJytUj9f/4DvPKKCjO3avUGkj5mHFCNuebNffNp3tz4ylq2TP2av4A2bfI/t/71Yfd1ZiYlRcmkp6+oMFr3Dz9sdGhbx+FbWbtWtf4/+ii0UW7h4nKMQfygv20PHTJGSNT28D0i5Rtj4sTgad20/hKNjAzDr4b+MjaP4DAzapSx5iize18vDz1kH15ZqR7unj19w5cuVUPmrKOtnEwgdY0pU9QL0W6SGwCceqrvsVmRDx0KrF7te4/tJgnZmTMKC9W9MZsxKir864HZ5NO6tVFX9OfLPCu7Z081ZDjcyY0DBxr1F1DXZdcuYyimtRz6i2bXLv+8Hn3UaAi2bx+ePOHiuZa7PnQpJ0eN/wbi5wEdPlz9rl7tH9e5c+3KEguuvlo9mOaWtP65DxitZ53OnZVCGDvW33YaLsnJhpsEM+efr0wNieIoLNK0aKGG3joNKdVNn/rL2jxcUe/rcBr+p2O39rBda/frrwPnA6j7qCtVu2crPT24OdDcZ2J+EZSV+TYY09N9h8+avyKAwMr9ttuM8ziZCqOFp5R7Xp7h68SM2T4YSxYsUC2Jbt3842r7xpqxszdGg+Rko5wvv6x+//pXI37IEN/0Xbuq35kzjU7l2rBFCqGj+7fRFbhZGepT7x991Ahz+zVtp9zNrWYr5kaArlStHaKAqkfBzG1mc0xmprLXA8AXX/g20E480Ve5Wyde6XLo4QMHGnEtWqiW/m+/BZYlGnhKuU+YYO9uU2/BxyPduyvTw4IFtX/ut95SlfTzz8PPI9is1latjH3zzMUbblAvOrM/lWHDfP9rteMCatKWPutPiB9atvRVhnYjjawTfaxYHaABhn3cTCDlblbkTqNdAHe+i6wOB1tb592b8jK31q3yZWSoX72fwdwB3bChetHVtitrwGPK3W5mYaDweKB+fTXCxjy1PBr06KE6bMwdlFdeqb4irOYQ89TwYFxyibG/fLnvMaAq+qxZaj+QFz7A/+vF7msmLS3wdHohNjRo4Kuc7eznwRRYMFcDOk4zTgFfRa73A9gpd7OsF1xg7HfooF48a9b4f9Ga+xXMz6v1paTLl5OjfnVb+rp16tfsYiRYZ2008ZRydxqyVJs+Z2pCNF9CLVsq26M+HM7ceWPukxg3Tn1Grl9vzBPQMY+QsCM313eM+XHHKdun3koKNna3Tx81Xbu0tG52NHsd3Q+OE04uBmqKebihWZHr8pjnN+iY3YUMMHm6KixUDS47U2VmpvGsmF8I5rz+8hdjeKY+rLZxY/UF+/336lg3yzr5A6otPKXcnXzLOA2zizesfktCoWlT5WjKzCmnGO53zR2FP//s7wbYasvu2FG1TsydTl984b+ajRWzLVV/mN0qdyLg//7P3q+KEP8EqxtWrrzS+Do75xz/eLt5IHYO+5KTDbu2ucNXV8DmsfY65q8/c4drIB9EDRrYT7Yzr9ZmnnBofhbOP994yXTrpuYD2PUP1iaeUu7Dh/t2qCQlqRusj1LxAseOGcO2zItsWJ0/Ab6zXrdvN/ypA2qo108/qZb0TTf5Lr7Rpo3/OOCCAtW6sC5tlpamvPgB6rNab1GPGWMMUfzuO6PTWjfxDB5s5KHPCKyNWXdC7LjhBvVrft6sZjoAuPNO9Xv++WqiE6A8WwLKZPHdd6rum+uirkBvuskI08/TpInxItDt24B69lNS7F8ISUnAddep/RNOAKZPN2QIhC6T2cR04onKBHPiicrpmu6IzdzQNDvlS0lRzv2i6eTQFW58FERjC9e3jO4k6fbbmevVUw59vMbevYZfdkD5qdf3zdvevcYSXQcOqDR/+5s6/stfIifPsWOGD5WsLJX/rFn2adesUfHmhbV//VWFjRsXOZmE+GTTJuXfZvt25eBO9/+flqaWkHv+eVWfPv5Y+ZJhNupWYaGqP2Z+/ZX5xx+VT3Z9Cbrt25mXLVM+dt57Ty2tx6z8SVlx8sOjx61cGdxnvJXPP1fOxax5lZWp/fJy5hde8HcWt3Klcm4WbRApx2HR2sJV7szKs1qTJkp63WG/V9m9WylxZuUUa8kSVa4xY1SY7txKXzW9uJg5NVU9KNFAX9xBd6pkx6ZN/g9MUVFk19gUBMEet8rdczNUAWV/3r1bfTp5fXKQechW27ZqW7bMcF42f77yh61PD2/dOrrrMOqzDM2fv1bsOtbMK8ULghB7PKncdbtvp06JOePQvGhDo0Y1WwA8VG66SXW2xsNiyIIghI8nlbs+Fbo2lV5dgSi0ZdkEQYhPPDVaRkdX7jKkThAEwR5PKnd9sV2nRXcFQRDqOp5S7nl5yhSjuwe1LpAhCIIgKDyj3PPy1HTebduMsEWLVLggCILgi2eU+4QJ/jMgjxyJb4+QgiAIscIzyt2LHiEFQRBihWeUu9c9QgqCINQmnlHukyfb+wP3ikdIQRCE2sQzyn34cLVyT2ammmiTmamOveQRUhAEobbw1AzV4cNFmQuCILjBVcudiAYQ0QYi2khE423iRxFRCREVaNvNkRdVEARBcEvQljsRJQGYCeBiAMUAviGiJcxcaEm6iJnH+WUgCIIg1DpuWu49AGxk5s3MfBjAQgBXRlcsQRAEoSa4Ue6tAfxiOi7Wwqz8iYjWENFiIrJdLZSIRhNRPhHll5gX7xQEQRAiihvlbucx3bp2/TsA2jFzNoDlAObZZcTMs5k5h5lz0s2rVAiCIAgRxY1yLwZgbolnANhhTsDMpcz8u3b4LwDdIyOeIAiCEA5ulPs3ADoQUXsiaghgKIAl5gRE1NJ0OAjA+siJKAiCIIRK0NEyzFxFROMALAOQBOBlZl5HRI9DLdS6BMBfiGgQgCoAewGMiqLMglCrHDlyBMXFxTh06FCsRRHqEMnJycjIyECDBg3C+j+pxbRrn5ycHM7Pz4/JuQUhFLZs2YJmzZohNTUVlIiL9gpxBzOjtLQUBw4cQPv27X3iiGg1M+cEy8Mz7gcEIVYcOnRIFLtQqxARUlNTa/S1KMpdEFwgil2obWpa50S5C4IgJCCeUu76Gqr16qlfWWJPiEciXU8nT56Mzp07Izs7G127dsVXX30VCTFt2bp1K1599dXq47lz52LcuPC9inzyySe4/PLL/cILCgqwVF8MOQR27NiBwYMHB003cOBAlJWVhZx/IuEZr5D6Gqr6UnvbtqljQDxFCvFDpOvpl19+iXfffRfffvstGjVqhD179uDw4cORE9iCrtz//Oc/R+0cgFLu+fn5GDhwoF9cVVUV6te3V02tWrXC4sWLg+Yfzosj0fBMy91uDdWDB2UNVSG+iHQ93blzJ9LS0tCoUSMAQFpaGlq1agUAaNeuHR566CH06tULOTk5+Pbbb3HJJZfg1FNPxfPPPw9Ajbq47777cOaZZyIrKwuLFi0KGD5+/Hh89tln6Nq1K6ZNmwZAtZYHDBiADh064P7776+W7YMPPkCvXr3QrVs3DBkyBOXl5QCA999/Hx07dsS5556LN998069Mhw8fxsSJE7Fo0SJ07doVixYtwqRJkzB69Gj0798f1113HbZu3YrzzjsP3bp1Q7du3fDFF18AUC+fM888E4D6qrj66qttZWvXrh327NmDrVu34owzzsAtt9yCzp07o3///qisrAQAfPPNN8jOzkavXr2qr4WV8vJy5Obmolu3bsjKysLbb79dHffKK68gOzsbXbp0wciRIwEAu3btwlVXXYUuXbqgS5cu1XLHBGaOyda9e3cOBSJmwH8jCikbQQiZwsJC12kjXU8PHDjAXbp04Q4dOvCYMWP4k08+qY7LzMzkWbNmMTPzXXfdxVlZWbx//37evXs3p6enMzPz4sWLuV+/flxVVcW//vort2nThnfs2OEYvmLFCr7sssuqzzFnzhxu3749l5WVcWVlJbdt25Z//vlnLikp4fPOO4/Ly8uZmXnKlCn82GOPcWVlJWdkZHBRUREfO3aMhwwZ4pOfOd/bb7+9+vjRRx/lbt268cGDB5mZuaKigisrK5mZuaioiHV9sWXLFu7cuXNA2fRrU1JSwlu2bOGkpCT+7rvvmJl5yJAhPH/+fGZm7ty5M69cuZKZmR944IHqfM0cOXKE9+3bx8zMJSUlfOqpp/KxY8d47dq1fNppp3FJSQkzM5eWljIz8zXXXMPTpk1jZuaqqiouKysLfpMDYFf3oOYXBdWxnmm5yxqqgheIdD1t2rQpVq9ejdmzZyM9PR3XXnst5s6dWx0/aNAgAEBWVhbOOeccNGvWDOnp6UhOTkZZWRk+//xzDBs2DElJSTjppJNwwQUX4JtvvnEMtyM3NxfHHXcckpOT0alTJ2zbtg2rVq1CYWEh+vTpg65du2LevHnYtm0bfvzxR7Rv3x4dOnQAEWHEiBGuyzpo0CA0btwYgJo4dssttyArKwtDhgxBYaHVw7izbFbat2+Prl27AgC6d++OrVu3oqysDAcOHEDv3r0BwNEMxcx46KGHkJ2djX79+mH79u3YtWsXPv74YwwePBhpaWkAgBNOOAEA8PHHH2PMmDEAgKSkJBx33HGuyx9pPGNznzzZ15YJyBqqQvwRjXqalJSEvn37om/fvsjKysK8efMwatQoAKg219SrV696Xz+uqqoCO0xSdAq3w5xvUlJSdb4XX3wxXnvtNZ+0BQUFYQ/ha9KkSfX+tGnTcNJJJ+H777/HsWPHkJyc7Fq2YGkqKytdlz8vLw8lJSVYvXo1GjRogHbt2uHQoUNg5rgfHuuZlrusoSp4gUjX0w0bNuCnn36qPi4oKEBmZqbr/59//vlYtGgRjh49ipKSEnz66afo0aOHY3izZs1w4MCBoPn27NkTK1euxMaNGwEABw8eRFFRETp27IgtW7Zg06ZNAOCn/HWCnWffvn1o2bIl6tWrh/nz5+Po0aOuy+yG448/Hs2aNcOqVasAAAsXLnSU48QTT0SDBg2wYsWK6i+D3NxcvP766ygtLQUA7N27tzr8ueeeAwAcPXoU+/fvj6jcoeAZ5Q6oB2TrVuDYMfUril2IRyJZT8vLy3H99dejU6dOyM7ORmFhISZNmuT6/1dddVV1p99FF12EqVOn4uSTT3YMz87ORv369dGlS5fqDlU70tPTMXfuXAwbNgzZ2dno2bMnfvzxRyQnJ2P27Nm47LLLcO655zq+iC688EIUFhZWd6haGTt2LObNm4eePXuiqKjIp1UfKV566SWMHj0avXr1AjPbmlCGDx+O/Px85OTkIC8vDx07dgQAdO7cGRMmTMAFF1yALl264O677wYATJ8+HStWrEBWVha6d++OdevWRVxut4hvGUEIwvr163HGGWfEWgwhwpSXl6Np06YAgClTpmDnzp2YPn16jKXyxa7uufUt4xmbuyAIQiT573//iyeffBJVVVXIzMz06ahOBES5C4JQJ7n22mtx7bXXxlqMqOEpm7sgCILgDlHugiAICYgod0EQhARElLsgCEICIspdEOKcRHT5W5N8lixZgilTptim04c2OlFWVoZZs2ZVH7t1IexFRLkLQhxjdvm7Zs0aLF++HG3atIna+azKPR4ZNGgQxo8fH9Z/rcrdrQthLyLKXRBC4K67gL59I7vddZfz+RLR5S8AnHPOOT6zN/v27YvVq1fj66+/Ru/evXHWWWehd+/e2LBhg99/zV8TW7ZsQa9evXD22WfjkUceqU7j5Kp3/Pjx2LRpE7p27Yr77rvPx4XwoUOHcMMNNyArKwtnnXUWVqxYUX0+J9fCZh5//HGcffbZOPPMMzF69Ohq/zUbN25Ev3790KVLF3Tr1q3aNcPUqVORlZWFLl26hP2yCogb15HR2EJ1+SsIscLsdvXOO5kvuCCy2513Op87UV3+Pv300zxx4kRmZt6xYwd36NCBmZn37dvHR44cYWbmDz/8kK+++mpmZh+5zO6Cr7jiCp43bx4zM8+YMYObNGnCzM6ues0ug5l9XQg/9dRTPGrUKGZmXr9+Pbdp04YrKysDuhY2o7v9ZWYeMWIEL1myhJmZe/TowW+++SYzM1dWVnJFRQUvXbqUe/XqxRUVFX7/NVMTl78yiUkQQuCf/6zd8+kufz/77DOsWLEC1157LaZMmVLtFdLs8re8vBzNmjVDs2bNwnb527x5cz8ZdLe6AKrd6paVlVW7/AXUAhy9evXycfkLACNGjMDs2bP98rzmmmtw8cUX47HHHsPrr7+OIUOGAFCOuq6//nr89NNPICIcOXIk4PVZuXIl3njjDQDAyJEj8cADDwAwXPV++umnqFevXrWr3kB8/vnnuOOOOwAAHTt2RGZmJoqKihyvgdU8tmLFCkydOhUHDx7E3r170blzZ/Tt2xfbt2/HVVddBQDV3i2XL1+OG264ASkpKQAMl8GRxFNmGVlDVaiL6C5/H3vsMcyYMaNamQGxd/lbUFCAgoICFBYW4qWXXgIAV65wW7dujdTUVKxZswaLFi3C0KFDAQCPPPIILrzwQqxduxbvvPMODh06FDQvu/OZXfUWFBTgpJNOCppXoGsSzLXwoUOHMHbsWCxevBg//PADbrnllmrXwE7nirbLYFfKnYgGENEGItpIRI7GISIaTERMREGd2oSKvjbltm1qbRt9bUpR8EIik6gufwFg6NChmDp1Kvbt24esrCwAquXeunVrAHDl66VPnz7V7nrzTMrAyVVvoPKdf/751XkUFRXh559/xumnnx5UBgDVL460tDSUl5dXd9I2b94cGRkZeOuttwAAv//+Ow4ePIj+/fvj5ZdfxkHN8b/uMjiSBFXuRJQEYCaASwF0AjCMiDrZpGsG4C8AojJOS9ZQFeoiieryFwAGDx6MhQsX4pprrqkOu//++/Hggw+iT58+rny4T58+HTNnzsTZZ5+Nffv2VYc7uepNTU1Fnz59cOaZZ+K+++7zyWvs2LE4evQosrKyqle8MrfYA9GiRYvqlaP++Mc/4uyzz66Omz9/Pp555hlkZ2ejd+/e+PXXXzFgwAAMGjQIOTk56Nq1K5566ilX5wmFoC5/iagXgEnMfIl2/CAAMPOTlnT/BLAcwL0A7mXmgP58Q3X5W6+earH7y6f8ZgtCtBCXv0KsqInLXzdmmdYAfjEdF2th5pOdBaANM7/rIr+wkDVUBUEQ3ONGudtZ/avb0ERUD8A0APcEzYhoNBHlE1F+SUmJeymh1qDUOparkTVUBUEQ7HGj3IsBmMf8ZADYYTpuBuBMAJ8Q0VYAPQEssetUZebZzJzDzDnp6ekhCSprqAqxJJTRJYIQCWpa59yMc/8GQAciag9gO4ChAP5sEmAfgDT9mIg+gQubezgMHy7KXKh9kpOTUVpaitTU1Lhf8V5IDJgZpaWl1ePiwyGocmfmKiIaB2AZgCQALzPzOiJ6HGqm1JKwzy4IHiAjIwPFxcUI1ZQoCDUhOTkZGRkZYf9fFsgWBEHwEJEcLSMIgiB4DFHugiAICYgod0EQhAQkZjZ3IioBsC3Mv6cB2BNBcWKJlCU+SZSyJEo5ACmLTiYzBx1LHjPlXhOIKN9Nh4IXkLLEJ4lSlkQpByBlCRUxywiCICQgotwFQRASEK8qd/+lXbyLlCU+SZSyJEo5AClLSHjS5i4IgiAExqstd0EQBCEAotwFQRASEM8pd7frucYLRLSViH4gogIiytfCTiCiD4noJ+33eC2ciOgZrWxriKhbjGV/mYh2E9FaU1jIshPR9Vr6n4jo+jgqyyQi2q7dmwIiGmiKe1ArywYiusQUHtP6R0RtiGgFEa0nonVEdKcW7rn7EqAsXrwvyUT0NRF9r5XlMS28PRF9pV3jRUTUUAtvpB1v1OLbBStjyDCzZzYor5SbAJwCoCGA7wF0irVcQWTeCiDNEjYVwHhtfzyAv2n7AwG8B7VASk8AX8VY9vMBdAOwNlzZAZwAYLP2e7y2f3yclGUSlHtqa9pOWt1qBKC9VueS4qH+AWgJoJu23wxAkSav5+5LgLJ48b4QgKbafgOotaR7AngdwFAt/HkAY7T9sQCe1/aHAlgUqIzhyOS1lnsPABuZeTMzHwawEMCVMZYpHK4EME/bnwfgj6bwV1ixCkALImoZCwEBgJk/BWBdlj1U2S8B8CEz72Xm3wB8CGBA9KX3xaEsTlwJYCEz/87MWwBshKp7Ma9/zLyTmb/V9g8AWA+17KXn7kuAsjgRz/eFmblcO2ygbQzgIgCLtXDrfdHv12IAuUREcC5jyHhNuQddzzUOYQAfENFqIhqthZ3EzDsBVcEBnKiFe6F8ocoe72Uap5krXtZNGfBIWbRP+bOgWomevi+WsgAevC9ElEREBQB2Q70sNwEoY+YqG7mqZdbi9wFIRQTL4jXlHnA91zilDzN3A3ApgNuJ6PwAab1YPh0n2eO5TM8BOBVAVwA7AfxDC4/7shBRUwBvALiLmfcHSmoTFu9l8eR9YeajzNwVainSHgDOsEum/Ua9LF5T7sHWc407mHmH9rsbwH+gbvou3dyi/e7WknuhfKHKHrdlYuZd2gN5DMC/YHz+xnVZiKgBlDLMY+Y3tWBP3he7snj1vugwcxmAT6Bs7i2ISF/xzixXtcxa/HFQZsOIlcVryr16PVet13kogLhd5o+ImhBRM30fQH8Aa6Fk1kcnXA/gbW1/CYDrtBEOPQHs0z+144hQZV8GoD8RHa99XvfXwmKOpT/jKqh7A6iyDNVGNLQH0AHA14iD+qfZZV8CsJ6ZnzZFee6+OJXFo/clnYhaaPuNAfSD6kNYAWCwlsx6X/T7NRjAx6x6VJ3KGDq12aMciQ2q978Iyp41IdbyBJH1FKie7+8BrNPlhbKtfQTgJ+33BDZ63GdqZfsBQE6M5X8N6rP4CFSL4qZwZAdwI1TH0EYAN8RRWeZrsq7RHqqWpvQTtLJsAHBpvNQ/AOdCfaavAVCgbQO9eF8ClMWL9yUbwHeazGsBTNTCT4FSzhsB/BtAIy08WTveqMWfEqyMoW7ifkAQBCEB8ZpZRhAEQXCBKHdBEIQERJS7IAhCAiLKXRAEIdmsDkUAAAAcSURBVAER5S4IgpCAiHIXBEFIQES5C4IgJCD/H5q61+JAIW8NAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_smoothly(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
